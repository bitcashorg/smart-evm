{
  "relatedBlogs": [
    {
      "id": "190259319",
      "topics": [
        "Summary",
        "LLM",
        "Training"
      ],
      "title": "Latent Space Podcast 8/16/23 [Summary] - The Mathematics of Training LLMs — with Quentin Anthony of Eleuther AI",
      "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:19:45+01:00",
      "description": "Explore the math behind training LLMs with Quentin Anthony from Eleuther AI. Dive into the Transformers Math 101 article & master distributed training techniques for peak GPU performance.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      },
      "seo": {
        "description": "Dive into the Transformers Math 101 article & master distributed training techniques for peak GPU performance.",
        "title": "Latent Space Podcast 8/16/23 [Summary] Math of Training LLMs",
        "twitterCard": null,
        "image": {
          "width": 1576,
          "height": 554,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
        }
      }
    },
    {
      "id": "190259129",
      "topics": [
        "LLM",
        "Hardware",
        "Summary",
        "Edge"
      ],
      "title": "Latent Space Podcast 8/10/23 [Summary]: LLMs Everywhere: Running 70B models in browsers and iPhones using MLC — with Tianqi Chen of CMU / OctoML",
      "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:18:37+01:00",
      "description": "Explore the magic of MLC with Tianqi Chen: deploying 70B models on browsers & iPhones. Dive into XGBoost, TVM's creation, & the future of universal AI deployments. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      },
      "seo": {
        "description": "Explore deploying 70B models on browsers & iPhones. Dive into XGBoost, TVM's creation, & the future of universal AI deployments. ",
        "title": "Latent Space 8/10/23 [Summary]: LLMs Everywhere",
        "twitterCard": null,
        "image": {
          "width": 1538,
          "height": 548,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
        }
      }
    },
    {
      "id": "190259087",
      "topics": [
        "Summary",
        "LLM",
        "Code",
        "Open Source",
        "Small Models"
      ],
      "title": "Latent Space Podcast 8/4/23 [Summary] Latent Space x AI Breakdown crossover pod! ",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "Join AI Breakdown & Latent Space for the summer AI tech roundup: Dive into GPT4.5, Llama 2, AI tools, the rising AI engineer, and more!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "seo": {
        "description": "Dive into GPT4.5, Llama 2, AI tools, the rising AI engineer, and more!",
        "title": "Latent Space Podcast 8/4/23 [Summary] AI Breakdown crossover",
        "twitterCard": null,
        "image": {
          "width": 1578,
          "height": 558,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
        }
      }
    },
    {
      "id": "190259111",
      "topics": [
        "Summary",
        "Transformers",
        "Training",
        "Open Source"
      ],
      "title": " Latent Space Podcast 7/26/23 [Summary] FlashAttention 2: making Transformers 800% faster - Tri Dao of Together AI",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "Discover how FlashAttention revolutionized AI speed with Tri Dao, as he unveils the power of FlashAttention 2, dives into Stanford's Hazy Lab & future AI insights.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "seo": {
        "description": "Discover how FlashAttention revolutionized AI speed with Tri Dao, as he unveils the power of FlashAttention 2",
        "title": " Latent Space Podcast 7/26/23 [Summary] FlashAttention 2",
        "twitterCard": null,
        "image": {
          "width": 1648,
          "height": 594,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
        }
      }
    },
    {
      "id": "190259172",
      "topics": [
        "Summary",
        "LLM",
        "Open Source",
        "Small Models"
      ],
      "title": "Latent Space Podcast 7/19/23 [Summary] - Llama 2: The New Open LLM SOTA (ft. Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog et al.)",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "Explore Llama 2, the latest AI breakthrough with experts Nathan Lambert, Matt Bornstein & more. Dive into datasets, benchmarks & AI predictions. Llama insights & drama await in this top podcast!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "seo": {
        "description": "Dive into datasets, benchmarks & AI predictions. Llama insights & drama await in this top podcast!",
        "title": "Latent Space Podcast 7/19/23 [Summary] - Llama 2",
        "twitterCard": null,
        "image": {
          "width": 1632,
          "height": 574,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
        }
      }
    },
    {
      "id": "190259191",
      "topics": [
        "Summary",
        "Code",
        "LLM"
      ],
      "title": "Latent Space Podcast 7/10/23 [Summary] - Code Interpreter == GPT 4.5 (w/ Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "Explore ChatGPT's Code Interpreter: a game-changer in AI. Dive into its 1000x capabilities leap with Simon, Alex & top AI experts. #CodeAugmentedInference #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "seo": {
        "description": "Explore ChatGPT's Code Interpreter: a game-changer in AI. Dive into its 1000x capabilities leap with Simon, Alex & top AI experts. ",
        "title": "Latent Space Podcast  [Summary] Code Interpreter = GPT 4.5",
        "twitterCard": null,
        "image": {
          "width": 1596,
          "height": 582,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
        }
      }
    },
    {
      "id": "190259216",
      "topics": [
        "Summary",
        "Open Source"
      ],
      "title": "Latent Space Podcast 7/2/23 [Summary] AI Trends: a Latent Space x Practical AI crossover pod!",
      "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:08:36+01:00",
      "description": "Explore the fusion of Practical AI & Latent Space as they delve into 2023's top AI trends, reflect on standout episodes, and share insights on navigating the AI evolution.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      },
      "seo": {
        "description": "2023's top AI trends, reflect on standout episodes, and share insights on navigating the AI evolution.",
        "title": "Latent Space Podcast 7/2/23 [Summary] AI Trends ",
        "twitterCard": null,
        "image": {
          "width": 1600,
          "height": 532,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
        }
      }
    },
    {
      "id": "190259238",
      "topics": [
        "Hardware",
        "LLM",
        "Summary"
      ],
      "title": "Latent Space Podcast 6/20/23 [Summary] - Commoditizing the Petaflop — with George Hotz of the tiny corp",
      "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:07:15+01:00",
      "description": "George Hotz of tiny corp challenges Nvidia & Google! Dive into the world of AMD collaborations, insights on ggml, Mojo, Elon & GPT-4, plus a peek into AI Girlfriend. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      },
      "seo": {
        "description": "George Hotz of tiny corp challenges Nvidia & Google! AMD collaborations, insights on ggml, Mojo, Elon & GPT-4, plus a peek into AI Girlfriend. ",
        "title": "Latent Space Podcast 6/20/23 [Summary] - George Hotz ",
        "twitterCard": null,
        "image": {
          "width": 1586,
          "height": 508,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
        }
      }
    },
    {
      "id": "190259294",
      "topics": [
        "LLM",
        "Functions",
        "Summary"
      ],
      "title": "Latent Space Podcast 6/14/23 [Summary] - Emergency Pod: OpenAI's new Functions API, 75% Price Drop, 4x Context Length (w/ Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin et al)",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "Explore the June 2023 OpenAI updates with top AI engineers from Scale, Microsoft, Pinecone, & Huggingface. Dive into the Code x LLM paradigms and discover Recursive Function Agents.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "seo": {
        "description": "Explore the June 2023 OpenAI updates with top AI engineers from Scale, Microsoft, Pinecone, & Huggingface. ",
        "title": "Latent Space Podcast 6/20/23 [Summary] - Emergency Pod",
        "twitterCard": null,
        "image": {
          "width": 1626,
          "height": 606,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
        }
      }
    },
    {
      "id": "190259333",
      "topics": [
        "LLM",
        "Summary",
        "UX"
      ],
      "title": "Latent Space Podcast 6/8/23 [Summary] - From RLHF to RLHB: The Case for Learning from Human Behavior - with Jeffrey Wang and Joe Reeve of Amplitude",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "Explore AI & analytics with Jeffrey Wang & Joe Reeve on Latent Space Live! Dive into why AI values Analytics and the power of first-party behavioral data. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "seo": {
        "description": "Explore AI & analytics with Jeffrey Wang & Joe Reeve on Latent Space Live! Dive into why AI values Analytics and the power of first-party behavioral data. ",
        "title": "Latent Space Podcast 6/8/23 [Summary] - From RLHF to RLHB",
        "twitterCard": null,
        "image": {
          "width": 1674,
          "height": 550,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
        }
      }
    },
    {
      "id": "190260528",
      "topics": [
        "Summary",
        "LLM",
        "UX"
      ],
      "title": "Latent Space Podcast 6/1/23 [Summary] - Building the AI × UX Scenius — with Linus Lee of Notion AI",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "Explore Notion AI's transformative approach to AI and UX. Dive into the future of AI-augmented workspaces, the value beyond chat interfaces, and insights on effective knowledge work. Recap of AI×UX NYC meetup included!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "seo": {
        "description": "Explore Notion AI's transformative approach to AI and UX. ",
        "title": "Latent Space Podcast 6/1/23 [Summary] - AI × UX Scenius",
        "twitterCard": null,
        "image": {
          "width": 1614,
          "height": 546,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
        }
      }
    },
    {
      "id": "190260557",
      "topics": [
        "Summary",
        "Code",
        "LLM",
        "Agents"
      ],
      "title": "Latent Space Podcast 5/25/23 [Summary] - Debugging the Internet with AI agents – with Itamar Friedman of Codium AI and AutoGPT",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "Explore the future of AI with Itamar Friedman from Codium AI on 'Debugging the Internet'. Dive into 'Extreme DRY' agents, the rapid sync of specs & tests, and the balance between code & testing. Plus, insights from Toran & an exclusive look at AutoGPT's roadmap!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "seo": {
        "description": "Dive into 'Extreme DRY' agents, the rapid sync of specs & tests, and the balance between code & testing. ",
        "title": "Latent Space Pod 5/25/23 [Summary] Debugging the Internet",
        "twitterCard": null,
        "image": {
          "width": 1568,
          "height": 548,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
        }
      }
    },
    {
      "id": "190260577",
      "topics": [
        "LLM",
        "Small Models"
      ],
      "title": "Latent Space Podcast 5/20/23 [Summary] - MPT-7B and The Beginning of Context=Infinity — with Jonathan Frankle and Abhinav Venigalla of MosaicML",
      "slug": "latent-space-podcast-5-20-23-summary-mpt-7b-and-the-beginning-of-context-infinity",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:57:33+01:00",
      "description": "Dive into MosaicML's 9-day, $200k \"llongboi\" MPT-7B training, data prep insights, & the rise of open AI models with experts Frankle & Venigalla.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
      },
      "seo": {
        "description": "Dive into MosaicML's 9-day, $200k \"llongboi\" MPT-7B training, data prep insights, & the rise of open AI models ",
        "title": "Latent Space Podcast 6/25/23 [Summary] MosaicML",
        "twitterCard": null,
        "image": {
          "width": 1568,
          "height": 556,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
        }
      }
    },
    {
      "id": "190260597",
      "topics": [
        "LLM",
        "Structured Data"
      ],
      "title": "Latent Space Podcast 5/15/23 [Summary] - Guaranteed quality and structure in LLM outputs - with Shreya Rajpal of Guardrails AI",
      "slug": "latent-space-podcast-5-15-23-summary-guaranteed-quality-and-structure-in-llm-outp",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:56:26+01:00",
      "description": "Explore Ep. 12 with Shreya Rajpal of Guardrails AI: Dive deep into validating LLM outputs, refining answers through re-asking loops, and establishing SLAs for models. Master the nuances of AI quality assurance.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
      },
      "seo": {
        "description": "Explore Ep. 12 with Shreya Rajpal of Guardrails AI: Dive deep into validating LLM outputs.",
        "title": "Latent Space Podcast 5/15/23 [Summary] Quality LLM Outputs",
        "twitterCard": null,
        "image": {
          "width": 1580,
          "height": 512,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
        }
      }
    },
    {
      "id": "190260606",
      "topics": [
        "LLM",
        "Training",
        "Agents",
        "Multimodal"
      ],
      "title": "Latent Space Podcast 5/8/23 [Summary] - The AI Founder Gene: Being Early, Building Fast, and Believing in Greatness — with Sharif Shameem of Lexica",
      "slug": "latent-space-podcast-5-8-23-summary-the-ai-founder-gene-being-early-building-fast",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:52:09+01:00",
      "description": "Ep.11 with Sharif Shameem of Lexica: Dive into the AI founder mindset, uncovering the secrets to pioneering innovation, building game-changing tech, training models, and the intriguing potential of Agents and genomic sequencing. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
      },
      "seo": {
        "description": "Ep.11 with Sharif Shameem of Lexica: Dive into the AI founder mindset, uncovering the secrets to pioneering innovation.",
        "title": "Latent Space Pod 5/8/23 [Summary] The AI Founder Gene",
        "twitterCard": null,
        "image": {
          "width": 1606,
          "height": 550,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
        }
      }
    },
    {
      "id": "190260671",
      "topics": [
        "LLM",
        "Code",
        "Summary"
      ],
      "title": "Latent Space Podcast 5/3/23 [Summary] - Training a SOTA Code LLM in 1 week and Quantifying the Vibes — with Reza Shabani of Replit",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "Ep. 10 with Reza Shabani: Dive deep into the rapid training of a state-of-the-art Code LLM, explore Replit Ghostwriter's future, and journey from Finance to AI. Discover the transition from Kaplan to Chinchilla and more!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "seo": {
        "description": "Ep. 10 with Reza Shabani: Dive deep into the rapid training of a state-of-the-art Code LLM!",
        "title": "Latent Space Pod 5/3/23 [Summary] - SOTA Code LLM",
        "twitterCard": null,
        "image": {
          "width": 1566,
          "height": 530,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
        }
      }
    },
    {
      "id": "190629271",
      "topics": [
        "LLM",
        "Small Models",
        "Summary"
      ],
      "title": "Latent Space Podcast 4/28/23 [Summary] - Mapping the future of *truly* Open Models and Training Dolly for $30 — with Mike Conover of Databricks",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "Explore the future of open models with Mike Conover of Databricks. Dive deep into Dolly's creation, its transition from 1.0 to 2.0, & the influences behind its development. Ep.9 touches on model infrastructure, Databricks' vision, & more. #AI #OpenModels #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "seo": {
        "description": "Ep.9 touches on model infrastructure, Databricks' vision, & more. #AI #OpenModels #Dolly",
        "title": "Latent Space Pod 4/28/23 [Summary] - Mike of Databricks",
        "twitterCard": null,
        "image": {
          "width": 1572,
          "height": 628,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
        }
      }
    },
    {
      "id": "191164291",
      "topics": [
        "LLM",
        "Enterprise",
        "Summary"
      ],
      "title": "Latent Space Podcast 4/21/23 [Summary] - AI-powered Search for the Enterprise — with Deedy Das of Glean",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "Ep.8: Dive into AI in enterprise search with Deedy Das of Glean. Unpack challenges in creating an AI search giant, Google vs ChatGPT comparisons, AI infrastructure intricacies, spotting AI-generated text, and why businesses need more than just Document QA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "seo": {
        "description": "Ep.8: Dive into AI in enterprise search with Deedy Das of Glean. Unpack challenges in creating an AI search giant, Google vs ChatGPT ...",
        "title": "Latent Space Podcast 4/21/23 [Summary] - with Deedy Das ",
        "twitterCard": null,
        "image": {
          "width": 1608,
          "height": 530,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
        }
      }
    },
    {
      "id": "191165673",
      "topics": [
        "Summary",
        "Vision"
      ],
      "title": "Latent Space Podcast 4/13/23 [Summary] - Segment Anything Model and the Hard Problems of Computer Vision — with Joseph Nelson of Roboflow",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "Explore Ep.7 with Joseph Nelson on the Segment Anything Model by Meta. Dive deep into Computer Vision's future, the significance of OCR, Image Segmentation, and beyond. #Roboflow #AI",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "seo": {
        "description": "Dive deep into Computer Vision's future, the significance of OCR, Image Segmentation, and beyond. #Roboflow #AI",
        "title": "Latent Space Podcast 4/13/23 [Summary] - Segment Anything ",
        "twitterCard": null,
        "image": {
          "width": 1604,
          "height": 604,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
        }
      }
    }
  ],
  "blogContent": {
    "id": "190260640",
    "topics": [
      "Summary",
      "Open Source",
      "LLM"
    ],
    "title": "Latent Space Podcast 5/5/23 [Summary] - No Moat: Closed AI gets its Open Source wakeup call — ft. Simon Willison",
    "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T08:49:18+01:00",
    "description": "Explore 'No Moat: Closed AI's Open Source Awakening' with Simon Willison. Dive into leaked Google Moat memo insights, Google Brain Drain, and Python's speed boost with Mojo.",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Original Link: No Moat: "
                    },
                    {
                      "url": "https://www.latent.space/p/no-moat#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Closed AI gets its Open Source wakeup call — ft. Simon Willison"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Summary"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 3,
                  "children": [
                    {
                      "type": "span",
                      "value": "Open Source AI Models Challenge Tech Giants"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "\nThe Google Memo and Open Source Rise"
                    },
                    {
                      "type": "span",
                      "value": " Simon Willison highlighted a leaked memo titled \"We Have No Moat and neither does OpenAI\" suggesting that while Google and OpenAI are building bigger language models, open source projects are quickly catching up. He mentioned Facebook's Lama as a milestone and Stanford's Alpaca as a substantial improvement. The memo argues against the belief that larger models mean more power, suggesting instead that smaller, flexible models could be the future. The high quality and richness of the analysis within the memo was stressed."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Open Source vs. Closed Systems"
                    },
                    {
                      "type": "span",
                      "value": " swyx commented on how traditionally, the narrative was that open source would lag behind closed systems because closed systems could adopt from open. However, this memo suggests the opposite is now occurring, with open source outpacing closed models. Travis Fischer echoed this sentiment, noting that the rapid pace of AI advancements could only be matched by open source. He questioned the real competitive advantage when models become commoditized and how companies like Google can engage with open source without compromising their position in the market."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Infrastructure and Practicality"
                    },
                    {
                      "type": "span",
                      "value": " Alessio Fanelli argued that while building the best model is essential, it's equally crucial to consider the infrastructure around running these models. Although many open-source tools are freely available, the cost and expertise required to run them might be prohibitive for many."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Running Models On Device"
                    },
                    {
                      "type": "span",
                      "value": " Simon discussed the capabilities of current models, particularly how they can be run on personal devices. He cited Vicuna 13B, a model derived from Facebook's Lama, as an example of a model running directly in the browser. He also mentioned the emerging techniques to compress these models, making them even more accessible to everyday devices."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "The Google Moat and Future Directions"
                    },
                    {
                      "type": "span",
                      "value": " swyx raised a question about Google's apparent panic, considering their vast resources and existing user base with tools like Google Calendar, Docs, and more. He wondered why, given these advantages, there's a sense of urgency within Google concerning the advances of open-source AI."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Throughout the discussion, the underlying theme was the shifting dynamics between closed systems and the rapidly advancing open-source world in AI. The rapid strides open source has made, the possibility of 'installable' abilities on models, and Google's position in this changing landscape were all debated."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-20-at-5-25-53-pm",
            "height": 532,
            "width": 1602,
            "filename": "screenshot-2023-08-20-at-5-25-53-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "AI's Competitive Landscape: Talent Drain, Data Loops, and the Promise of LoRA"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Travis Fischer touched on a significant challenge faced by companies like Google: retaining top talent. When the perception is that they are lagging in advancements, their best researchers may consider opportunities elsewhere, such as OpenAI or academic institutions. However, Fischer argued that Google, with its vast resources, shouldn't be underestimated and has the potential to regain momentum."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio Fanelli highlighted the importance of high-quality data. While Google possesses vast amounts of data from their platforms, startups face the daunting task of accumulating enough high-quality data to compete. The idea is not to have the most data but to have the right kind of data. This is where first-party data loops become crucial."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Simon Willison and swyx discussed the emergence of the Open Source Models that are trained on publicly available data, reducing dependency on large-scale, proprietary datasets. They dove into the concept of LoRA (Lower Rank Adaptation), a technique where a portion of the model is frozen, and only a smaller segment is trained, saving computational costs and time. However, these LoRAs are tied to specific model versions, raising the question of compatibility and the relevance of constantly retraining base models."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In conclusion, the AI landscape is rapidly evolving, with the focus shifting from the sheer size of data and models to the quality and adaptability of models. It remains to be seen which strategies will prove most successful in the long run."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img2",
            "height": 930,
            "width": 930,
            "filename": "abls16-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568229-abls16-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "The Power of Optimized AI Models and Language Supersets"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Optimized Models"
                            },
                            {
                              "type": "span",
                              "value": ": Simon Willison and Travis Fischer discussed the need for specialized AI models that can run directly on devices without requiring external API calls, especially in critical contexts where precision and speed are vital, like in fighter jets. Milliseconds can make a difference in such scenarios, and using an external API is not feasible."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Mojo - The Next Big Programming Language"
                            },
                            {
                              "type": "span",
                              "value": ": Simon introduced \"Mojo\", a newly announced programming language that acts as a superset of Python, which means any Python code will work in Mojo. However, Mojo introduces features that allow for highly optimized code. What sets Mojo apart is its ability to significantly improve the performance of existing Python code, evidenced by a demo that increased matrix multiplication performance by 2000 times. The language was designed by Chris Lattner, who had a hand in creating significant computing products like LLVM and Swift."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Potential of Language Supersets"
                            },
                            {
                              "type": "span",
                              "value": ": A topic raised by swyx revolves around the concept of language supersets and their transformative potential. He expressed intrigue on why the idea of Mojo wasn't conceived earlier, given the existing concept of language supersets. Simon explained that Mojo built upon a platform called MLIR, another Lattner project optimized for multiple cores and GPU access. This gave Mojo a robust foundation to build on. The ability to enhance performance while staying in a familiar ecosystem (like Python) was touted as its standout feature."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Google and AI Strategy"
                            },
                            {
                              "type": "span",
                              "value": ": The conversation shifted to strategic moves in the AI space. There were hints that Facebook might officially release the Lama weights, a significant development that could influence the AI landscape."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The discussion overall touched on the importance of AI optimization, the introduction and potential of the Mojo programming language, and strategic moves by tech giants in the AI domain."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img3",
            "height": 930,
            "width": 930,
            "filename": "abls16-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568243-abls16-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google and the AI Landscape"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google Leak Confirmed"
                    },
                    {
                      "type": "span",
                      "value": ": Simon Willison revealed that insiders have confirmed the legitimacy of a leaked Google document."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google's Ad Model at Risk"
                    },
                    {
                      "type": "span",
                      "value": ": Both Simon and swyx discussed how ChatGPT, and other chatbots that don't serve ads, could pose a threat to Google's ad-driven revenue model. They also touched on the future of ad-supported chat models like a prototype of Bing with ads."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "AI Safety Concerns"
                    },
                    {
                      "type": "span",
                      "value": ":"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Simon distinguished between \"science fiction\" concerns of AI, like it turning against humans, and immediate threats, such as the misuse of AI for scams. He particularly highlighted the risk of AI-enabled romance scams."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Discussions hinted at an undercurrent of unease among key industry figures about AI safety."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "swyx suggested Simon could document real, non-science fiction threats posed by AI today."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Prompt Injection"
                    },
                    {
                      "type": "span",
                      "value": ": Simon expressed concern about the current risk from AI, where systems could be easily manipulated by attackers. swyx humorously suggested that individuals might start incorporating \"prompt injections\" into their bios to detect AI scraping."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google vs. OpenAI"
                    },
                    {
                      "type": "span",
                      "value": ": The document indicated that there might be internal concerns within Google about AI competition. swyx felt the document provided a glimpse into Google's internal sentiments. The debate also touched on the assertion that OpenAI, despite its innovations, lacked a sustainable competitive advantage or \"moat\"."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The discussion concluded with Travis Fischer's perspective on the eventual commoditization of large language models, agreeing with the document's sentiment about OpenAI's uncertain edge in the long run."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img1",
            "height": 930,
            "width": 930,
            "filename": "abls16-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568257-abls16-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "AI Innovations and Concerns: A Dialogue with Simon Willison and Travis Fischer"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Simon Willison discussed the challenge posed to his open-source project \"datasets\" by Chat GPT's capabilities, which could perform many of the tasks he had planned for the project's future. Nonetheless, he emphasized the growing convergence of data and AI and promoted his blog, simonwillis.net, and his newsletter which updates on AI advancements."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Travis Fischer announced the founding of his new company, aiming to develop a framework for creating reliable AI agents for specific use cases. He likened the broader AI projects to the complexities of self-driving vehicles and mentioned his desire to build from foundational, reliable primitives. Additionally, he referenced the success of his Chat PT Twitter bot which has amassed over 125,000 followers and has been sponsored by OpenAI, after a brief branding alteration."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The conversation concluded with swyx highlighting the shifting boundaries in AI usage and copyright, and expressing gratitude to the contributors and audience for their involvement."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img4",
            "height": 930,
            "width": 930,
            "filename": "abls16-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568279-abls16-img4.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Explore 'No Moat: Closed AI's Open Source Awakening' with Simon Willison. Dive into leaked Google Moat memo insights.",
      "title": "Latent Space Podcast 5/5/23 [Summary] - No Moat",
      "twitterCard": null,
      "image": {
        "width": 1602,
        "height": 532,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      }
    }
  },
  "topics": [
    "Summary",
    "Open Source",
    "LLM"
  ],
  "shortLink": ""
}