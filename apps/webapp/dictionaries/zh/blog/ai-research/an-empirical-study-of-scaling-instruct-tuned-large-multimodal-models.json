{
  "relatedBlogs": [],
  "blogContent": {
    "id": "198277150",
    "topics": [
      "大型语言模型",
      "指令调优",
      "多模态"
    ],
    "title": "关于扩展指令调优大规模多模态模型的实证研究",
    "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2024-05-27T03:33:15+01:00",
    "description": "摘要评论与评级",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "发表于 9月18日"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "作者:"
                    },
                    {
                      "url": "https://huggingface.co/Adong17",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "吕亚东"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/Chunyuan24",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "李春元"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/liuhaotian",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "刘昊天"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/jw2yang",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "杨健为"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/wyngjf",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "高建峰"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/uuu6",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "申业龙"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "摘要"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "视觉指令调优最近在开源大规模多模态模型（LMM）如LLaVA和MiniGPT-4上显示出令人鼓舞的进展。然而，现有大部分的开源LMM研究都使用13B参数或更小的模型。在本文中，我们展示了将LLaVA扩展到33B及65B/70B的实证研究，并分享了我们在图像分辨率、数据混合和参数高效训练方法（如LoRA/QLoRA）方面的探索结果。这些方法通过完成现实世界任务中的多模态和语言能力的影响进行评估。我们发现，扩展LMM能持续提升模型性能和语言能力，LoRA/QLoRA调优的性能与全模型微调的性能相当。此外，研究突出表明更高图像分辨率和多模态-语言数据混合的重要性可以提高LMM性能，有时视觉指令调优甚至可以提升LMM的纯语言能力。我们希望本研究能够让更大规模的LMM研究变得更加可访问，从而帮助建立未来研究的更强基准。代码和检查点将公开发布。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.09958",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "查看arXiv页面"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.09958",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "查看PDF"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "评论"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "论文《关于扩展指令调优大规模多模态模型的实证研究》旨在缩小对扩展大规模多模态模型（LMM）影响的理解差距。这些模型设计用于处理文本和图像，使其在需要多模态理解的任务中非常有价值。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "主要要点:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "扩展超越13B"
                            },
                            {
                              "type": "span",
                              "value": ": 之前的开源LMM研究主要集中在高达13B参数的模型上。该研究通过将LLaVA扩展到33B甚至65B/70B，提供了对更大模型动态的洞见。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "探索领域"
                            },
                            {
                              "type": "span",
                              "value": ": 研究聚焦于图像分辨率、数据混合和参数高效训练方法如LoRA/QLoRA的影响。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "一致的规模效益"
                            },
                            {
                              "type": "span",
                              "value": ": 研究发现，扩展LMM大小能持续提升其性能。此外，某些训练技巧如LoRA/QLoRA可以实现与全模型微调相当的性能，但具有更好的参数效率。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "分辨率及数据混合"
                            },
                            {
                              "type": "span",
                              "value": ": 研究强调了更高图像分辨率和混合多模态-语言数据的重要性，以实现LMM更好的性能。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "增强语言能力"
                            },
                            {
                              "type": "span",
                              "value": ": 有趣的是，视觉指令调优有时甚至能提升LMM的纯语言能力，进一步强调了多模态学习的相互关联性。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "潜在的现实世界影响:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "多样化应用"
                            },
                            {
                              "type": "span",
                              "value": ": 由于具备处理文本和图像的能力，LMM可以部署在广泛的应用中，如视觉问答、图像描述、内容审核等。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "性能提升"
                            },
                            {
                              "type": "span",
                              "value": ": 通过扩展LMM，组织和研究人员可以从增强的性能中受益，从而在现实世界任务中获得更准确的结果。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "成本效益高的微调"
                            },
                            {
                              "type": "span",
                              "value": ": 像LoRA/QLoRA这样的技术可以使研究人员在不需要全模型微调的情况下实现高性能，从而节省成本和时间。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "更好的图像分析"
                            },
                            {
                              "type": "span",
                              "value": ": 对高分辨率图像输入的强调可以提高各领域的视觉数据处理质量，从医学成像到卫星图像分析。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "促进开放科学"
                            },
                            {
                              "type": "span",
                              "value": ": 作者意图公开代码和检查点，鼓励更广泛的AI社区进行实验、复制和潜在增强研究结果。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "挑战:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "计算资源限制"
                            },
                            {
                              "type": "span",
                              "value": ": 扩展到65B/70B的模型需要大量计算资源，可能不易为许多研究人员和开发者访问。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "向实际场景的转移"
                            },
                            {
                              "type": "span",
                              "value": ": 虽然研究提供了坚实的基准，但在特定行业的实际部署可能需要特定领域的调整。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "鉴于在众多应用中对多模态理解的日益重视，从电子商务到医疗:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "我对本文现实世界影响的评级是9分（满分10分）。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "论文提供的见解可以显著影响未来多模态系统的设计、训练和部署，为各领域内更直观和高效的人机交互铺平道路。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "摘要评论与评级\n",
      "title": "关于扩展指令调优大型语言模型的实证研究",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Instruction Tuning",
    "Multimodal"
  ]
}