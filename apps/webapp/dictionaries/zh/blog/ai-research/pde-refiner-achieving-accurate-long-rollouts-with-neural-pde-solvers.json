{
  "relatedBlogs": [
    {
      "id": "198277124",
      "topics": [
        "大语言模型",
        "金融",
        "医疗",
        "法律",
        "提示"
      ],
      "title": "通过阅读理解适应大规模语言模型",
      "slug": "adapting-large-language-models-via-reading-comprehension",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:22+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "通过阅读理解适应大规模语言模型",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277342",
      "topics": [
        "大语言模型",
        "多语言"
      ],
      "title": "OpenBA：一个从零开始预训练的开源15B双语非对称seq2seq模型",
      "slug": "openba-an-open-sourced-15b-bilingual-asymmetric-seq2seq-model-pre-trained-from-sc",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:02+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "OpenBA：一个开源的15B双语...模型...",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277117",
      "topics": [
        "大语言模型",
        "检索"
      ],
      "title": "PDFTriage：在长结构化文档上进行问答",
      "slug": "pdftriage-question-answering-over-long-structured-documents",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:49+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "PDFTriage：在长结构化文档上进行问答",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277138",
      "topics": [
        "大语言模型",
        "微调"
      ],
      "title": "Sorted LLaMA：通过排序微调（SoFT）利用大语言模型中间层进行动态推理",
      "slug": "sorted-llama-unlocking-the-potential-of-intermediate-layers-of-large-language-mod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:31+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Sorted LLaMA：通过排序微调进行推理",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277150",
      "topics": [
        "大语言模型",
        "指令调整",
        "多模态"
      ],
      "title": "指令调整的大规模多模态模型的实证研究",
      "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:15+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "指令调整的大规模语言模型的实证研究",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277160",
      "topics": [
        "大语言模型",
        "代理",
        "游戏"
      ],
      "title": "MindAgent：新兴游戏交互",
      "slug": "mindagent-emergent-gaming-interaction",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:32:58+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "MindAgent：新兴游戏交互",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277196",
      "topics": [
        "大语言模型",
        "结构化数据"
      ],
      "title": "Struc-Bench：大语言模型在生成复杂结构化数据方面真的好吗？",
      "slug": "struc-bench-are-large-language-models-really-good-at-generating-complex-structure",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:38+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Struc-Bench：...生成复杂结构化数据？",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277217",
      "topics": [
        "大语言模型",
        "隐私",
        "边缘"
      ],
      "title": "通过大语言模型从隐私保护遮罩中恢复",
      "slug": "recovering-from-privacy-preserving-masking-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:26+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "通过大语言模型从隐私保护遮罩中恢复",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277239",
      "topics": [
        "大语言模型",
        "对话"
      ],
      "title": "S3-DST：大语言模型时代的结构化开放领域对话分割与状态追踪",
      "slug": "s3-dst-structured-open-domain-dialogue-segmentation-and-state-tracking-in-the-era",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:11+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "S3-DST：大语言模型时代的结构化对话分割...",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277253",
      "topics": [
        "大语言模型",
        "音频"
      ],
      "title": "利用大语言模型增强语音理解的文本",
      "slug": "augmenting-text-for-spoken-language-understanding-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:49+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "利用大语言模型增强语音理解的文本",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277277",
      "topics": [
        "大语言模型",
        "压缩"
      ],
      "title": "语言建模即压缩",
      "slug": "language-modeling-is-compression",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:32+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "语言建模即压缩",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277345",
      "topics": [
        "大语言模型",
        "多语言"
      ],
      "title": "白川2：开放的大规模语言模型",
      "slug": "baichuan-2-open-large-scale-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:59:10+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "白川2：开放的大规模语言模型",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277360",
      "topics": [
        "大语言模型",
        "RLHF"
      ],
      "title": "通过优势模型与选择性排练稳定RLHF",
      "slug": "stabilizing-rlhf-through-advantage-model-and-selective-rehearsal",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:22:15+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "通过优势模型与选择性排练稳定RLHF",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277446",
      "topics": [
        "大语言模型",
        "幻觉"
      ],
      "title": "验证链减少大语言模型中的幻觉",
      "slug": "chain-of-verification-reduces-hallucination-in-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:21:05+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "验证链减少大语言模型中的幻觉",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277458",
      "topics": [
        "大语言模型",
        "幻觉",
        "实体",
        "结构化数据"
      ],
      "title": "LMDX：基于语言模型的文档信息提取与定位",
      "slug": "lmdx-language-model-based-document-information-extraction-and-localization",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:20:31+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "LMDX：...文档信息提取与定位",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198277209",
      "topics": [
        "大语言模型",
        "数据"
      ],
      "title": "SlimPajama-DC：了解大语言模型训练的数据组合",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T23:43:32+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "SlimPajama-DC：了解大语言模型训练的数据组合",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198044929",
      "topics": [
        "大语言模型",
        "数据",
        "代理"
      ],
      "title": "推理化身代理的数据源",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:33:25+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "推理化身代理的数据源",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198044879",
      "topics": [
        "大语言模型",
        "变压器",
        "可解释性"
      ],
      "title": "稀疏自动编码器在语言模型中发现高度可解释的特征",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:23:08+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "稀疏自动编码器在语言模型中发现可解释特征",
        "description": "摘要评论与评级\n"
      }
    },
    {
      "id": "198044746",
      "topics": [
        "大语言模型",
        "变压器",
        "训练"
      ],
      "title": "稀疏连接基础模型的比例定律",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:09:44+01:00",
      "description": "摘要评论与评级",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "稀疏连接基础模型的比例定律",
        "description": "摘要评论与评级\n"
      }
    }
  ],
  "blogContent": {
    "id": "198277109",
    "topics": [
      "LLM",
      "推理"
    ],
    "title": "对比解码提升大型语言模型的推理能力",
    "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-04T22:18:11+01:00",
    "description": "摘要点评与评分",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "发布于 9月16日"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "作者:"
                    },
                    {
                      "url": "https://huggingface.co/seanobrienresearch",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "肖恩·奥布莱恩"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/mikelewis0",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "迈克·刘易斯"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "摘要"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "我们展示了对比解码——由Li等人于2022年提出的一种简单、计算轻便、无需训练的文本生成方法——在各种推理任务上相对于贪婪解码的显著提升。对比解码最初被证明能提高长文生成的感知质量，它搜索最大化强弱模型之间加权差异的字符串。我们展示了对比解码使LLaMA-65B在HellaSwag常识推理基准上优于LLaMA 2、GPT-3.5和PaLM 2-L，并在GSM8K数学词推理基准上优于LLaMA 2、GPT-3.5和PaLM-540B，同时在其他任务上也有所改进。分析表明，对比解码通过防止一些抽象推理错误以及避免在链式思维过程中复制输入部分的简单模式，相较于现有的方法有所改进。总体而言，对比解码在长文生成中优于核采样，在推理任务中优于贪婪解码，使其成为从语言模型生成文本的强大通用方法。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.09117",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "View arXiv page"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.09117",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "View PDF"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Commentary"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The paper titled \"Contrastive Decoding Improves Reasoning in Large Language Models\" presents an approach to improving text generation quality and reasoning capabilities in large language models."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Key Insights:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Contrastive Decoding"
                            },
                            {
                              "type": "span",
                              "value": ": This method leverages the difference in likelihood between strong and weak models to generate text. Originally designed for improving long-form text generation, the authors demonstrate its value for reasoning tasks as well."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Significant Outperformance"
                            },
                            {
                              "type": "span",
                              "value": ": Contrastive Decoding allows LLaMA-65B to surpass several other state-of-the-art models on specific reasoning benchmarks, such as the HellaSwag commonsense reasoning benchmark and the GSM8K math word reasoning benchmark."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Avoiding Errors"
                            },
                            {
                              "type": "span",
                              "value": ": The analysis indicates that this method can help in avoiding some abstract reasoning errors. It also reduces simpler errors such as unnecessary copying of input sections during text generation."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Potential Real-World Impact:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Enhanced Text Generation"
                            },
                            {
                              "type": "span",
                              "value": ": The method promises to improve the quality of text generated by large language models, making outputs more coherent, relevant, and reasoned."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Improved Reasoning"
                            },
                            {
                              "type": "span",
                              "value": ": A better performance on reasoning tasks can have numerous applications ranging from more intelligent chatbots to tools that can assist professionals in various analytical tasks."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Wider Applicability"
                            },
                            {
                              "type": "span",
                              "value": ": As a training-free method, Contrastive Decoding offers an advantage as it doesn't require additional computational resources for training."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Versatility"
                            },
                            {
                              "type": "span",
                              "value": ": The approach seems versatile, showing improvements across both long-form generation and specific reasoning tasks."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Challenges:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Dependence on Weak Models"
                            },
                            {
                              "type": "span",
                              "value": ": The effectiveness of Contrastive Decoding relies on the presence of both strong and weak models, which might not always be available or may vary in relative strength."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Given the novel approach to improve text generation and reasoning, as well as its demonstrated efficacy:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "I'd rate the real-world impact of this paper as an 8.5 out of 10."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "The method appears to offer a powerful, general-purpose technique for generating text from language models. If it can be broadly applied to a range of tasks and settings, its real-world impact could be considerable, especially in applications where reasoning capabilities of models are crucial."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "摘要点评与评分\n",
      "title": "对比解码在LLM中的推理能力提升",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Reasoning"
  ]
}