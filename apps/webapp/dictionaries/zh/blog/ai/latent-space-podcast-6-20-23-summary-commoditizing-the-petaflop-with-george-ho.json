{
  "relatedBlogs": [
    {
      "id": "190259319",
      "topics": [
        "总结",
        "LLM",
        "训练"
      ],
      "title": "潜在空间播客 8/16/23 [总结] - 训练LLM的数学 — 与Eleuther AI的Quentin Anthony",
      "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:19:45+01:00",
      "description": "与Eleuther AI的Quentin Anthony一起探索训练LLM背后的数学。深入了解《Transformers Math 101》文章并掌握分布式训练技术以实现GPU性能的峰值。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 8/16/23 [总结] 训练LLM的数学",
        "description": "深入了解《Transformers Math 101》文章并掌握分布式训练技术以实现GPU性能的峰值。"
      }
    },
    {
      "id": "190259129",
      "topics": [
        "LLM",
        "硬件",
        "总结",
        "边缘"
      ],
      "title": "潜在空间播客 8/10/23 [总结]: LLM无处不在：使用MLC在浏览器和iPhone上运行70B模型 — 与CMU / OctoML的Tianqi Chen",
      "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:18:37+01:00",
      "description": "与Tianqi Chen一起探索MLC的魔力：在浏览器和iPhone上部署70B模型。深入了解XGBoost、TVM的创建及通用AI部署的未来。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      },
      "seo": {
        "title": "潜在空间 8/10/23 [总结]: LLM无处不在",
        "description": "探索在浏览器和iPhone上部署70B模型。深入了解XGBoost、TVM的创建及通用AI部署的未来。"
      }
    },
    {
      "id": "190259087",
      "topics": [
        "总结",
        "LLM",
        "代码",
        "开源",
        "小模型"
      ],
      "title": "潜在空间播客 8/4/23 [总结] 潜在空间 x AI Breakdown 跨界播客！",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "加入AI Breakdown & 潜在空间的夏季AI技术综述：深入了解GPT4.5、Llama 2、AI工具、崛起的AI工程师等！",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 8/4/23 [总结] AI Breakdown 跨界",
        "description": "深入了解GPT4.5、Llama 2、AI工具、崛起的AI工程师等！"
      }
    },
    {
      "id": "190259111",
      "topics": [
        "总结",
        "Transformers",
        "训练",
        "开源"
      ],
      "title": "潜在空间播客 7/26/23 [总结] FlashAttention 2：使Transformers速度提高800% - Together AI的Tri Dao",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "与Tri Dao一起发现FlashAttention如何通过FlashAttention 2的力量革命性地提高AI速度，深入了解斯坦福的Hazy Lab及未来的AI见解。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 7/26/23 [总结] FlashAttention 2",
        "description": "与Tri Dao一起发现FlashAttention如何通过FlashAttention 2的力量革命性地提高AI速度。"
      }
    },
    {
      "id": "190259172",
      "topics": [
        "总结",
        "LLM",
        "开源",
        "小模型"
      ],
      "title": "潜在空间播客 7/19/23 [总结] - Llama 2：新的开放LLM SOTA（与Nathan Lambert、Matt Bornstein、Anton Troynikov、Russell Kaplan、Whole Mars Catalog等）",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "与专家Nathan Lambert、Matt Bornstein等一起探索Llama 2，最新的AI突破。深入了解数据集、基准测试和AI预测。在这个顶级播客中等待Llama的见解和戏剧！",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 7/19/23 [总结] - Llama 2",
        "description": "深入了解数据集、基准测试和AI预测。在这个顶级播客中等待Llama的见解和戏剧！"
      }
    },
    {
      "id": "190259191",
      "topics": [
        "总结",
        "代码",
        "LLM"
      ],
      "title": "潜在空间播客 7/10/23 [总结] - 代码解释器 == GPT 4.5（与Simon Willison、Alex Volkov、Aravind Srinivas、Alex Graveley等）",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "探索ChatGPT的代码解释器：AI的游戏规则改变者。与Simon、Alex及顶级AI专家一起深入了解其1000倍能力提升。#代码增强推理 #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 [总结] 代码解释器 = GPT 4.5",
        "description": "探索ChatGPT的代码解释器：AI的游戏规则改变者。与Simon、Alex及顶级AI专家一起深入了解其1000倍能力提升。"
      }
    },
    {
      "id": "190259216",
      "topics": [
        "总结",
        "开源"
      ],
      "title": "潜在空间播客 7/2/23 [总结] AI趋势：潜在空间 x Practical AI 跨界播客！",
      "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:08:36+01:00",
      "description": "探索Practical AI & 潜在空间的融合，深入探讨2023年的顶级AI趋势，回顾突出集，并分享在AI演变中导航的见解。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 7/2/23 [总结] AI趋势",
        "description": "2023年的顶级AI趋势，回顾突出集，并分享在AI演变中导航的见解。"
      }
    },
    {
      "id": "190259294",
      "topics": [
        "LLM",
        "功能",
        "总结"
      ],
      "title": "潜在空间播客 6/14/23 [总结] - 紧急播客：OpenAI的新功能API，75%价格下降，4倍上下文长度（与Alex Volkov、Simon Willison、Riley Goodside、Joshua Lochner、Stefania Druga、Eric Elliott、Mayo Oshin等）",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "与Scale、Microsoft、Pinecone和Huggingface的顶级AI工程师一起探索2023年6月的OpenAI更新。深入了解代码 x LLM范式并发现递归函数代理。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 6/20/23 [总结] - 紧急播客",
        "description": "与Scale、Microsoft、Pinecone和Huggingface的顶级AI工程师一起探索2023年6月的OpenAI更新。"
      }
    },
    {
      "id": "190259333",
      "topics": [
        "LLM",
        "总结",
        "用户体验"
      ],
      "title": "潜在空间播客 6/8/23 [总结] - 从RLHF到RLHB：学习人类行为的案例 - 与Amplitude的Jeffrey Wang和Joe Reeve",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "与Jeffrey Wang和Joe Reeve一起在潜在空间直播中探索AI和分析。深入了解为什么AI重视分析以及第一方行为数据的力量。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 6/8/23 [总结] - 从RLHF到RLHB",
        "description": "与Jeffrey Wang和Joe Reeve一起在潜在空间直播中探索AI和分析。深入了解为什么AI重视分析以及第一方行为数据的力量。"
      }
    },
    {
      "id": "190260528",
      "topics": [
        "总结",
        "LLM",
        "用户体验"
      ],
      "title": "潜在空间播客 6/1/23 [总结] - 构建AI × UX Scenius — 与Notion AI的Linus Lee",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "探索Notion AI对AI和用户体验的变革性方法。深入了解AI增强工作空间的未来，超越聊天界面的价值，以及有效知识工作的见解。包括AI×UX NYC聚会的回顾！",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 6/1/23 [总结] - AI × UX Scenius",
        "description": "探索Notion AI对AI和用户体验的变革性方法。"
      }
    },
    {
      "id": "190260557",
      "topics": [
        "总结",
        "代码",
        "LLM",
        "代理"
      ],
      "title": "潜在空间播客 5/25/23 [总结] - 使用AI代理调试互联网 – 与Codium AI和AutoGPT的Itamar Friedman",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "与Codium AI的Itamar Friedman一起探索AI的未来，讨论“极端DRY”代理、规范和测试的快速同步以及代码与测试之间的平衡。还有来自Toran的见解和AutoGPT路线图的独家预览！",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 5/25/23 [总结] 调试互联网",
        "description": "讨论“极端DRY”代理、规范和测试的快速同步以及代码与测试之间的平衡。"
      }
    },
    {
      "id": "190260577",
      "topics": [
        "LLM",
        "小模型"
      ],
      "title": "潜在空间播客 5/20/23 [总结] - MPT-7B和Context=Infinity的开始 — 与MosaicML的Jonathan Frankle和Abhinav Venigalla",
      "slug": "latent-space-podcast-5-20-23-summary-mpt-7b-and-the-beginning-of-context-infinity",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:57:33+01:00",
      "description": "深入了解MosaicML的9天、20万美元“llongboi”MPT-7B训练、数据准备见解及开放AI模型的崛起，与专家Frankle和Venigalla一起。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 6/25/23 [总结] MosaicML",
        "description": "深入了解MosaicML的9天、20万美元“llongboi”MPT-7B训练、数据准备见解及开放AI模型的崛起。"
      }
    },
    {
      "id": "190260597",
      "topics": [
        "LLM",
        "结构化数据"
      ],
      "title": "潜在空间播客 5/15/23 [总结] - 保证LLM输出的质量和结构 - 与Guardrails AI的Shreya Rajpal",
      "slug": "latent-space-podcast-5-15-23-summary-guaranteed-quality-and-structure-in-llm-outp",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:56:26+01:00",
      "description": "与Guardrails AI的Shreya Rajpal一起探索第12集：深入了解验证LLM输出，通过重新提问循环优化答案，并为模型建立SLA。掌握AI质量保证的细微差别。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 5/15/23 [总结] 质量LLM输出",
        "description": "与Guardrails AI的Shreya Rajpal一起探索第12集：深入了解验证LLM输出。"
      }
    },
    {
      "id": "190260606",
      "topics": [
        "LLM",
        "训练",
        "代理",
        "多模态"
      ],
      "title": "潜在空间播客 5/8/23 [总结] - AI创始基因：早期、快速构建和相信伟大 — 与Lexica的Sharif Shameem",
      "slug": "latent-space-podcast-5-8-23-summary-the-ai-founder-gene-being-early-building-fast",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:52:09+01:00",
      "description": "第11集与Lexica的Sharif Shameem：深入了解AI创始人的心态，揭示开创性创新的秘密，构建改变游戏规则的技术，训练模型，以及代理和基因组测序的有趣潜力。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 5/8/23 [总结] AI创始基因",
        "description": "第11集与Lexica的Sharif Shameem：深入了解AI创始人的心态，揭示开创性创新的秘密。"
      }
    },
    {
      "id": "190260640",
      "topics": [
        "总结",
        "开源",
        "LLM"
      ],
      "title": "潜在空间播客 5/5/23 [总结] - 无护城河：封闭AI的开源觉醒 — 与Simon Willison",
      "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:49:18+01:00",
      "description": "与Simon Willison一起探索“无护城河：封闭AI的开源觉醒”。深入了解泄露的Google Moat备忘录见解、Google Brain Drain和Python的速度提升与Mojo。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 5/5/23 [总结] - 无护城河",
        "description": "与Simon Willison一起探索“无护城河：封闭AI的开源觉醒”。深入了解泄露的Google Moat备忘录见解。"
      }
    },
    {
      "id": "190260671",
      "topics": [
        "LLM",
        "代码",
        "总结"
      ],
      "title": "潜在空间播客 5/3/23 [总结] - 在1周内训练SOTA代码LLM并量化氛围 — 与Replit的Reza Shabani",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "第10集与Replit的Reza Shabani：深入了解快速训练的最先进代码LLM，探索Replit Ghostwriter的未来，并从金融到AI的旅程。发现从Kaplan到Chinchilla的过渡及更多！",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 5/3/23 [总结] - SOTA代码LLM",
        "description": "第10集与Replit的Reza Shabani：深入了解快速训练的最先进代码LLM！"
      }
    },
    {
      "id": "190629271",
      "topics": [
        "LLM",
        "小模型",
        "总结"
      ],
      "title": "潜在空间播客 4/28/23 [总结] - 映射真正开放模型的未来并以30美元训练Dolly — 与Databricks的Mike Conover",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "与Databricks的Mike Conover一起探索开放模型的未来。深入了解Dolly的创建，从1.0到2.0的过渡及其开发背后的影响。第9集涉及模型基础设施、Databricks的愿景等。#AI #开放模型 #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 4/28/23 [总结] - Mike of Databricks",
        "description": "第9集涉及模型基础设施、Databricks的愿景等。#AI #开放模型 #Dolly"
      }
    },
    {
      "id": "191164291",
      "topics": [
        "LLM",
        "企业",
        "总结"
      ],
      "title": "潜在空间播客 4/21/23 [总结] - 企业的AI驱动搜索 — 与Glean的Deedy Das",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "第8集：与Glean的Deedy Das一起深入探讨企业搜索中的AI。解开创建AI搜索巨头的挑战，Google与ChatGPT的比较，AI基础设施的复杂性，识别AI生成的文本，以及为什么企业需要的不仅仅是文档QA。",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 4/21/23 [总结] - 与Deedy Das",
        "description": "第8集：与Glean的Deedy Das一起深入探讨企业搜索中的AI。解开创建AI搜索巨头的挑战，Google与ChatGPT的比较。"
      }
    },
    {
      "id": "191165673",
      "topics": [
        "总结",
        "视觉"
      ],
      "title": "潜在空间播客 4/13/23 [总结] - Segment Anything模型和计算机视觉的难题 — 与Roboflow的Joseph Nelson",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "与Joseph Nelson一起探索第7集，讨论Meta的Segment Anything模型。深入了解计算机视觉的未来，OCR的重要性，图像分割等。#Roboflow #AI",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "seo": {
        "title": "潜在空间播客 4/13/23 [总结] - Segment Anything",
        "description": "深入了解计算机视觉的未来，OCR的重要性，图像分割等。#Roboflow #AI"
      }
    }
  ],
  "blogContent": {
    "id": "190259238",
    "topics": [
      "硬件",
      "LLM",
      "摘要"
    ],
    "title": "潜在空间播客 2023年6月20日 [摘要] - 商品化的 Petaflop — 与 tiny corp 的 George Hotz",
    "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T09:07:15+01:00",
    "description": "tiny corp 的 George Hotz 挑战 Nvidia 和 Google！深入了解 AMD 合作、ggml、Mojo、Elon 和 GPT-4 的见解，以及 AI 女友的窥探。",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "原始链接："
                    },
                    {
                      "url": "https://www.latent.space/p/geohot#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "商品化的 Petaflop — 与 tiny corp 的 George Hotz"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "潜在空间播客的 Swyx、Alessio 和嘉宾 Geohot (George Hotz) 的摘要"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "介绍"
                    },
                    {
                      "type": "span",
                      "value": ":"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Swyx 是潜在空间的作家和编辑。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio 是 Decibel Partners 的合伙人和驻场 CTO。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Geohot (George Hotz) 是嘉宾，以其开创性的黑客技术而闻名，如解锁第一代 iPhone、破解 PS3 系统和创立 Comma.ai。他与科技巨头和监管机构有着争议性的历史。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "讨论要点"
                    },
                    {
                      "type": "span",
                      "value": ":\nGeohot 对一些主要科技公司在 AI 领域的封闭性质表示担忧，强调需要开源和可访问的工具。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "采访中充满了技术见解、对 AI 未来的讨论以及 Geohot 的经验和信仰。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Geohot 的成就"
                    },
                    {
                      "type": "span",
                      "value": ": 以解锁的 iPhone 换取汽车和 iPhone，破解 PS3，遭到索尼起诉，创立 Comma.ai 但面临政府限制。他澄清他的产品是为开发者设计的，强调开发工具包与标准产品的区别。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "英雄之旅"
                    },
                    {
                      "type": "span",
                      "value": ": 讨论 Geohot 的博客文章，涉及“英雄之旅”的概念及其与他现在深度参与的项目 TinyGrad 的关系。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "对 AI 监管的担忧"
                    },
                    {
                      "type": "span",
                      "value": ": Geohot 表达了对政府可能对 AI 进行限制的担忧，引用 Sam Altman 的国会听证会作为一个关键时刻，使他意识到自己工作的重要性。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "TinyGrad 和 TinyCorp"
                    },
                    {
                      "type": "span",
                      "value": ": Geohot 强调 AI 和机器学习模型的简化，比较复杂和简化的指令集。他提倡“RISC”方法，简化 ML 过程。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "AI 芯片辩论"
                    },
                    {
                      "type": "span",
                      "value": ": 讨论围绕 AI 芯片的效率和实现最佳性能所需的基础设施展开。George 建议，如果不能为标准 GPU 开发高效的 ML 框架，也不能为独特的芯片开发。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "图灵完备性"
                    },
                    {
                      "type": "span",
                      "value": ": George 和 Swyx 讨论了 ML 中图灵完备性的缺点。图灵完备性使编写代码更容易，但并不总是最有效的。对话涉及 TPU，它们比 CUDA 更好，以及像 Google 的 TPU 这样的闭源系统的问题。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "脉动阵列的解释"
                    },
                    {
                      "type": "span",
                      "value": ": 试图揭开脉动阵列的概念，这些阵列在功率方面效率很高，但可能并不适合所有计算。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-15-at-10-55-40-pm",
            "height": 508,
            "width": 1586,
            "filename": "screenshot-2023-08-15-at-10-55-40-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "探索 TinyGrad：George 的简化 AI 框架创新"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "在 Alessio、Swyx 和 George 之间的对话中，三人深入探讨了 'TinyGrad' 框架的复杂性和发展。"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "George 介绍了 TinyGrad，强调它最初限制在 1,000 行代码以内以确保效率。一旦核心框架建立，这一限制最终被取消。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "他将 TinyGrad 与 PyTorch 等平台进行对比，强调 PyTorch 的样板代码及其复杂性。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "TinyGrad 的前端设计类似于 PyTorch，但具有额外的功能和更好的 ONNX 支持，甚至超过了 Core ML 的能力。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "George 详细说明了 PyTorch 的问题，指出其在没有不必要的内存事务的情况下处理复杂操作的能力。他还提到了 PyTorch Lightning 的局限性，并描述了他对 TinyGrad API 的优化。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "TinyGrad 的一个重要特性是其操作融合，使用一种称为“懒惰”的概念。这使 TinyGrad 能够通过延迟操作的执行直到必要时来实现更高的效率，从而优化资源使用。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "该框架还提供了增强的调试工具。只需激活“debug=2”功能，用户就可以查看 GPU 操作的精确细节，提供更直观的性能分析方法。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "尽管有这些进步，TinyGrad 在 NVIDIA 和 x86 平台上的性能目前仍然落后。然而，在 Qualcomm GPU 上运行时，它的速度是 Qualcomm 库的两倍。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "一个显著的亮点是，TinyGrad 已成功部署在 OpenPilot 模型中达半年之久，进一步验证了其实际应用。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "总体而言，尽管仍在进行中，TinyGrad 代表了 George 对简化、高效和直观的 AI 框架的愿景。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img1",
            "height": 936,
            "width": 936,
            "filename": "abls7-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692159336-abls7-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 3,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "TinyGrad 在 AI 世界中追求开发者效率"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 在与 Swyx 和 Alessio 的对话中，强调了 NVIDIA 在市场上的显著领先地位，这归功于其投入的数百万工时。George 的 TinyGrad 项目专注于提高开发者效率，以缩小与竞争对手的性能差距。他承认在其他平台上面临的一些挑战，如 AMD 框架的复杂性和 PyTorch 的偶尔性能不一致。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "AMD 的内核问题是一个痛点，导致 George 的系统频繁崩溃。然而，在联系 AMD 的 CEO Lisa Su 后，他得到了相当大的支持和一个修复的驱动程序。这一经历突显了响应性开源文化在软件开发中的重要性。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 赞扬了良好的 CI（持续集成）对 TinyGrad 的重要性，并提到如果 PyTorch 兼容性成为障碍，可能会进行 API 调整。对话简要提到了 Chris Lattner 的 AI 项目 Mojo，强调了他们项目路径的不同。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "虽然 TinyGrad 的主要目标是商品化 petaflop，但 George 的直接商业愿望是以盈利的方式销售他的计算机。围绕 TinyGrad 项目的视觉表现和 George 关于“放弃”的玩笑分享了一些幽默。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img2",
            "height": 936,
            "width": 936,
            "filename": "abls7-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692159440-abls7-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "解码高级 AI 实现的硬件选择"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio、George 和 Swyx 讨论了硬件设计的复杂性，特别是关于 AI 的 GPU。关键亮点包括："
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio 问 George 在考虑硬件设计时考虑的指标。George 提到每秒的 teraflops 和内存带宽。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "George 讨论了“豪华 AI 计算机”的概念，专为用户设计，特别提到运行大型 AI 模型如“大 Llama”或“大 Falcon”的潜力。Swyx 提到 FB-16 Llama。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "George 和 Swyx 然后深入探讨了量化的技术细节，特别是 int8 和 FB16 标准。George 对一些不基于研究论文的量化标准持怀疑态度。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Swyx 建议，当处理数百亿参数时，单个量化可能并不重要。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "George 强调了硬件设计中的挑战，特别是在尝试将多个 GPU 集成到一个系统中时。他解释了确保系统安静、高效并具有足够功率，同时对用户保持实用性的复杂性。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Alessio 和 George 讨论了“微型盒子”作为个人计算集群或个人开发者的小型数据中心的潜力。George 设想这些设备作为家庭的 AI 中心，特别是用于家庭机器人等任务。他认为这比将数据发送到云端更好，因为延迟和成本问题。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Swyx 指出拥有个人计算集群的好处，George 强调其在 NVIDIA 许可条款下的合法性。"
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "他们以讨论 PCIe 连接的限制和带宽需求，特别是用于训练大规模模型的需求结束。"
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img2-5",
            "height": 936,
            "width": 936,
            "filename": "abls7-img2-5.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692159356-abls7-img2-5.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "AI 效率：计算和模型未来的瞥见"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx 和 George 讨论了 AI 的进步以及向更参数高效模型的推动。George 强调了 Comma 的方法，强调了在汽车中冷却和供电 AI 模型的重要性。他们触及了隐私和安全方面，强调了重大漏洞可能导致硬件被永久禁止进入其网络。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 强调了他对通过互联网进行联邦训练的怀疑，因为带宽限制。他深入探讨了“微型盒子”的想法，旨在成为“每美元 flops”和“每瓦 flops”的巅峰。他认为这些微型盒子可能对寻求高效训练方法的企业具有革命性意义。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 提到计算能力与人类认知之间的比较，引发了关于 GPT-4 的讨论，他概述了模型的参数和其训练背后的策略。他暗示了训练技术的持续改进，强调了新嵌入技术的重要性。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "以哲学性的结尾，对话转向了 Rich Sutton 的“苦涩教训”和计算能力与复杂模型设计之间的古老辩论。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img3",
            "height": 936,
            "width": 936,
            "filename": "abls7-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692158820-abls7-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "在未来的技术景观中融合 AI 和人类视角"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 讨论了 AI 的进步，提到它已经超出了预期。他考虑让多个 AI 模型如 LLM 进行讨论，然后再给出答案。他认为传统编码和 AI 模型预期需要转变视角。在他的公司 TinyCorp，他旨在处于这些技术进步的前沿，顺利整合机器学习。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "George 继续讨论 TinyCorp 的远程工作，强调公司不断发展的文化。他介绍了一种新的招聘视角，强调实用方法的重要性，而不是传统的技术筛选。George 相信工具和人类之间的共生关系。他介绍了“API 线”的概念，以解释被技术控制的人和控制技术的人之间的区别。他认为未来是一个人类被 AI 工具增强的混合体，而不是完全被取代。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx 提出了“API 线”，暗示其起源。对话转向任务分配和管理的演变，触及“看板板”的概念。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio 将话题转向物理机器人，特别是类人机器人。George 对比了 Tesla 复杂的机器人方法和 Comma 简化的版本，后者使用最少的硬件将机器人问题转化为软件挑战。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx 提到 Facebook 的“分割任何东西”，认为这是计算机视觉的重大进展。George 表达了对它的兴趣，但强调了将语音集成到 AI 中的价值，希望与 LLM 等模型进行更自然的对话体验。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img3-5",
            "height": 936,
            "width": 936,
            "filename": "abls7-img3-5.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692159096-abls7-img3-5.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "探索 AI 的未来：从机器集成到永生"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "在一场引人入胜的对话中，George 分享了他对 AI 的未来计划，描绘了一条从与 Comma 建立硬件基础设施，到与 TinyCorp 开发软件，最终创建“AI 女友”的时间线。George 挑战了通过 Neuralink 等方法进行神经融合的流行观念，认为人类和 AI 之间可以存在更深层次、更有机的连接。提到他自己在线上已经存在的大量数据，他推测通过数字化实现永生的概念。对话还深入探讨了机器学习的性质和挑战，George 强调了可访问性和提高效率的追求。聊天以 George 讨论可能推动 AI 达到新高度的“六个技巧”以及分享关于 AI 中变压器的见解结束。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img4",
            "height": 936,
            "width": 936,
            "filename": "abls7-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692158797-abls7-img4.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "有效加速主义，《阿凡达2》批评和 AI-人类内容困境"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx 以 Mark Andreessen 对有效加速主义（IAC）的支持和 George 对其的批评开场。George 认为只有左派认真对待意识形态，认为他们可以有效地围绕意识形态动员能量，而右派则不能。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "对话转向了两个名叫 Sam 的人物。一个被监禁，而两人都在各自领域寻求监管。Swyx 和 George 辩论了某些关键人物倡导 IAC 和 EA 的意图。他们还讨论了 Mark Andreessen 关于政治领域潜在欺骗的晚期认识，George 认为这对许多人来说已经很明显。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio 将话题转向电影《阿凡达2》。George 表达了对这部电影的失望，称他重写了剧本以更好地强调角色情感。Swyx 将电影的缺点归因于其写作，尽管它有令人印象深刻的 CGI。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio 和 George 讨论了 AI（如 ChatGPT）可能负责电影剧本的可能性。George 提出了在垃圾邮件等情况下区分 AI 和人类编写内容的担忧。他建议一种发送电子邮件可能有小成本的模型，以阻止垃圾邮件发送者。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "在讨论结束时，George 推广了 TinyGrad，希望它成为科技领域的重要竞争者，并最终在多个领域进行创新，从 GPU 开始扩展到自我复制的机器人。"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio 和 Swyx 感谢 George 的见解。"
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls7-img5",
            "height": 936,
            "width": 936,
            "filename": "abls7-img5.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692158781-abls7-img5.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "tiny corp 的 George Hotz 挑战 Nvidia 和 Google！AMD 合作、ggml、Mojo、Elon 和 GPT-4 的见解，以及 AI 女友的窥探。",
      "title": "潜在空间播客 2023年6月20日 [摘要] - George Hotz",
      "twitterCard": null,
      "image": {
        "width": 1586,
        "height": 508,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      }
    }
  },
  "topics": [
    "Hardware",
    "LLM",
    "Summary"
  ]
}