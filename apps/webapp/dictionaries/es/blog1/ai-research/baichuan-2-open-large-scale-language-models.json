{
  "relatedBlogs": [],
  "blogContent": {
    "id": "198277345",
    "topics": [
      "LLM",
      "Multilingüe"
    ],
    "title": "Baichuan 2: Modelos de Lenguaje a Gran Escala Abiertos",
    "slug": "baichuan-2-open-large-scale-language-models",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2024-05-24T05:59:10+01:00",
    "description": "Comentario Abstracto y Calificación",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Publicado el 18 de sep"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Autores:Aiyuan Yang,"
                    },
                    {
                      "url": "https://huggingface.co/BinXiao",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Bin Xiao"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Bingning Wang,Borong Zhang,Chao Yin,Chenxu Lv,Da Pan,"
                    },
                    {
                      "url": "https://huggingface.co/wangdianhellen",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Dian Wang"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Dong Yan,Fan Yang,Fei Deng,Feng Wang,Feng Liu,Guangwei Ai,Guosheng Dong Haizhou Zhao,Hang Xu,Haoze Sun,"
                    },
                    {
                      "url": "https://huggingface.co/hongdaaaaaaaa",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Hongda Zhang"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Hui Liu,"
                    },
                    {
                      "url": "https://huggingface.co/jijiaming",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Jiaming Ji"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/hsaest",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Jian Xie"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/calico-1226",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Juntao Dai"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": "+30 autores"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Resumen"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Los modelos de lenguaje a gran escala (LLM) han demostrado un rendimiento notable en una variedad de tareas de lenguaje natural basadas en solo unos pocos ejemplos de instrucciones de lenguaje natural, reduciendo la necesidad de una ingeniería de características extensa. Sin embargo, la mayoría de los LLM más poderosos son de código cerrado o tienen capacidades limitadas para idiomas distintos del inglés. En este informe técnico, presentamos Baichuan 2, una serie de modelos de lenguaje multilingües a gran escala que contienen 7 mil millones y 13 mil millones de parámetros, entrenados desde cero, en 2.6 billones de tokens. Baichuan 2 iguala o supera a otros modelos de código abierto de tamaño similar en benchmarks públicos como MMLU, CMMLU, GSM8K y HumanEval. Además, Baichuan 2 sobresale en dominios verticales como la medicina y el derecho. Publicaremos todos los puntos de control del modelo de preentrenamiento para beneficiar a la comunidad investigadora en la mejor comprensión de la dinámica de entrenamiento de Baichuan 2."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.10305",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Ver página de arXiv"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.10305",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Ver PDF"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Comentario"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "El artículo \"Baichuan 2: Modelos de Lenguaje a Gran Escala Abiertos\" introduce una serie de modelos de lenguaje multilingües a gran escala y enfatiza sus capacidades en diversas tareas, incluidas aplicaciones específicas de dominio como la medicina y el derecho."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Puntos Clave:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "LLM Multilingüe"
                            },
                            {
                              "type": "span",
                              "value": ": Baichuan 2 es multilingüe, lo que lo hace adecuado para tareas en múltiples idiomas, abordando la limitación de otros LLM poderosos que se centran principalmente en el inglés."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Escala Significativa"
                            },
                            {
                              "type": "span",
                              "value": ": El modelo cuenta con 7 mil millones y 13 mil millones de parámetros y fue entrenado en 2.6 billones de tokens, lo que lo convierte en un LLM poderoso."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Rendimiento en Benchmarks"
                            },
                            {
                              "type": "span",
                              "value": ": Baichuan 2 tiene un rendimiento competitivo en benchmarks públicos, igualando o incluso superando a otros modelos de código abierto de tamaño similar."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Especialización en Dominios"
                            },
                            {
                              "type": "span",
                              "value": ": El modelo muestra excelencia en dominios verticales como la medicina y el derecho, lo que indica su versatilidad."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Disponibilidad de Código Abierto"
                            },
                            {
                              "type": "span",
                              "value": ": Se publicarán todos los puntos de control del modelo de preentrenamiento, ayudando a la comunidad investigadora a comprender la dinámica de entrenamiento de Baichuan 2."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Impacto Potencial en el Mundo Real:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Amplia Aplicabilidad"
                            },
                            {
                              "type": "span",
                              "value": ": La naturaleza multilingüe de Baichuan 2 le permite aplicarse a diversas tareas en diferentes idiomas, convirtiéndolo en una herramienta versátil en el ecosistema global de PLN."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Dominios de Alto Valor"
                            },
                            {
                              "type": "span",
                              "value": ": La excelencia del modelo en dominios como la medicina y el derecho puede allanar el camino para aplicaciones específicas de dominio, como el análisis de documentos legales o la asistencia en diagnósticos médicos basados en datos textuales."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Impulso a la Investigación"
                            },
                            {
                              "type": "span",
                              "value": ": La naturaleza de código abierto del modelo probablemente fomentará más investigación para comprender y mejorar los LLM a gran escala, empujando los límites de lo que pueden lograr."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Reducción de la Ingeniería de Características"
                            },
                            {
                              "type": "span",
                              "value": ": Dado su rendimiento con ejemplos mínimos, Baichuan 2 puede reducir significativamente la necesidad de ingeniería de características en tareas de PLN, simplificando los procesos de desarrollo de modelos."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Desafíos:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Intensidad de Recursos"
                            },
                            {
                              "type": "span",
                              "value": ": Tales modelos grandes a menudo conllevan altos costos computacionales, lo que hace que su implementación en tiempo real en ciertos entornos sea un desafío."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                {
                                  "0": "s",
                                  "1": "t",
                                  "2": "r",
                                  "3": "o",
                                  "4": "n",
                                  "5": "g"
                                }
                              ],
                              "value": "Posibles Sesgos"
                            },
                            {
                              "type": "span",
                              "value": ": Al igual que otros LLM, el riesgo de sesgos inherentes en los datos de entrenamiento podría manifestarse en las salidas del modelo, especialmente dado su tamaño."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dada la escala significativa del modelo, sus capacidades multilingües, su alto rendimiento en benchmarks y su excelencia en dominios específicos:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Calificaría el impacto en el mundo real de este artículo como un 9 de 10."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Baichuan 2 aborda una brecha crítica en el espacio de los LLM al proporcionar un modelo multilingüe poderoso. Su rendimiento competitivo, combinado con el potencial para aplicaciones específicas de dominio, lo convierte en una contribución impactante al campo del PLN."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Comentario Abstracto y Calificación\n",
      "title": "Baichuan 2: Modelos de Lenguaje a Gran Escala Abiertos",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Multilingual"
  ]
}