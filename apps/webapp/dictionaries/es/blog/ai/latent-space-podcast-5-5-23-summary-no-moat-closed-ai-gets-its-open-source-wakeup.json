{
  "relatedBlogs": [
    {
      "id": "190259319",
      "topics": [
        "Resumen",
        "LLM",
        "Entrenamiento"
      ],
      "title": "Podcast de Latent Space 16/8/23 [Resumen] - Las Matemáticas del Entrenamiento de LLMs — con Quentin Anthony de Eleuther AI",
      "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:19:45+01:00",
      "description": "Explora las matemáticas detrás del entrenamiento de LLMs con Quentin Anthony de Eleuther AI. Sumérgete en el artículo Transformers Math 101 y domina las técnicas de entrenamiento distribuido para un rendimiento óptimo de GPU.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 16/8/23 [Resumen] Matemáticas del Entrenamiento de LLMs",
        "description": "Sumérgete en el artículo Transformers Math 101 y domina las técnicas de entrenamiento distribuido para un rendimiento óptimo de GPU."
      }
    },
    {
      "id": "190259129",
      "topics": [
        "LLM",
        "Hardware",
        "Resumen",
        "Edge"
      ],
      "title": "Podcast de Latent Space 10/8/23 [Resumen]: LLMs en Todas Partes: Ejecutando modelos de 70B en navegadores y iPhones usando MLC — con Tianqi Chen de CMU / OctoML",
      "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:18:37+01:00",
      "description": "Explora la magia de MLC con Tianqi Chen: desplegando modelos de 70B en navegadores y iPhones. Sumérgete en XGBoost, la creación de TVM y el futuro de los despliegues universales de IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      },
      "seo": {
        "title": "Latent Space 10/8/23 [Resumen]: LLMs en Todas Partes",
        "description": "Explora el despliegue de modelos de 70B en navegadores y iPhones. Sumérgete en XGBoost, la creación de TVM y el futuro de los despliegues universales de IA."
      }
    },
    {
      "id": "190259087",
      "topics": [
        "Resumen",
        "LLM",
        "Código",
        "Código Abierto",
        "Modelos Pequeños"
      ],
      "title": "Podcast de Latent Space 4/8/23 [Resumen] Latent Space x AI Breakdown crossover pod!",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "Únete a AI Breakdown y Latent Space para el resumen de tecnología de IA del verano: Sumérgete en GPT4.5, Llama 2, herramientas de IA, el creciente ingeniero de IA y más!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 4/8/23 [Resumen] crossover de AI Breakdown",
        "description": "Sumérgete en GPT4.5, Llama 2, herramientas de IA, el creciente ingeniero de IA y más!"
      }
    },
    {
      "id": "190259111",
      "topics": [
        "Resumen",
        "Transformers",
        "Entrenamiento",
        "Código Abierto"
      ],
      "title": "Podcast de Latent Space 26/7/23 [Resumen] FlashAttention 2: haciendo los Transformers 800% más rápidos - Tri Dao de Together AI",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "Descubre cómo FlashAttention revolucionó la velocidad de la IA con Tri Dao, mientras revela el poder de FlashAttention 2, se sumerge en el Hazy Lab de Stanford y ofrece perspectivas futuras sobre la IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 26/7/23 [Resumen] FlashAttention 2",
        "description": "Descubre cómo FlashAttention revolucionó la velocidad de la IA con Tri Dao, mientras revela el poder de FlashAttention 2"
      }
    },
    {
      "id": "190259172",
      "topics": [
        "Resumen",
        "LLM",
        "Código Abierto",
        "Modelos Pequeños"
      ],
      "title": "Podcast de Latent Space 19/7/23 [Resumen] - Llama 2: El Nuevo SOTA de LLM Abierto (con Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog y otros)",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "Explora Llama 2, el último avance en IA con expertos Nathan Lambert, Matt Bornstein y más. Sumérgete en conjuntos de datos, benchmarks y predicciones de IA. ¡Perspectivas y drama de Llama te esperan en este podcast top!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 19/7/23 [Resumen] - Llama 2",
        "description": "Sumérgete en conjuntos de datos, benchmarks y predicciones de IA. ¡Perspectivas y drama de Llama te esperan en este podcast top!"
      }
    },
    {
      "id": "190259191",
      "topics": [
        "Resumen",
        "Código",
        "LLM"
      ],
      "title": "Podcast de Latent Space 10/7/23 [Resumen] - Intérprete de Código == GPT 4.5 (con Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley y otros)",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "Explora el Intérprete de Código de ChatGPT: un cambio de juego en la IA. Sumérgete en su salto de capacidades de 1000x con Simon, Alex y los principales expertos en IA. #InferenciaAumentadaPorCódigo #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space [Resumen] Intérprete de Código = GPT 4.5",
        "description": "Explora el Intérprete de Código de ChatGPT: un cambio de juego en la IA. Sumérgete en su salto de capacidades de 1000x con Simon, Alex y los principales expertos en IA."
      }
    },
    {
      "id": "190259216",
      "topics": [
        "Resumen",
        "Código Abierto"
      ],
      "title": "Podcast de Latent Space 2/7/23 [Resumen] Tendencias de IA: un crossover de Latent Space x Practical AI!",
      "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:08:36+01:00",
      "description": "Explora la fusión de Practical AI y Latent Space mientras profundizan en las principales tendencias de IA de 2023, reflexionan sobre episodios destacados y comparten perspectivas sobre cómo navegar la evolución de la IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 2/7/23 [Resumen] Tendencias de IA",
        "description": "Las principales tendencias de IA de 2023, reflexionan sobre episodios destacados y comparten perspectivas sobre cómo navegar la evolución de la IA."
      }
    },
    {
      "id": "190259238",
      "topics": [
        "Hardware",
        "LLM",
        "Resumen"
      ],
      "title": "Podcast de Latent Space 20/6/23 [Resumen] - Commoditizando el Petaflop — con George Hotz de tiny corp",
      "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:07:15+01:00",
      "description": "¡George Hotz de tiny corp desafía a Nvidia y Google! Sumérgete en el mundo de las colaboraciones con AMD, perspectivas sobre ggml, Mojo, Elon y GPT-4, además de un vistazo a la Novia de IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 20/6/23 [Resumen] - George Hotz",
        "description": "¡George Hotz de tiny corp desafía a Nvidia y Google! Colaboraciones con AMD, perspectivas sobre ggml, Mojo, Elon y GPT-4, además de un vistazo a la Novia de IA."
      }
    },
    {
      "id": "190259294",
      "topics": [
        "LLM",
        "Funciones",
        "Resumen"
      ],
      "title": "Podcast de Latent Space 14/6/23 [Resumen] - Pod de Emergencia: La nueva API de Funciones de OpenAI, Reducción de Precio del 75%, 4x Longitud de Contexto (con Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin y otros)",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "Explora las actualizaciones de OpenAI de junio de 2023 con los principales ingenieros de IA de Scale, Microsoft, Pinecone y Huggingface. Sumérgete en los paradigmas de Código x LLM y descubre los Agentes de Función Recursiva.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 20/6/23 [Resumen] - Pod de Emergencia",
        "description": "Explora las actualizaciones de OpenAI de junio de 2023 con los principales ingenieros de IA de Scale, Microsoft, Pinecone y Huggingface."
      }
    },
    {
      "id": "190259333",
      "topics": [
        "LLM",
        "Resumen",
        "UX"
      ],
      "title": "Podcast de Latent Space 8/6/23 [Resumen] - De RLHF a RLHB: El Caso de Aprender del Comportamiento Humano - con Jeffrey Wang y Joe Reeve de Amplitude",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "Explora la IA y la analítica con Jeffrey Wang y Joe Reeve en Latent Space Live! Sumérgete en por qué la IA valora la Analítica y el poder de los datos de comportamiento de primera mano.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 8/6/23 [Resumen] - De RLHF a RLHB",
        "description": "Explora la IA y la analítica con Jeffrey Wang y Joe Reeve en Latent Space Live! Sumérgete en por qué la IA valora la Analítica y el poder de los datos de comportamiento de primera mano."
      }
    },
    {
      "id": "190260528",
      "topics": [
        "Resumen",
        "LLM",
        "UX"
      ],
      "title": "Podcast de Latent Space 1/6/23 [Resumen] - Construyendo el Scenius de IA × UX — con Linus Lee de Notion AI",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "Explora el enfoque transformador de Notion AI hacia la IA y la UX. Sumérgete en el futuro de los espacios de trabajo aumentados por IA, el valor más allá de las interfaces de chat y perspectivas sobre el trabajo del conocimiento efectivo. ¡Incluye resumen del meetup AI×UX NYC!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 1/6/23 [Resumen] - Scenius de IA × UX",
        "description": "Explora el enfoque transformador de Notion AI hacia la IA y la UX."
      }
    },
    {
      "id": "190260557",
      "topics": [
        "Resumen",
        "Código",
        "LLM",
        "Agentes"
      ],
      "title": "Podcast de Latent Space 25/5/23 [Resumen] - Depurando Internet con agentes de IA – con Itamar Friedman de Codium AI y AutoGPT",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "Explora el futuro de la IA con Itamar Friedman de Codium AI en 'Depurando Internet'. Sumérgete en los agentes 'DRY Extremo', la rápida sincronización de especificaciones y pruebas, y el equilibrio entre código y pruebas. Además, perspectivas de Toran y una mirada exclusiva al roadmap de AutoGPT!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "seo": {
        "title": "Pod de Latent Space 25/5/23 [Resumen] Depurando Internet",
        "description": "Sumérgete en los agentes 'DRY Extremo', la rápida sincronización de especificaciones y pruebas, y el equilibrio entre código y pruebas."
      }
    },
    {
      "id": "190260577",
      "topics": [
        "LLM",
        "Modelos Pequeños"
      ],
      "title": "Podcast de Latent Space 20/5/23 [Resumen] - MPT-7B y El Comienzo de Contexto=Infinito — con Jonathan Frankle y Abhinav Venigalla de MosaicML",
      "slug": "latent-space-podcast-5-20-23-summary-mpt-7b-and-the-beginning-of-context-infinity",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:57:33+01:00",
      "description": "Sumérgete en el entrenamiento de 9 días y $200k del \"llongboi\" MPT-7B de MosaicML, perspectivas sobre la preparación de datos y el auge de los modelos de IA abiertos con los expertos Frankle y Venigalla.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 25/6/23 [Resumen] MosaicML",
        "description": "Sumérgete en el entrenamiento de 9 días y $200k del \"llongboi\" MPT-7B de MosaicML, perspectivas sobre la preparación de datos y el auge de los modelos de IA abiertos"
      }
    },
    {
      "id": "190260597",
      "topics": [
        "LLM",
        "Datos Estructurados"
      ],
      "title": "Podcast de Latent Space 15/5/23 [Resumen] - Calidad y estructura garantizadas en las salidas de LLM - con Shreya Rajpal de Guardrails AI",
      "slug": "latent-space-podcast-5-15-23-summary-guaranteed-quality-and-structure-in-llm-outp",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:56:26+01:00",
      "description": "Explora el Ep. 12 con Shreya Rajpal de Guardrails AI: Sumérgete en la validación de salidas de LLM, refinando respuestas a través de bucles de re-pregunta y estableciendo SLAs para modelos. Domina los matices de la garantía de calidad de IA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 15/5/23 [Resumen] Calidad de Salidas de LLM",
        "description": "Explora el Ep. 12 con Shreya Rajpal de Guardrails AI: Sumérgete en la validación de salidas de LLM."
      }
    },
    {
      "id": "190260606",
      "topics": [
        "LLM",
        "Entrenamiento",
        "Agentes",
        "Multimodal"
      ],
      "title": "Podcast de Latent Space 8/5/23 [Resumen] - El Gen Fundador de IA: Ser Temprano, Construir Rápido y Creer en la Grandeza — con Sharif Shameem de Lexica",
      "slug": "latent-space-podcast-5-8-23-summary-the-ai-founder-gene-being-early-building-fast",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:52:09+01:00",
      "description": "Ep.11 con Sharif Shameem de Lexica: Sumérgete en la mentalidad del fundador de IA, descubriendo los secretos para innovar, construir tecnología revolucionaria, entrenar modelos y el intrigante potencial de los Agentes y la secuenciación genómica.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
      },
      "seo": {
        "title": "Pod de Latent Space 8/5/23 [Resumen] El Gen Fundador de IA",
        "description": "Ep.11 con Sharif Shameem de Lexica: Sumérgete en la mentalidad del fundador de IA, descubriendo los secretos para innovar."
      }
    },
    {
      "id": "190260671",
      "topics": [
        "LLM",
        "Código",
        "Resumen"
      ],
      "title": "Podcast de Latent Space 3/5/23 [Resumen] - Entrenando un LLM de Código SOTA en 1 semana y Cuantificando las Vibras — con Reza Shabani de Replit",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "Ep. 10 con Reza Shabani: Sumérgete en el rápido entrenamiento de un LLM de Código de última generación, explora el futuro de Replit Ghostwriter y el viaje de Finanzas a IA. Descubre la transición de Kaplan a Chinchilla y más!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "seo": {
        "title": "Pod de Latent Space 3/5/23 [Resumen] - LLM de Código SOTA",
        "description": "Ep. 10 con Reza Shabani: Sumérgete en el rápido entrenamiento de un LLM de Código de última generación!"
      }
    },
    {
      "id": "190629271",
      "topics": [
        "LLM",
        "Modelos Pequeños",
        "Resumen"
      ],
      "title": "Podcast de Latent Space 28/4/23 [Resumen] - Mapeando el futuro de los Modelos *realmente* Abiertos y Entrenando a Dolly por $30 — con Mike Conover de Databricks",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "Explora el futuro de los modelos abiertos con Mike Conover de Databricks. Sumérgete en la creación de Dolly, su transición de 1.0 a 2.0 y las influencias detrás de su desarrollo. El Ep.9 toca la infraestructura de modelos, la visión de Databricks y más. #IA #ModelosAbiertos #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "seo": {
        "title": "Pod de Latent Space 28/4/23 [Resumen] - Mike de Databricks",
        "description": "El Ep.9 toca la infraestructura de modelos, la visión de Databricks y más. #IA #ModelosAbiertos #Dolly"
      }
    },
    {
      "id": "191164291",
      "topics": [
        "LLM",
        "Empresa",
        "Resumen"
      ],
      "title": "Podcast de Latent Space 21/4/23 [Resumen] - Búsqueda Potenciada por IA para la Empresa — con Deedy Das de Glean",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "Ep.8: Sumérgete en la IA en la búsqueda empresarial con Deedy Das de Glean. Desentraña los desafíos de crear un gigante de búsqueda de IA, comparaciones entre Google y ChatGPT, las complejidades de la infraestructura de IA, cómo detectar texto generado por IA y por qué las empresas necesitan más que solo QA de Documentos.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 21/4/23 [Resumen] - con Deedy Das",
        "description": "Ep.8: Sumérgete en la IA en la búsqueda empresarial con Deedy Das de Glean. Desentraña los desafíos de crear un gigante de búsqueda de IA, comparaciones entre Google y ChatGPT ..."
      }
    },
    {
      "id": "191165673",
      "topics": [
        "Resumen",
        "Visión"
      ],
      "title": "Podcast de Latent Space 13/4/23 [Resumen] - Modelo Segment Anything y los Problemas Difíciles de la Visión por Computadora — con Joseph Nelson de Roboflow",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "Explora el Ep.7 con Joseph Nelson sobre el Modelo Segment Anything de Meta. Sumérgete en el futuro de la Visión por Computadora, la importancia del OCR, la Segmentación de Imágenes y más. #Roboflow #IA",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "seo": {
        "title": "Podcast de Latent Space 13/4/23 [Resumen] - Segment Anything",
        "description": "Sumérgete en el futuro de la Visión por Computadora, la importancia del OCR, la Segmentación de Imágenes y más. #Roboflow #IA"
      }
    }
  ],
  "blogContent": {
    "id": "190260640",
    "topics": [
      "Resumen",
      "Código Abierto",
      "LLM"
    ],
    "title": "Podcast de Latent Space 5/5/23 [Resumen] - Sin Foso: La IA Cerrada recibe su llamada de atención de Código Abierto — con Simon Willison",
    "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T08:49:18+01:00",
    "description": "Explora 'Sin Foso: El Despertar de Código Abierto de la IA Cerrada' con Simon Willison. Sumérgete en las ideas del memo filtrado de Google Moat, la fuga de cerebros de Google y el aumento de velocidad de Python con Mojo.",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Enlace Original: Sin Foso: "
                    },
                    {
                      "url": "https://www.latent.space/p/no-moat#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "La IA Cerrada recibe su llamada de atención de Código Abierto — con Simon Willison"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Resumen"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 3,
                  "children": [
                    {
                      "type": "span",
                      "value": "Modelos de IA de Código Abierto Desafían a los Gigantes Tecnológicos"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "\nEl Memo de Google y el Auge del Código Abierto"
                    },
                    {
                      "type": "span",
                      "value": " Simon Willison destacó un memo filtrado titulado \"No Tenemos Foso y OpenAI Tampoco\" sugiriendo que mientras Google y OpenAI están construyendo modelos de lenguaje más grandes, los proyectos de código abierto están alcanzándolos rápidamente. Mencionó a Lama de Facebook como un hito y a Alpaca de Stanford como una mejora sustancial. El memo argumenta en contra de la creencia de que los modelos más grandes significan más poder, sugiriendo en cambio que los modelos más pequeños y flexibles podrían ser el futuro. Se destacó la alta calidad y riqueza del análisis dentro del memo."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Código Abierto vs. Sistemas Cerrados"
                    },
                    {
                      "type": "span",
                      "value": " swyx comentó cómo tradicionalmente, la narrativa era que el código abierto quedaría rezagado detrás de los sistemas cerrados porque los sistemas cerrados podían adoptar del abierto. Sin embargo, este memo sugiere que ahora está ocurriendo lo contrario, con el código abierto superando a los modelos cerrados. Travis Fischer hizo eco de este sentimiento, señalando que el ritmo rápido de los avances en IA solo podría ser igualado por el código abierto. Cuestionó la verdadera ventaja competitiva cuando los modelos se convierten en productos básicos y cómo empresas como Google pueden interactuar con el código abierto sin comprometer su posición en el mercado."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Infraestructura y Practicidad"
                    },
                    {
                      "type": "span",
                      "value": " Alessio Fanelli argumentó que, aunque construir el mejor modelo es esencial, es igualmente crucial considerar la infraestructura alrededor de la ejecución de estos modelos. Aunque muchas herramientas de código abierto están disponibles gratuitamente, el costo y la experiencia necesarios para ejecutarlas podrían ser prohibitivos para muchos."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Ejecutando Modelos en Dispositivos"
                    },
                    {
                      "type": "span",
                      "value": " Simon discutió las capacidades de los modelos actuales, particularmente cómo pueden ejecutarse en dispositivos personales. Citó a Vicuna 13B, un modelo derivado de Lama de Facebook, como un ejemplo de un modelo que se ejecuta directamente en el navegador. También mencionó las técnicas emergentes para comprimir estos modelos, haciéndolos aún más accesibles para dispositivos cotidianos."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "El Foso de Google y Direcciones Futuras"
                    },
                    {
                      "type": "span",
                      "value": " swyx planteó una pregunta sobre el aparente pánico de Google, considerando sus vastos recursos y base de usuarios existente con herramientas como Google Calendar, Docs y más. Se preguntó por qué, dadas estas ventajas, hay un sentido de urgencia dentro de Google con respecto a los avances de la IA de código abierto."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "A lo largo de la discusión, el tema subyacente fue la dinámica cambiante entre los sistemas cerrados y el mundo de código abierto en rápida evolución en la IA. Se debatieron los rápidos avances del código abierto, la posibilidad de habilidades 'instalables' en modelos y la posición de Google en este panorama cambiante."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-20-at-5-25-53-pm",
            "height": 532,
            "width": 1602,
            "filename": "screenshot-2023-08-20-at-5-25-53-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "El Paisaje Competitivo de la IA: Fuga de Talentos, Bucles de Datos y la Promesa de LoRA"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Travis Fischer tocó un desafío significativo enfrentado por empresas como Google: retener a los mejores talentos. Cuando la percepción es que están rezagados en los avances, sus mejores investigadores pueden considerar oportunidades en otros lugares, como OpenAI o instituciones académicas. Sin embargo, Fischer argumentó que Google, con sus vastos recursos, no debe ser subestimado y tiene el potencial de recuperar el impulso."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio Fanelli destacó la importancia de los datos de alta calidad. Mientras Google posee vastas cantidades de datos de sus plataformas, las startups enfrentan la tarea desalentadora de acumular suficientes datos de alta calidad para competir. La idea no es tener la mayor cantidad de datos, sino tener el tipo correcto de datos. Aquí es donde los bucles de datos de primera parte se vuelven cruciales."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Simon Willison y swyx discutieron la aparición de los Modelos de Código Abierto que se entrenan con datos disponibles públicamente, reduciendo la dependencia de conjuntos de datos propietarios a gran escala. Se adentraron en el concepto de LoRA (Adaptación de Rango Inferior), una técnica donde una parte del modelo se congela y solo se entrena un segmento más pequeño, ahorrando costos computacionales y tiempo. Sin embargo, estos LoRA están vinculados a versiones específicas del modelo, planteando la cuestión de la compatibilidad y la relevancia de reentrenar constantemente los modelos base."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "En conclusión, el panorama de la IA está evolucionando rápidamente, con el enfoque cambiando del tamaño puro de los datos y modelos a la calidad y adaptabilidad de los modelos. Queda por ver qué estrategias resultarán más exitosas a largo plazo."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img2",
            "height": 930,
            "width": 930,
            "filename": "abls16-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568229-abls16-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "El Poder de los Modelos de IA Optimizados y los Superconjuntos de Lenguaje"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Modelos Optimizados"
                            },
                            {
                              "type": "span",
                              "value": ": Simon Willison y Travis Fischer discutieron la necesidad de modelos de IA especializados que puedan ejecutarse directamente en dispositivos sin requerir llamadas a API externas, especialmente en contextos críticos donde la precisión y la velocidad son vitales, como en aviones de combate. Los milisegundos pueden hacer la diferencia en tales escenarios, y usar una API externa no es factible."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Mojo - El Próximo Gran Lenguaje de Programación"
                            },
                            {
                              "type": "span",
                              "value": ": Simon presentó \"Mojo\", un lenguaje de programación recién anunciado que actúa como un superconjunto de Python, lo que significa que cualquier código Python funcionará en Mojo. Sin embargo, Mojo introduce características que permiten un código altamente optimizado. Lo que distingue a Mojo es su capacidad para mejorar significativamente el rendimiento del código Python existente, evidenciado por una demostración que aumentó el rendimiento de la multiplicación de matrices en 2000 veces. El lenguaje fue diseñado por Chris Lattner, quien participó en la creación de productos informáticos significativos como LLVM y Swift."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Potencial de los Superconjuntos de Lenguaje"
                            },
                            {
                              "type": "span",
                              "value": ": Un tema planteado por swyx gira en torno al concepto de superconjuntos de lenguaje y su potencial transformador. Expresó intriga sobre por qué la idea de Mojo no se concibió antes, dado el concepto existente de superconjuntos de lenguaje. Simon explicó que Mojo se construyó sobre una plataforma llamada MLIR, otro proyecto de Lattner optimizado para múltiples núcleos y acceso a GPU. Esto le dio a Mojo una base robusta sobre la cual construir. La capacidad de mejorar el rendimiento mientras se permanece en un ecosistema familiar (como Python) fue destacada como su característica sobresaliente."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Google y la Estrategia de IA"
                            },
                            {
                              "type": "span",
                              "value": ": La conversación se trasladó a movimientos estratégicos en el espacio de la IA. Hubo indicios de que Facebook podría liberar oficialmente los pesos de Lama, un desarrollo significativo que podría influir en el panorama de la IA."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "La discusión en general tocó la importancia de la optimización de la IA, la introducción y el potencial del lenguaje de programación Mojo, y los movimientos estratégicos de los gigantes tecnológicos en el dominio de la IA."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img3",
            "height": 930,
            "width": 930,
            "filename": "abls16-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568243-abls16-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google y el Panorama de la IA"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Fuga de Google Confirmada"
                    },
                    {
                      "type": "span",
                      "value": ": Simon Willison reveló que los informantes han confirmado la legitimidad de un documento filtrado de Google."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "El Modelo de Anuncios de Google en Riesgo"
                    },
                    {
                      "type": "span",
                      "value": ": Tanto Simon como swyx discutieron cómo ChatGPT y otros chatbots que no sirven anuncios podrían representar una amenaza para el modelo de ingresos basado en anuncios de Google. También tocaron el futuro de los modelos de chat con soporte publicitario como un prototipo de Bing con anuncios."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Preocupaciones de Seguridad en IA"
                    },
                    {
                      "type": "span",
                      "value": ":"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Simon distinguió entre preocupaciones de \"ciencia ficción\" de la IA, como que se vuelva contra los humanos, y amenazas inmediatas, como el uso indebido de la IA para estafas. Destacó particularmente el riesgo de estafas románticas habilitadas por IA."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "Las discusiones insinuaron una corriente subyacente de inquietud entre las figuras clave de la industria sobre la seguridad de la IA."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "value": "swyx sugirió que Simon podría documentar amenazas reales, no de ciencia ficción, planteadas por la IA hoy en día."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Inyección de Prompts"
                    },
                    {
                      "type": "span",
                      "value": ": Simon expresó preocupación por el riesgo actual de la IA, donde los sistemas podrían ser fácilmente manipulados por atacantes. swyx sugirió humorísticamente que las personas podrían comenzar a incorporar \"inyecciones de prompts\" en sus biografías para detectar el raspado de IA."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Google vs. OpenAI"
                    },
                    {
                      "type": "span",
                      "value": ": El documento indicó que podría haber preocupaciones internas dentro de Google sobre la competencia en IA. swyx sintió que el documento proporcionaba una visión de los sentimientos internos de Google. El debate también tocó la afirmación de que OpenAI, a pesar de sus innovaciones, carecía de una ventaja competitiva sostenible o \"foso\"."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "La discusión concluyó con la perspectiva de Travis Fischer sobre la eventual comoditización de los grandes modelos de lenguaje, coincidiendo con el sentimiento del documento sobre la ventaja incierta de OpenAI a largo plazo."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img1",
            "height": 930,
            "width": 930,
            "filename": "abls16-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568257-abls16-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Innovaciones y Preocupaciones en IA: Un Diálogo con Simon Willison y Travis Fischer"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Simon Willison discutió el desafío planteado a su proyecto de código abierto \"datasets\" por las capacidades de Chat GPT, que podría realizar muchas de las tareas que había planeado para el futuro del proyecto. No obstante, enfatizó la creciente convergencia de datos e IA y promovió su blog, simonwillis.net, y su boletín que actualiza sobre los avances en IA."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Travis Fischer anunció la fundación de su nueva empresa, con el objetivo de desarrollar un marco para crear agentes de IA confiables para casos de uso específicos. Comparó los proyectos de IA más amplios con las complejidades de los vehículos autónomos y mencionó su deseo de construir a partir de primitivas confiables y fundamentales. Además, mencionó el éxito de su bot de Twitter Chat PT, que ha acumulado más de 125,000 seguidores y ha sido patrocinado por OpenAI, después de una breve alteración de marca."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "La conversación concluyó con swyx destacando los límites cambiantes en el uso de la IA y los derechos de autor, y expresando gratitud a los contribuyentes y la audiencia por su participación."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls16-img4",
            "height": 930,
            "width": 930,
            "filename": "abls16-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692568279-abls16-img4.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Explora 'Sin Foso: El Despertar de Código Abierto de la IA Cerrada' con Simon Willison. Sumérgete en las ideas del memo filtrado de Google Moat.",
      "title": "Podcast de Latent Space 5/5/23 [Resumen] - Sin Foso",
      "twitterCard": null,
      "image": {
        "width": 1602,
        "height": 532,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      }
    }
  },
  "topics": [
    "Summary",
    "Open Source",
    "LLM"
  ]
}