{
  "relatedBlogs": [],
  "blogContent": {
    "id": "198277277",
    "topics": [
      "LLM",
      "Compresión"
    ],
    "title": "El Modelado del Lenguaje es Compresión",
    "slug": "language-modeling-is-compression",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2024-05-25T03:37:32+01:00",
    "description": "Comentario Abstracto y Calificación",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Publicado el 19 de Sep"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Autores:Grégoire Delétang,Anian Ruoss,"
                    },
                    {
                      "url": "https://huggingface.co/padqn",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Paul-Ambroise Duquenne"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Elliot Catt,Tim Genewein,Christopher Mattern,Jordi Grau-Moya,Li Kevin Wenliang,Matthew Aitchison,"
                    },
                    {
                      "url": "https://huggingface.co/lorseau",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Laurent Orseau"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",Marcus Hutter,Joel Veness"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Resumen"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Hace tiempo que se estableció que los modelos predictivos pueden transformarse en compresores sin pérdida y viceversa. Por cierto, en los últimos años, la comunidad de aprendizaje automático se ha centrado en entrenar modelos (de lenguaje) auto-supervisados cada vez más grandes y poderosos. Dado que estos grandes modelos de lenguaje exhiben impresionantes capacidades predictivas, están bien posicionados para ser fuertes compresores. En este trabajo, abogamos por ver el problema de la predicción a través del lente de la compresión y evaluamos las capacidades de compresión de grandes modelos (fundacionales). Mostramos que los grandes modelos de lenguaje son poderosos predictores de propósito general y que el punto de vista de la compresión proporciona nuevas ideas sobre las leyes de escalado, la tokenización y el aprendizaje en contexto. Por ejemplo, Chinchilla 70B, aunque entrenado principalmente en texto, comprime parches de ImageNet al 43.4% y muestras de LibriSpeech al 16.4% de su tamaño bruto, superando a compresores específicos de dominio como PNG (58.5%) o FLAC (30.3%), respectivamente. Finalmente, mostramos que la equivalencia predicción-compresión nos permite usar cualquier compresor (como gzip) para construir un modelo generativo condicional."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.10668",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Ver página de arXiv"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.10668",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Ver PDF"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Comentario"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "El artículo \"El Modelado del Lenguaje es Compresión\" revisita el concepto bien establecido de que los modelos predictivos también pueden aprovecharse como compresores sin pérdida y evalúa cómo esta idea puede aplicarse a los modelos de lenguaje modernos y a gran escala."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Puntos Clave:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Compresión como Predicción"
                            },
                            {
                              "type": "span",
                              "value": ": El artículo impulsa la idea de usar modelos predictivos (como los modernos LLMs) como compresores eficientes. Dadas sus fuertes capacidades predictivas, estos modelos pueden comprimir una amplia gama de tipos de datos."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Compresores de Propósito General"
                            },
                            {
                              "type": "span",
                              "value": ": La investigación indica que los grandes modelos de lenguaje, incluso si se entrenan principalmente en texto, pueden comprimir datos no textuales de manera eficiente. Por ejemplo, Chinchilla 70B puede comprimir imágenes de ImageNet y muestras de audio de LibriSpeech mejor que compresores específicos de dominio como PNG y FLAC."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Obteniendo Ideas"
                            },
                            {
                              "type": "span",
                              "value": ": Ver la predicción desde una perspectiva de compresión puede proporcionar ideas sobre varios aspectos del aprendizaje automático, como las leyes de escalado, la tokenización y el aprendizaje en contexto."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Modelos Generativos a partir de Compresores"
                            },
                            {
                              "type": "span",
                              "value": ": La equivalencia de predicción y compresión permite la creación de modelos generativos condicionales usando cualquier compresor."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Impacto Potencial en el Mundo Real:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Almacenamiento y Transferencia de Datos"
                            },
                            {
                              "type": "span",
                              "value": ": Si los LLMs pueden usarse efectivamente como compresores, pueden revolucionar el almacenamiento y la transmisión de datos, particularmente para medios ricos como imágenes y audio."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Más Allá del Texto"
                            },
                            {
                              "type": "span",
                              "value": ": Demostrar que un modelo entrenado en texto puede comprimir datos no textuales abre puertas a aplicaciones multimodales y muestra la capacidad de generalización de los LLMs modernos."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Mejor Comprensión de los LLMs"
                            },
                            {
                              "type": "span",
                              "value": ": La perspectiva de la compresión puede proporcionar ideas más profundas sobre el funcionamiento y las posibles aplicaciones de los grandes modelos de lenguaje."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Aplicaciones Generativas"
                            },
                            {
                              "type": "span",
                              "value": ": La capacidad de transformar cualquier compresor en un modelo generativo condicional puede tener amplias implicaciones en tareas de generación, síntesis y aumento de datos."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Desafíos:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Recursos Computacionales"
                            },
                            {
                              "type": "span",
                              "value": ": Usar grandes modelos de lenguaje como compresores puede ser computacionalmente costoso, haciéndolos menos accesibles para aplicaciones en tiempo real o para usuarios con recursos limitados."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Experiencia en el Dominio"
                            },
                            {
                              "type": "span",
                              "value": ": Para algunos dominios específicos, los compresores especializados aún pueden ser preferidos debido a las restricciones y requisitos específicos del dominio."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dado el potencial de avances en el almacenamiento de datos, la transmisión y la comprensión más amplia de los LLMs:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Calificaría el impacto en el mundo real de este artículo como un 9 de 10."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "El puente entre predicción y compresión no es completamente nuevo, pero la aplicación del artículo a los LLMs modernos y los resultados que logra son notables. Si estos hallazgos pueden implementarse eficientemente, podría allanar el camino para aplicaciones novedosas y una comprensión más profunda de los modelos de lenguaje."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Comentario Abstracto y Calificación\n",
      "title": "El Modelado del Lenguaje es Compresión",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Compression"
  ]
}