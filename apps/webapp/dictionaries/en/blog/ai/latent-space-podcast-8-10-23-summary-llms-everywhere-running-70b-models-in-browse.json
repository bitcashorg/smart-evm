{
  "relatedBlogs": [
    {
      "id": "190259319",
      "topics": [
        "Summary",
        "LLM",
        "Training"
      ],
      "title": "Latent Space Podcast 8/16/23 [Summary] - The Mathematics of Training LLMs — with Quentin Anthony of Eleuther AI",
      "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:19:45+01:00",
      "description": "Explore the math behind training LLMs with Quentin Anthony from Eleuther AI. Dive into the Transformers Math 101 article & master distributed training techniques for peak GPU performance.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/transformers-math#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "The Mathematics of Training LLMs — with Quentin Anthony of Eleuther AI"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Mathematics Behind Training Large Language Models [Summary]"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In the recent episode of the Latent Space podcast, hosts Alessio and Swyx are joined by Quentin Anthony, an integral figure from Eleuther.ai. They begin by appreciating Eleuther's Transformers Math 101 article, regarded by many as a highly authoritative source for understanding AI's underlying math and the intricacies of training large language models. Quentin elaborates on his journey, from being a PhD student at Ohio State University to joining Eleuther and diving deep into the challenges of distributed AI model training."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Quentin also sheds light on the primary motivation behind writing the article. Despite many in the Deep Learning (DL) space being familiar with the theory of AI, few delve into the practical intricacies—such as understanding how AI inference runs correctly across multiple GPUs. With the article, Eleuther aimed to bridge this gap and share knowledge that would benefit engineers beyond the institution's walls."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Further, Quentin emphasizes the importance of considering not just the dataset but also the computational requirements. This involves taking into account the total computational time and the cost associated with it, making the equation they discuss central to understanding compute requirements. The conversation steers towards the strategies for efficient GPU usage, pointing out the common pitfalls and challenges faced during high-scale deployments."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout, the underlying theme is the need for practical intuition, with Quentin stressing the \"good enough\" approach over chasing perfection. The talk offers a blend of theoretical understanding and pragmatic insights into the world of AI and large model training."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-17-at-9-59-17-pm",
              "height": 554,
              "width": 1576,
              "filename": "screenshot-2023-08-17-at-9-59-17-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Deep Dive into Computational Efficiencies and Memory Requirements in AI Systems"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a detailed discussion:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Forward and Backward Passes"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio questioned why computers have a 2:1 ratio for forward and backward passes (2PD for forward and 4PD for backward). Quentin explained that the forward pass involves simple propagation of inputs through a layer, whereas the backward pass is more complicated, entailing backpropagation."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Deep Learning Math"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx mentioned the efficiency of deep learning mathematics, particularly backpropagation, compared to traditional numerical methods."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Complexities Behind Simple Numbers"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio pointed out that while some math equations appear simple and elegant, the logic behind them can be complex. This sentiment is seen in the public's perception of optimal ratios on platforms like Twitter."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Theoretical vs. Actual FLOPs"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx brought up the distinction between theoretical and actual FLOPs, noting discrepancies in reported values. Quentin explained that theoretical FLOPs are based on hardware expectations, but full utilization doesn't always occur due to synchronization waits, data movement between CPU and GPU, and other delays. He suggests benchmarking expected FLOPs against known GPU capabilities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "GPU Considerations"
                              },
                              {
                                "type": "span",
                                "value": ": The discussion touched on the differences between Nvidia and AMD GPUs. While AMD may offer better theoretical performance, Nvidia's CUDA software and vast open-source support offer practical advantages. Quentin highlighted that the choice often boils down to the efficiency of the software stack and the momentum in the open-source domain."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Memory Requirements and Precision"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio and Swyx delved into memory requirements for training models, particularly focusing on precision and quantization. Quentin explained that transitioning from FP32 to mixed precision, like FP16 and FP32, or BF16 and FP32, often results in more memory usage due to storing both versions of weights. He also emphasized the evolution of precision types in response to hardware advancements, hinting at the future potential of using even smaller representations like INT4."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls9-img1",
              "height": 956,
              "width": 956,
              "filename": "abls9-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692334531-abls9-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Deep Learning Memory Dilemmas: The Adam Optimizer's Challenge"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a discussion about deep learning and optimization methods, Quentin highlighted the RWKV paper as an exploration into achieving Transformer quality without the quadratic attention overhead. The essence of the dialogue revolves around the challenges and intricacies of handling the computational memory requirements of the Adam optimizer. Notably, Quentin points out that while Adam is efficient, it consumes more memory than SGD, particularly three times as much. As a result, distributing memory, especially when dealing with model parallelism and optimizer states, becomes crucial in deep learning operations. Alessio then underlines the memory implications of vanilla Adam, emphasizing that it uses 12 bytes per parameter, which balloons when considering other components like quantization levels. The overarching theme is the quest for efficiency and understanding in the realm of deep learning optimization and memory management."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls9-img2",
              "height": 956,
              "width": 956,
              "filename": "abls9-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692334519-abls9-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Optimizing Memory and Training Models in Deep Learning"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Quentin, Swyx, and Alessio discuss memory challenges and optimizations in training large models."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Key Points:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Model vs. Optimizer Memory:"
                              },
                              {
                                "type": "span",
                                "value": " While most attention is on the model's memory, the optimizer (e.g., Adam) typically requires more memory. It stores momentum, variance, and other parameters. Optimizing the optimizer can yield better memory efficiency than solely focusing on the model."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Memory Components in Training:"
                              },
                              {
                                "type": "span",
                                "value": " When training a model, the main memory components are model parameters, optimizer states, gradients, and activation memory. Activation memory dynamically changes, which can cause unexpected out-of-memory issues."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Activation Recomputation:"
                              },
                              {
                                "type": "span",
                                "value": " To handle memory concerns, some strategies involve recomputing activations rather than storing them. Strategies vary from recomputing everything, selective recomputation based on tensor sizes, or setting a static size threshold for which tensors are stored."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Distributed Training with Zero:"
                              },
                              {
                                "type": "span",
                                "value": " The Zero algorithm optimizes distributed training. It scatters parameters, gradients, and optimizer states across multiple GPUs, then gathers them back during each training step. The aim is to shard the states across GPUs, but this increases communication overhead."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Fine-tuning vs. Training:"
                              },
                              {
                                "type": "span",
                                "value": " While there are established methods and knowledge about training models, fine-tuning presents its challenges. Aspects like learning rate adjustments and transferring datasets are still areas of exploration."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Considerations for Scaling:"
                              },
                              {
                                "type": "span",
                                "value": " The ideal number of GPUs for distributed training varies based on the interconnect speed and the total parameters. Too much sharding can introduce inefficiencies due to synchronization overheads."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion underscores the intricacies of memory management and the importance of optimizing not just model parameters but also other components, like the optimizer, for efficient deep learning."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls9-img3",
              "height": 956,
              "width": 956,
              "filename": "abls9-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692334505-abls9-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Deciphering 3D Parallelism: A Deep Dive into Advanced AI Model Techniques"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a conversation between Alessio, Quentin, and Swyx, the concept of 3D parallelism in AI models is explored."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "3D Parallelism"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "numbered",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "marks": [
                                          "strong"
                                        ],
                                        "value": "Data Parallelism"
                                      },
                                      {
                                        "type": "span",
                                        "value": ": Described as having a copy of the model on each GPU. If two GPUs are present, each has a copy of the model that performs a forward and backward pass, after which they synchronize and average the gradients."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "marks": [
                                          "strong"
                                        ],
                                        "value": "Tensor Parallelism"
                                      },
                                      {
                                        "type": "span",
                                        "value": ": This involves splitting the model. If two GPUs are present, the model is split in the middle, with each GPU operating on its specific tensor. Synchronization between GPUs happens only when necessary."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "marks": [
                                          "strong"
                                        ],
                                        "value": "Pipeline Parallelism"
                                      },
                                      {
                                        "type": "span",
                                        "value": ": Illustratively, if there are four layers in the model and four GPUs, each GPU holds one layer. As each GPU finishes its forward pass, it sends its output to the next GPU in line. The process is reminiscent of a pipeline, hence the name."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Issues & Considerations"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "numbered",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "A potential issue raised is the need for all GPUs to be uniform in their capabilities. Disparity in VRAM between GPUs can lead to bottlenecks. Similarly, having GPUs of varying speeds will lead to synchronization issues, making the system only as fast as the slowest GPU."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Quentin cites a real-world example where nodes had varying network switches, resulting in operations moving at the pace of the slowest switch."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "When asked about the widespread adoption of the techniques discussed, Quentin mentions that while many GPT-based models use this scheme, a pure sharded system seems to be more prevalent as it offers simplicity."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Future Challenges"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "numbered",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Adapting the 3D parallel scheme to new model features, especially with the rise of multimodal models which combine different data types like text and vision."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Communication becoming a bottleneck, especially when transferring data across nodes."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "By the end, Quentin offers to answer further questions on the topic offline and mentions his swift response time on Discord. The talk concludes with Alessio and Swyx thanking Quentin for his insights."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls9-img4",
              "height": 956,
              "width": 956,
              "filename": "abls9-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692334478-abls9-img4.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive into the Transformers Math 101 article & master distributed training techniques for peak GPU performance.",
        "title": "Latent Space Podcast 8/16/23 [Summary] Math of Training LLMs",
        "twitterCard": null,
        "image": {
          "width": 1576,
          "height": 554,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
        }
      }
    },
    {
      "id": "190259087",
      "topics": [
        "Summary",
        "LLM",
        "Code",
        "Open Source",
        "Small Models"
      ],
      "title": "Latent Space Podcast 8/4/23 [Summary] Latent Space x AI Breakdown crossover pod! ",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "Join AI Breakdown & Latent Space for the summer AI tech roundup: Dive into GPT4.5, Llama 2, AI tools, the rising AI engineer, and more!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Original Podcast Link: "
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "url": "https://www.latent.space/p/breakdown#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "[AI Breakdown] Summer AI Technical Roundup: a Latent Space x AI Breakdown crossover pod!"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Podcast Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "[0:00 - 11:51]"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Agenda and Introduction:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "An initial exchange of pleasantries with participants expressing their excitement about the session."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Recognition that the AI audience is diverse, comprising both technical experts in the field and those who are non-technical but keenly aware of the rapid developments in AI. There's a strong interest in understanding the recent trends and major events in AI over the past month, particularly in July."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion of Code Interpreter from OpenAI:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Code Interpreter is initially presented as a chat GPT plugin but has functionalities closer to GPT 4.5. The significant difference it offers from previous models, like the chat GPT, makes it worth noting."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The launch of the Code Interpreter wasn't heavily publicized by OpenAI but has garnered attention for its capabilities, which seem to surpass those of GPT-4. Some speculate it's a step forward but not officially labeled to avoid potential controversies."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Enhancements in GPT 4.5:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Code Interpreter handles non-coding queries and diversifies ChatGPT's coding support."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "While previous models struggled with direct mathematical questions due to how numbers are tokenized, the Code Interpreter overcomes this by focusing on code that can answer such questions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "It caters not just to developers but also non-technical individuals, offering solutions to problems akin to a junior developer or analyst."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The significant distinction between GPT 4.5 and its predecessors is its capability to handle coding tasks effectively."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Shift in AI Development Focus:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The shift from simply using larger datasets for training to focusing on inference time optimizations marks a change in AI development. This is believed to be the direction towards AGI (Artificial General Intelligence)."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "OpenAI's origins in gaming AI and the use of reinforcement learning environments hinted at this trend, where the AI would vary its inference time based on problem complexity."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "GPT 4.5, particularly with the Code Interpreter, is viewed as an evolution that incorporates tools to enhance its capabilities. It is compared to humans evolving and then using tools to achieve tasks that were previously challenging."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Overall, the development and functionality of Code Interpreter represent a shift in AI capabilities, allowing the model to not just be bigger but smarter in its operations."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-08-at-8-02-52-pm",
              "height": 558,
              "width": 1578,
              "filename": "screenshot-2023-08-08-at-8-02-52-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "[11:51 - 19:36]\nPerformance concerns about GPT4: "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's been speculation and research indicating that GPT4's performance might have deteriorated over time or has been intentionally nerfed."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Challenges in Evaluation:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Evaluating the effectiveness of models like GPT4 is difficult, especially for open-ended tasks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Examples of evaluation include assessing if code suggestions in programs like Co-pilot are maintained over time."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's ambiguity in evaluations: e.g., changes in formatting might not necessarily indicate the model's inefficiency."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "With reinforcement learning, it's hard to determine what the model is anchoring on, leading to inconsistencies."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Pressure on OpenAI:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "OpenAI faces the challenge of ensuring safety and providing consistent outputs, especially as they roll out updates."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a suggestion to \"version lock\" the model to better understand its evolution and changes."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Transition of OpenAI:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "OpenAI has evolved from a research lab to a product/infrastructure company, creating challenges in balancing research evolution and product reliability."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's an identified communication challenge within OpenAI: one spokesperson suggests models are static, while another suggests they're updated frequently. This creates confusion among users."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a comparison to Facebook's evolution, where even small algorithmic changes had immediate feedback and ramifications, but OpenAI doesn't receive the same immediate feedback."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Feedback Challenges:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Unlike platforms like Facebook, which could gauge success through metrics like click-through rates, OpenAI has limited immediate feedback mechanisms."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Custom Instructions Feature:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "OpenAI introduced a \"custom instructions\" feature that allows users to personalize GPT-4 more effectively."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "This feature existed in OpenAI's playground and other platforms like Perplexity AI and Character AI. So, while significant for GPT users, it's not a brand-new capability in the AI chatbot sphere."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls1-img1",
              "height": 936,
              "width": 936,
              "filename": "abls1-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691540939-abls1-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "[19:36 - 32:04]\n"
                      },
                      {
                        "type": "span",
                        "value": "Facebook's release of Llama 2 represents a significant step in AI development, symbolizing a shift in the balance between open-source and commercial models. Here's a comprehensive summary of the details and implications from the transcript:"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Technical Overview"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Llama 2 is described as the first fully commercially usable GPT-3.5 equivalent model. It can run on private infrastructure, opening new possibilities for government, healthcare, and financial sectors, and users can fine-tune it with full control over the internals."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open-Source Debate"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Despite not being fully open-source, Llama 2 has been generously shared with the community. The debate around its status has led to reflections on the need for better labeling and definition for models like this. An estimated $15 to $20 million has been effectively donated to the community, with many building on top of it."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Shift in Value"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Llama 2 reflects a change in AI's relative value, with data becoming more valuable than compute. It marks a reversal in open-source culture, where the sequence of openness has shifted. There's a growing trend to restrict data while still providing access to models, indicating a more protective stance towards proprietary data."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Legal and Ethical Considerations"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a growing intrigue and concern around regulatory pressure and copyright issues in the AI space. Instances of training on copyrighted data like books have stirred debate on Twitter, highlighting the blurry lines around what constitutes fair use."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Impact on Business and Development"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Llama 2 has significantly impacted the evolution of the AI space and business strategies. Companies are now less reliant on startups for AI solutions, as technical teams can spin up their versions using open-source tools. It has raised the bar for what vendors must offer, shifting competition towards other areas of AI application production."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open-Source vs Commercial Models"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The discussion also brings to light the subtle nuances between truly open-source models and those that are labeled as such but come with certain restrictions. The conversation around Llama 2 has served as a focal point for a broader conversation about how the AI community navigates the balance between openness and commercial interests."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Cultural Shift"
                      },
                      {
                        "type": "span",
                        "value": ": "
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a cultural shift in how open-source models are handled, with a focus on functional use over strict definitions. The availability of tools like Llama 2 has changed the landscape, demanding more from vendors and reshaping how both startups and large companies approach AI development."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In conclusion, the introduction of Llama 2 has ignited conversations and changes that reach far beyond its technical capabilities. It has become a symbol of the evolving dynamics in AI, marking a period of transition where the boundaries between open-source, commercial interests, regulation, and ethics are being actively explored and redefined."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls1-img2",
              "height": 936,
              "width": 936,
              "filename": "abls1-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691540952-abls1-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "[32:04 - 44:40]\n"
                      },
                      {
                        "type": "span",
                        "value": "Perspective on AI developments."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Highlighted Developments"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Context Window Expansion"
                              },
                              {
                                "type": "span",
                                "value": ": A major change that allows for improved handling of data."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "MLC Team's Experiment"
                              },
                              {
                                "type": "span",
                                "value": ": The team wrapped llama two to run on MacBook GPUs. This is interesting because it bridges the gap between using token-based AI services and unlimited local usage."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Open Source Creativity"
                              },
                              {
                                "type": "span",
                                "value": ": Open Source offers unpredictable potential. The \"AI girlfriend economy\" is a booming, less-talked-about sector with millions of users. It also brings forth debates on societal perspectives of such technology."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Significance of AI in Relationships"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "AI relationships might play a crucial role in addressing loneliness in the future, potentially reducing adverse societal events."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "A prediction is made that future generations will find AI relationships normal, leading to generational debates."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Matthew McConaughey discussed the idea of computers assisting humans in interpersonal relationships. These AI tools can help individuals learn and better their interaction with others."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion on Claude 2 & Anthropic"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Claude 2"
                              },
                              {
                                "type": "span",
                                "value": ": Considered significant for its longer context window and its utility in aiding developers."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Anthropic"
                              },
                              {
                                "type": "span",
                                "value": ": Positioned as a safer alternative to OpenAI, it has made a mark in the competitive CI landscape. While it has been overshadowed by giants like OpenAI, there's a growing appreciation in the developer community for its potential."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Usage Recommendations"
                              },
                              {
                                "type": "span",
                                "value": ": Suggestion made to run chats side by side on platforms like Tragicia, Claude, and Llama two to derive maximum benefits."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Context Limitations"
                              },
                              {
                                "type": "span",
                                "value": ": There's a discussion on whether too much context might be counterproductive. Models might retrieve data better from the start or end of a context window, but information in the middle might get lost."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation delves into recent AI developments, their implications, and societal perspectives on AI's role in human relationships."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls1-img3b",
              "height": 936,
              "width": 936,
              "filename": "abls1-img3b.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691540966-abls1-img3b.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "[44:40 - 58:37]"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google Bard Updates:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Mid-month, Google Bard released several updates focused largely on business."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Added support for more languages."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The main feature they highlighted was advancements in image recognition, signaling a move towards multimodality."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Some participants feel Google needs to enhance product level offerings, suggesting integrating Bard with tools like Google Maps."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Despite Bard's efforts in multi-modality, there's been criticism, with some feeling the updates aren't as innovative as they should be."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Bard did, however, achieve a general multimodal availability before GPT-4, where one can upload an image and have Bard describe it."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Some feel Google's consistency in product updates is lacking, referencing Google Adobe's discontinuation and other failed promises."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Trends in Developer Community:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Interest in auto GPT-like systems, mentioning GBT Engineer and Multi-on."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Agent technology hasn't died down; there's a push towards making agents more usable."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A rising trend of evaluation companies, which monitor the success of AI models and versions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a shift from generic agent models to verticalized agents, combining industry-specific knowledge with AI capabilities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "SDXL, a text-to-image technology, has been on the horizon but hasn't gained the traction it should have."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Character AI is becoming popular, potentially laying the foundation for AI-native social media platforms. These platforms could serialize personality and intelligence, perhaps hinting at \"mind uploading.\""
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Reports suggest Meta (formerly Facebook) might introduce AI personas."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Predictions for August 2023:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Expect more public discourse on open-source models being used in production environments."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Despite current perceptions, some big companies might be transitioning from OpenAI models to open-source models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "August might be a preparation month, with bigger announcements coming later in the year."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion appears to revolve around the rapid advancements in AI, with a specific focus on Google Bard's updates and the broader trends in the AI development community. There is an evident excitement and anticipation for what's to come in the AI landscape, especially as it begins to merge with other industries and consumer applications."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls1-img4",
              "height": 936,
              "width": 936,
              "filename": "abls1-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691540978-abls1-img4.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive into GPT4.5, Llama 2, AI tools, the rising AI engineer, and more!",
        "title": "Latent Space Podcast 8/4/23 [Summary] AI Breakdown crossover",
        "twitterCard": null,
        "image": {
          "width": 1578,
          "height": 558,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
        }
      }
    },
    {
      "id": "190259111",
      "topics": [
        "Summary",
        "Transformers",
        "Training",
        "Open Source"
      ],
      "title": " Latent Space Podcast 7/26/23 [Summary] FlashAttention 2: making Transformers 800% faster - Tri Dao of Together AI",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "Discover how FlashAttention revolutionized AI speed with Tri Dao, as he unveils the power of FlashAttention 2, dives into Stanford's Hazy Lab & future AI insights.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Introduction"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "On the Latent Space podcast, Alessio, a Partner and CTO-in-Residence at Decibel Partners, hosts a discussion with guest Tri Dao. Tri recently completed his PhD at Stanford and is a main author of the groundbreaking FlashAttention paper pivotal in the Transformers era. Tri shares insights into efficient transformer training, inference, and long-range sequence models. He is set to be an assistant professor in Computer Science at Princeton in the coming year. Tri also recently joined as the Chief Scientist at the company, Together, which is responsible for RedPajama."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Tri reveals a personal tidbit that he initially intended to major in economics during his early days at Stanford, but after taking math classes, he shifted his focus to mathematics. This decision played a significant role in steering him towards his current career in math, computer science, and AI research."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion delves deep into FlashAttention and its recently released successor, FlashAttention 2. The innovation in FlashAttention is its capability to scale linearly, as opposed to the traditional quadratic scaling. Tri emphasizes the importance of avoiding approximation in attention mechanisms. He explains that while other methods focus on approximating attention, their main objective was efficiency and memory. Their approach saw a wall-clock speed up of 2 to 4 times, making training 2 to 4 times longer possible without added costs."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A significant aspect of their innovation involves merging ideas from both machine learning and system designs, particularly kernel fusion. This technique optimizes memory reading and writing, which consumes most of the time in attention mechanisms. While kernel fusion has its merits, Tri acknowledges that it may limit flexibility, especially for researchers keen on tweaking the attention process. However, the benefits are primarily in leveraging faster memory (SRAM) compared to the more massive but slower memory (HBM), capitalizing on the asymmetric memory hierarchy present in GPUs."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-08-at-8-43-59-pm",
              "height": 594,
              "width": 1648,
              "filename": "screenshot-2023-08-08-at-8-43-59-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Memory Hierarchies in Hardware"
                      },
                      {
                        "type": "span",
                        "value": ": There are multiple levels of memory storage in hardware systems:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "SRAM (Static Random-Access Memory) is faster but much smaller. Its size is unlikely to grow substantially due to spatial constraints on-chip."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "HBM (High Bandwidth Memory) is larger and resides off-chip. Its growth potential is larger due to having more space."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Challenges and Evolution"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The inherent spatial constraints on SRAM might prevent it from getting much larger in size."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "HBM's growth is forecasted, both in size and speed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a strong emphasis on designing algorithms that account for this memory disparity. Just like CPUs have small cache sizes but vast DRAM, algorithms must learn to efficiently utilize these variances."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "FlashAttention's Relevance"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Attention mechanisms in neural networks, like FlashAttention, have proven their worth over time. Even though the exact implementations might change, the foundational ideas are expected to remain."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Attention is anticipated to be pivotal in state-of-the-art architectures in the coming years."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Research Popularity & Utility"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri discusses the unpredicted popularity of FlashAttention and emphasizes the significance of code as an artifact in research. It's not just about presenting an idea but ensuring that it can be efficiently and effectively utilized by others."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Hazy Research Group"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Hazy Research is a diverse research group at Stanford. It incorporates experts across various domains from algorithms, systems, to applications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "This diversity facilitates a robust feedback loop where theoretical ideas can be built into systems and then practically applied. Direct feedback from applications helps refine and improve theoretical concepts."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Chris Re, an advisor at Hazy Research, emphasizes understanding fundamental concepts, which aids in creating more impactful research."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls2-img2",
              "height": 936,
              "width": 936,
              "filename": "abls2-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691544005-abls2-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Academia vs Industry in AI/ML Research"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio inquired about the balance and comparison between academia and industry, especially in the field of AI/ML."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri believes both sectors play complementary roles. Industry has the advantage in scaling due to access to resources, such as computing power. However, many foundational ideas, like the Attention mechanism, originated from academia."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Post the success of models like GPT-2, companies like OpenAI emphasized scaling, achieving remarkable results."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Academia focuses on evaluations, understanding the underpinnings of models, and taking riskier research bets. They have the freedom to delve deeper into understanding and even undertake projects with a lower chance of success."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri suggests industry may offer better compensation and work-life balance, while academia offers more intellectual freedom. Career choice depends on individual preference."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Role of Evaluations"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio highlighted how benchmarks can influence model development since models need to score well on them to gain attention and funding."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri emphasized the importance of evaluations and benchmarks. He notes that both academia and industry contribute to the field, understanding emerging use cases and ensuring advancements."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "FlashAttention 2 & NVIDIA"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri introduced FlashAttention 2, a project developed over months, which started as an exploration of NVIDIA’s CUTLASS library but evolved into a tool that is twice as fast."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Currently, FlashAttention 2 works on NVIDIA GPUs. However, the main idea of addressing memory hierarchy asymmetry is universal and can be applied across different hardware."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Hardware Lottery"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio referred to Sara Hooker’s idea of the \"hardware lottery\", where potential better architectures may not see the light of day because they aren't optimized for the dominant hardware like NVIDIA."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri acknowledged the hardware lottery and the feedback loop it creates with software frameworks. For example, since transformers are currently dominant, most optimization work centers around them."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Compilers might offer a way out of this cycle. They allow for efficient performance across diverse hardware platforms. Tri cited the Mojo language as an example, as it aims to make AI models run efficiently on various devices."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls2-img3",
              "height": 936,
              "width": 936,
              "filename": "abls2-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691544017-abls2-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Chips and On-chip Memory"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio inquires about AI chip companies like Cerebras that focus on integrating everything onto the chip to combat memory bandwidth issues."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri acknowledges the promising direction, mentioning Tesla's Dojo supercomputer, which seeks to maximize on-chip memory speed and eliminate repetitive data transfers. A challenge is the high manufacturing cost of on-chip memory, which is pricier per gigabyte than off-chip memory. Tri cites Cerebros, which has overcome some of these obstacles with its proprietary software stack and compiler."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He also points out the complexity of supporting tools like PyTorch on such hardware, given the rapid evolution of AI models and the longer time frame required for hardware development."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Influence of Industry Pace on PhD Research"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio queries the influence of the rapidly progressing industry on research, particularly in cases where newer model architectures might make older topics obsolete."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri reflects on the challenges faced by researchers and emphasizes the importance of understanding the fundamentals. He shares his own PhD experience and believes that acquiring foundational knowledge and skills is crucial for evolving as a researcher."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Transformer Alternatives"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio brings up the potential alternatives to Transformer models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri references a wager between Jonathan Franco and Sasha Rush on this subject. He highlights several promising Transformer alternatives that have emerged, such as state space methods, which offer better performance for capturing long-range information without quadratic scaling. He also discusses the resurgence of recurrent neural networks (RNNs) adapted for today's AI landscape."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri emphasizes the academic quest to determine whether attention in models is essential. He suggests that alternative architectures might be more suited for applications with long sequences (like high-resolution images or audio) or those that require high-throughput generation. Tri is optimistic about RNNs for their potential in batch processing."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls2-img4",
              "height": 936,
              "width": 936,
              "filename": "abls2-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691544032-abls2-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open-source AI:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio comments on the evolution and ambiguity of what defines \"open-source\" in AI, drawing comparisons between software licenses and the transparency of AI models and datasets. He mentions the introduction of models such as Red Pajama, LLAMA1, and LLAMA2 and their impact on the AI industry. LLAMA2 is especially notable as its weightings are available to the public, amounting to $3 million of computational power donated to the public domain."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri acknowledges the contribution of Meta in training LLAMA1 and LLAMA2 and praises the reduced restrictions on the latter. He predicts a significant impact on the open-source AI landscape due to the usability of models like LLAMA2 in business settings. Tri emphasizes the shift in the balance of power from closed-source models to open models. He highlights the importance of democratizing decision-making in AI rather than concentrating it in the hands of a few corporations."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The conversation shifts to datasets, with Alessio opining that open datasets have a greater impact than open models. Tri speaks about the challenges and rewards of releasing datasets, pointing out the need to incentivize data release. He cites the Dolly-15K dataset as a positive instance of a company championing open-source datasets."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussing his journey, Tri reveals his reasons for joining \"Together,\" a company focused on open-source models. He appreciates the company's philosophy, alignment with his values, and the chance to conduct research in areas he's passionate about."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Concluding lightning round:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri mentions he was surprised by AI's newfound ability to understand jokes."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He cites \"reasoning\" as an exciting unsolved question in AI, emphasizing the potential need for dedicated reasoning modules in future AI models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Tri's takeaway message is the importance of understanding both algorithms and the systems they run on, emphasizing the excitement and results found at the intersection of machine learning and systems."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls2-img1",
              "height": 936,
              "width": 936,
              "filename": "abls2-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691544076-abls2-img1.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Discover how FlashAttention revolutionized AI speed with Tri Dao, as he unveils the power of FlashAttention 2",
        "title": " Latent Space Podcast 7/26/23 [Summary] FlashAttention 2",
        "twitterCard": null,
        "image": {
          "width": 1648,
          "height": 594,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
        }
      }
    },
    {
      "id": "190259172",
      "topics": [
        "Summary",
        "LLM",
        "Open Source",
        "Small Models"
      ],
      "title": "Latent Space Podcast 7/19/23 [Summary] - Llama 2: The New Open LLM SOTA (ft. Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog et al.)",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "Explore Llama 2, the latest AI breakthrough with experts Nathan Lambert, Matt Bornstein & more. Dive into datasets, benchmarks & AI predictions. Llama insights & drama await in this top podcast!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: Llama 2: "
                      },
                      {
                        "url": "https://www.latent.space/p/llama2#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "The New Open LLM SOTA (ft. Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog et al.)"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Introduction"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "\nIn an episode of a podcast focusing on AI research and models, Alessio Fanelli hosts with guests Simon Willison and Nathan Lambert."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alessio Fanelli"
                              },
                              {
                                "type": "span",
                                "value": " reiterates the podcast's ongoing commitment to discussing AI topics, hinting at its increasing depth. He acknowledges Simon as a frequent guest and thanks Nathan, who has shared insights on the technical details of Lama two."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon Willison"
                              },
                              {
                                "type": "span",
                                "value": " expresses his excitement about the release of LAMA two. He highlights that this version can be used for commercial purposes, marking a significant change from previous versions which were not. He also mentions that while the benchmarks suggest it's a quality product, time will be required to ascertain its real-world effectiveness. The model, although officially available through Meta's website upon form approval, has already seen unofficial distributions online."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nathan Lambert"
                              },
                              {
                                "type": "span",
                                "value": ", who is affiliated with Huggingface, shares his experience on the topic. He's a researcher involved in reinforcement learning from human feedback. He emphasizes the significance of LAMA two in terms of its research contribution. However, Nathan also points out that the paper's methodology is more evident than the specifics of the data sets used. This shift may be related to potential legal challenges regarding the training data used in the first LAMA. In the previous model, copyrighted data was involved, which may be one reason behind the decreased transparency in the new paper."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Matt Bornstein"
                              },
                              {
                                "type": "span",
                                "value": " from a16z briefly mentions their version of evaluations, positioning it as more of a \"feel-good\" approach in contrast to the deep dives of other panelists."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation revolves around the implications of LAMA two, its commercial viability, technical intricacies, and potential legal and ethical ramifications."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-13-at-7-11-06-pm",
              "height": 574,
              "width": 1632,
              "filename": "screenshot-2023-08-13-at-7-11-06-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "LAMA 2 Model Insights and Open Source Licensing Discussion"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "\nHighlights:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Diverse Model Sizes:"
                              },
                              {
                                "type": "span",
                                "value": " Alessio Fanelli highlights various sizes of the LAMA 2 models, including 7 billion, 13 billion, and 70 billion, but points out a 34 billion model size that was deemed \"unsafe\" and was not released due to safety concerns and time constraints."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Data Opacity:"
                              },
                              {
                                "type": "span",
                                "value": " There is a significant increase in pre-training corpus size for LAMA 2 (40% larger), but specific sources remain undisclosed, unlike LAMA 1."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Safety Overkill?"
                              },
                              {
                                "type": "span",
                                "value": " There are concerns about LAMA 2's overly cautious safety responses to certain queries, prompting discussions on the balance between safety and practicality."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Licensing and Open Source:"
                              },
                              {
                                "type": "span",
                                "value": " A major topic of discussion revolves around the term \"open source\" and its implications. The distinction between \"openly licensed\" and \"open source\" is emphasized, along with the complications introduced by terms like \"competing large language model.\""
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Commercial Potential:"
                              },
                              {
                                "type": "span",
                                "value": " There's strong anticipation of extensive commercial use of open source language models, but licensing questions, especially related to commercial applications, remain a constant challenge."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Model Potential and Optimizations:"
                              },
                              {
                                "type": "span",
                                "value": " With LAMA 2 being open source, there's excitement about potential optimizations and improvements from the broader AI research community."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Huggingface's Rail License:"
                              },
                              {
                                "type": "span",
                                "value": " Nathan Lambert from Huggingface discusses their Responsible AI License (RAIL) designed to be commercially available with good intentions and provides leeway to address bad actors using their models."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img1",
              "height": 936,
              "width": 936,
              "filename": "abls4-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691982762-abls4-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring the Evolution and Potential of Llama 2 in AI Pre-training"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " introduces the topic of pre-training base model discussions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nathan Lambert"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Mentions the role of cross-query attention (cqa) in making inference faster."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Notes a lack of emphasis on code and math in the paper, despite its market importance."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Appreciates the detailed information on RHF and sees it as confirmation of capabilities hinted at by companies like Anthropic and OpenAI."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Matt Bornstein"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Poses a question about pre-training data surpassing Chinchilla optimal."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Reflects on the initial excitement when Chinchilla's findings showed improved performance with increased training data."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Asks Nathan for clarification on how better data quality impacts performance."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nathan Lambert"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Comments on the changing nature of data quality, highlighting issues like insider jokes, phrasings, and errors."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Emphasizes the importance of deduplication and the challenges of determining good text from the internet."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Matt Bornstein"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Points out that early data limitations were possibly due to inadequate cleaning methods."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Questions whether there's an upper limit to the amount of data we can train models on."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Comments on the ever-increasing ratios of tokens to parameters."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Highlights how Chinchilla's methods were specific to their time and objectives and contrasts this with the new objectives presented in the Llama paper."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Points out the early stage of AI model development and the rapid progression of research."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon Willison"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Observes that the rush to publish might stem from the competition in AI research."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Mentions the practice of shipping state-of-the-art models quickly."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Points out that not everyone involved in Llama 2's development was credited in the paper due to employment transitions."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alessio Fanelli"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Cautions against delving into organizational drama without firsthand knowledge."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Matt Bornstein"
                              },
                              {
                                "type": "span",
                                "value": " and "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nathan Lambert"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Express light-hearted surprise about the potential drama among researchers."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Moves the discussion towards preference data mentioned by Nathan."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Key Takeaways:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a consensus that the field of AI research is rapidly evolving."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The quality of data and how it's processed is paramount to improving model performance."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The competitive nature of AI research might lead to publishing models before their full potential is realized."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Some contributors to Llama 2 might not have been credited due to employment shifts, hinting at potential drama in the AI research community."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img2",
              "height": 936,
              "width": 936,
              "filename": "abls4-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691982774-abls4-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Discussion on Meta's LAMA 2 Model and its Implications"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion Highlights"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Language Translation"
                              },
                              {
                                "type": "span",
                                "value": ": Alex Volkov highlights the surprising lack of focus on multilingual capabilities in the recent models, especially given Meta's earlier successes in this domain."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Llama2's Coding Abilities"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx mentions the inadequacies of relying solely on human eval for coding chatbot benchmarks, stressing the need for newer benchmarks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Training Data Transparency"
                              },
                              {
                                "type": "span",
                                "value": ": Simon Willison addresses the challenges faced by consumers due to the opaqueness of the models, emphasizing the importance of understanding their training data."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Meta's Release Strategy"
                              },
                              {
                                "type": "span",
                                "value": ": Alex Volkov and Nathan Lambert delve into the implications of Meta's open-source release, considering both its potential commercial benefits and the challenges associated with regulatory bodies."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Role of Open Licensing"
                              },
                              {
                                "type": "span",
                                "value": ": Simon Willison mentions the pivotal role Meta AI has in openly licensed language model research, particularly with the introduction of LAMA."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Impact on Startups"
                              },
                              {
                                "type": "span",
                                "value": ": Matt Bornstein discusses the monumental effect on the startup ecosystem, pointing out the ongoing dilemma faced by startups regarding the use of off-the-shelf models or custom training."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the discussion, the experts contemplate the balance between commercial benefits, the importance of transparency, and the evolving needs of the AI community, given the rapid advancements in the field."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img3",
              "height": 936,
              "width": 936,
              "filename": "abls4-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691982805-abls4-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Discussing the Evolution and Transparency of AI Models, and the Importance of Preference Data in Training"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Trying Llama 2 Model:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Hugging Face has launched an inference endpoint for the Llama 2 model, one of the few ways to access the 70B model directly. The G GML ecosystem is a reference for the two-bit quantized version. Base 10 might also have a similar setup."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Dataset Transparency Debate:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "While some believe that we don't necessarily need to know full datasets of models like Llama if we can evaluate them properly, others argue for transparency. Simon Willison favors transparency, especially when comparing two similar models. The emerging theme seems to be dataset non-transparency, highlighted by challenges such as Falcon's controversial responses to sensitive topics."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Cost of Developing Llama 2:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The cost associated with Llama 2, estimated around $25 million, primarily revolves around preference data collection rather than GPU resources. Nathan Lambert discusses the nuances of data collection costs, including the complexities associated with the iterative, hands-on approach used for data acquisition."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Human Annotators and Model Annotation:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There is a trend towards shifting from pre-training datasets to preference and HF data. An interesting observation is that human annotators often end up using models for annotation, leading to a recursive scenario of \"models rating models.\" The need for diversity in annotation tasks, ensuring there isn't much overlap, is emphasized. Models are getting good enough that some, like those from Philanthropic, no longer require supervised fine-tuning."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Preference Models and Open Source:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There is a gap in the open-source community when it comes to preference models. Nathan Lambert suggests that the focus should be on the preference side, potentially enabling creative avenues like constitutional AI. The possibility of creating a Stack Overflow-like platform for Llama to gather code dataset through ratings is also touched upon."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation explores the intricacies of AI models, the importance of data transparency, and the cost factors associated with model development. Preference data collection emerges as a significant theme, highlighting the need for diverse and high-quality datasets."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img5",
              "height": 936,
              "width": 936,
              "filename": "abls4-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691983359-abls4-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Llama 2 Finetuning Ecosystem Discussion"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alex Volkov"
                      },
                      {
                        "type": "span",
                        "value": " emphasizes that the Llama 2 ecosystem offers improved ease of work due to existing infrastructure like G GML and Pinocchio browsers. Commercial users who are profit-driven will also find it easier to participate now. Companies like scale.AI have already started providing open source toolkits for fine-tuning Llama on platforms such as Databricks."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Nathan Lambert"
                      },
                      {
                        "type": "span",
                        "value": " notes the dedication of teams like Hugging Face, who worked extensively to provide day zero support for Llama 2."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Swyx"
                      },
                      {
                        "type": "span",
                        "value": " brings up Scale.AI's partnership announcement, suggesting a connection with Llama 2, though it wasn't explicitly stated."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Simon Willison"
                      },
                      {
                        "type": "span",
                        "value": " expresses a desire for straightforward guidance on running Llama 2 on Mac's M2 using the Hugging Face Transformers for better GPU utilization. Nathan mentions Pedro from Hugging Face is already working towards integrating with Apple's ecosystem."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Russell Kaplan"
                      },
                      {
                        "type": "span",
                        "value": " from Scale.AI mentions a new open-source library, LM engine, to aid in the fine-tuning of Llama 2 and other language models. Scale.AI aims to fine-tune Llama 2 for domain-specific tasks, such as SQL and retrieval."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Simon Willison"
                      },
                      {
                        "type": "span",
                        "value": " requests a Llama 2 based version of the ChatGPT code interpreter."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the discussion, there's a recurring theme of the community's excitement about the possibilities with Llama 2 and the broader implications for the AI industry."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img4",
              "height": 936,
              "width": 936,
              "filename": "abls4-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691983398-abls4-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Partnerships, Predictions & Conclusion"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion revolves around relationships and partnerships in the tech world, particularly focusing on OpenAI, Azure, and Meta's contributions to open source AI models. Here are the main points:"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Relationship Dynamics"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Anton observes a potential shift in friendship dynamics among tech leaders like Sam Altman, Mark Zuckerberg, and Satya Nadella, pointing out a notable interaction between Satya and Mark."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio confirms this, recalling a recent photo of Satya laughing with Mark, contrasting it with a more serious picture of Satya with Sam."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Azure's Role with OpenAI"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "OpenAI's heavy reliance on Azure as a hardware platform is highlighted."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Anton and swyx ponder the significance of Azure being the launch partner for OpenAI, especially given Microsoft's considerable investment in OpenAI via Azure credits."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The importance of privacy and control is emphasized, with Russell discussing how businesses might prefer running inferences on their own Azure hardware to maintain data privacy and security."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open Source Movement"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The topic shifts to open sourcing in AI, with Matt pointing out that being the best in open source can sometimes outweigh being the top in proprietary models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx highlights the excitement around open source models and seeks predictions for the future of this domain."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Predictions"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Anton believes that the AI community will explore the true capabilities of the models, possibly uncovering new uses and furthering research in embeddings and internal states."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Nathan highlights the significance of this open source move for research, allowing it to proceed unhindered."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon eagerly anticipates the creative fine-tuning of the model and the potential for breakthrough applications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Russell predicts a surge in domain-specific fine-tuning, leading to specialized AI agents proficient in particular tools or tasks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Anton expresses optimism about the future of AI agents, hinting at their practical use cases."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion closes with participants sharing their bullish sentiments on the advancements of open source models, especially with regard to AI agents and their potential applications."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "\n"
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Ai Doom:"
                      },
                      {
                        "type": "span",
                        "value": "\nIn a discussion concerning the potential impact and implications of releasing new AI material, specifically the LAMA2 model, participants shared diverse views. While some displayed apathy toward potential doom scenarios, others expressed optimism, suggesting that accessibility to the model's internals might enhance safety and understanding. There was an acknowledgment that language models, which were once considered cutting edge, are quickly becoming more commonplace, with a future where many devices could run them natively. The conversation concluded with swyx encouraging everyone to experiment with LAMA2, and gratitude was expressed all around before signing off."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls4-img6",
              "height": 936,
              "width": 936,
              "filename": "abls4-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1691983112-abls4-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive into datasets, benchmarks & AI predictions. Llama insights & drama await in this top podcast!",
        "title": "Latent Space Podcast 7/19/23 [Summary] - Llama 2",
        "twitterCard": null,
        "image": {
          "width": 1632,
          "height": 574,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
        }
      }
    },
    {
      "id": "190259191",
      "topics": [
        "Summary",
        "Code",
        "LLM"
      ],
      "title": "Latent Space Podcast 7/10/23 [Summary] - Code Interpreter == GPT 4.5 (w/ Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "Explore ChatGPT's Code Interpreter: a game-changer in AI. Dive into its 1000x capabilities leap with Simon, Alex & top AI experts. #CodeAugmentedInference #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/code-interpreter#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Code Interpreter == GPT 4.5 (w/ Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "ChatGPT Code Interpreter Feature Discussion"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alex Volkov"
                      },
                      {
                        "type": "span",
                        "value": " announces a public release of a new beta feature for ChatGPT, which is a code interpreter. He describes how users can enable this feature and highlights its capabilities."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Key Features of the Code Interpreter"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "It allows users to upload files."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Code is run in a secure environment."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Users can download files generated by ChatGPT."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Simon Willison's Experience"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon"
                              },
                              {
                                "type": "span",
                                "value": " has been using this tool frequently and finds it revolutionary. It offers capabilities beyond just ChatGPT, especially for developers."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He also points out its wide file compatibility, from CSV to SQLite. It can analyze, run SQL queries, and even generate graphs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There was a feature (now apparently disabled) where users could upload Python packages to the interpreter."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A workaround for file size limit: Compressing files to zip and then uploading them."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Swyx's Notes"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " had documented his experiences and observations, which were displayed on the jumbotron. He mentions the early days of the interpreter and how it could write, run, and iteratively fix code."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Interaction with the Code Interpreter"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Users can guide the interpreter, almost like mentoring an intern."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Asking it to \"do better\" can often result in improved results."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alex mentions how users can still utilize familiar prompts like \"act as a senior developer\" for better outputs."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Practical Applications"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon"
                              },
                              {
                                "type": "span",
                                "value": " uses it for actual coding tasks. It can test its code, identify bugs, and rectify them."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "This tool saves developers time by quickly handling edge cases and providing accurate code."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Daniel Wilson's Perspective"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Daniel"
                              },
                              {
                                "type": "span",
                                "value": " praises the tool, calling it the \"most advanced agent the world has seen\"."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He hints at the significance of such a feature rollout for the entire user base and the potential DevOps implications."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Dependencies Exploration"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Daniel"
                              },
                              {
                                "type": "span",
                                "value": " and Nin seemingly uncovered the complete list of dependencies for the code interpreter."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion showcases the excitement around ChatGPT's new code interpreter feature, emphasizing its transformative potential for developers and the broader tech community."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-14-at-3-34-05-pm",
              "height": 582,
              "width": 1596,
              "filename": "screenshot-2023-08-14-at-3-34-05-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Code Interpreter Conundrums"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion revolves around the capabilities and limitations of a new Code Interpreter. Key points include:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Uploading Different Languages:"
                              },
                              {
                                "type": "span",
                                "value": " Simon Willison experimented by uploading binaries of Deno (an alternative to Node.js) and a Lua interpreter to the Code Interpreter, allowing it to execute JavaScript and Lua for a while before these functionalities were restricted."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Safety and Restrictions:"
                              },
                              {
                                "type": "span",
                                "value": " Simon muses about why there are certain limitations since the platform appears to use containers (possibly Kubernetes) that are restricted in networking and have limited CPU and disk space. The Code Interpreter also has timeouts on code execution."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Loss of State:"
                              },
                              {
                                "type": "span",
                                "value": " Users discuss instances where the Code Interpreter disconnects, leading to loss of the data or files uploaded. However, the conversation history remains, which can sometimes lead to confusing loops where the system behaves as if it still has access to the data."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Context Window:"
                              },
                              {
                                "type": "span",
                                "value": " There is speculation on the context window of the interpreter. It's believed to be around 8,000 tokens, similar to GPT-4, but this hasn't been confirmed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Refactoring and File System:"
                              },
                              {
                                "type": "span",
                                "value": " Simon observes that the interpreter often rewrites whole functions for small changes, so he sometimes instructs it to refactor the code into smaller functions for efficiency. He also advises against pasting large amounts of text directly and instead suggests uploading as a file to conserve tokens and speed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Git Repos:"
                              },
                              {
                                "type": "span",
                                "value": " Daniel Wilson discusses the potential of uploading git repos. Although the interpreter can read content and suggest changes, it cannot directly commit. If it had bindings to Git, it could potentially commit changes."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Security:"
                              },
                              {
                                "type": "span",
                                "value": " The panel discusses the security of the Code Interpreter, speculating it's robust due to its wide rollout. They believe it's running in a well-sandboxed environment, possibly using technologies like firecracker or Kubernetes, making breaches unlikely."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls5-img2",
              "height": 936,
              "width": 936,
              "filename": "abls5-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692049936-abls5-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring the Depths of Code Interpreter's Capabilities and Potential"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a discussion revolving around the capabilities of a 'Code Interpreter', participants delved into the following:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Visualization Libraries"
                              },
                              {
                                "type": "span",
                                "value": ": Alex Volkov mentioned that many users find it difficult to work with libraries for data visualization, particularly plotting data on maps. Some libraries cited were Pandas and Matplotlib, with Simon Willison noting that the tool only supports image outputs, specifically those like PNG or GIF. Matplotlib is an older Python plotting library that fits well within the training of GPT."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Generating Interactive Diagrams"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx highlighted that the interpreter is mainly equipped with Python libraries from its requirements. There's also the ability to generate HTML, CSS, and JavaScript files. By utilizing a 'hack' from Ethan, users can render JavaScript to produce interactive visuals."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Audio and Video Features"
                              },
                              {
                                "type": "span",
                                "value": ": The interpreter also boasts Torch and Torchaudio libraries. Nisten expressed excitement about its potential speech library, while Alex Volkov touched on the interpreter's ffmpeg capability, which allows interaction with video files. Users can split videos, convert formats, and more."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Data Analysis Strength"
                              },
                              {
                                "type": "span",
                                "value": ": Simon Willison shared an anecdote about the code interpreter's prowess in data analysis. Using a dataset of police calls from San Francisco, Simon asked the tool to visualize crime reports around two locations over time. The tool processed a sizable dataset efficiently and produced a relevant chart, all based on a single prompt. This efficiency led Simon to reconsider the future direction of his open-source project, Dataset, as the interpreter covered most of its intended functionalities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Potential Network Access"
                              },
                              {
                                "type": "span",
                                "value": ": Alex Volkov and Daniel Wilson hinted at the interpreter possibly gaining internet access in the future, which could further enhance its capabilities."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation showcased the power and flexibility of the Code Interpreter, hinting at a future where data analysis and visualization could become more accessible and efficient for a wider range of users."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring the Capabilities of Code Interpreter"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel Wilson discussed how he and others probed the system's prompts, expressing surprise at how readily the system divulged its last few prompts."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alex Volkov suggested the current model could be a fine-tuned earlier checkpoint."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Nisten confirmed that OpenAI uses Kubernetes and referenced a famous OpenAI blog post about their Kubernetes cluster."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The group discussed the system's ability to execute certain functions, with several members experimenting with its limitations and potential."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They discussed the possibility of the system having variable CPU performance, suggesting that it might sometimes operate on shared instances."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The conversation veered into the topic of system specs, with Simon Willison sharing a method he used to determine the system's RAM."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There was a humorous interjection about replacing certain technical terms with \"SpongeBob.\""
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel Wilson provided insights into his experiments with image recognition using OpenCV's pre-trained models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A notable omission from the model's capabilities is the absence of hugging face transformers and datasets."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The potential for the code interpreter to function as a debugger in software companies was highlighted."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring Code Interpreter's Potential: From Analysis Choices to Vector Database Integration"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Code Interpreter Behavior"
                      },
                      {
                        "type": "span",
                        "value": ": Swyx mentions that the Code Interpreter sometimes doesn't do the whole analysis but rather gives the user multiple options to choose from. Simon confirms this, likening it to how a real data analyst would ask for more specifics when given a vague question."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Product Design"
                      },
                      {
                        "type": "span",
                        "value": ": Daniel Wilson praises the design of such agents, particularly how they decide to either proceed independently or ask for user guidance."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Tips on Interaction"
                      },
                      {
                        "type": "span",
                        "value": ": Simon gives a tip for users to ask the AI for multiple options, suggesting that this could speed up the process and offer more diverse results. Daniel agrees, mentioning that vague prompts can lead to tangential but useful suggestions."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Code Interpreter Applications"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon introduces the idea of uploading project documentation to the Code Interpreter to help it answer questions about the docs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alex and Simon discuss the potential of integrating vector databases with the Code Interpreter, hinting at its vast applications."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Tokens & Model Discussion"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx brings up a topic about extracting tokens from the Code Interpreter environment and the possible implications of such an act."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel Wilson and Alex discuss the possibility of the Code Interpreter using a different model, with Daniel providing evidence based on his client-side observations."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Working with Code"
                      },
                      {
                        "type": "span",
                        "value": ": Simon and Daniel discuss uploading code to the AI. Simon typically copy-pastes code while Daniel suggests that users can upload a zip file full of Python code."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Tinygrad on Code Interpreter"
                      },
                      {
                        "type": "span",
                        "value": ": Daniel proposes the idea of running Tinygrad, an alternative to PyTorch, on the Code Interpreter."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Feature Request"
                      },
                      {
                        "type": "span",
                        "value": ": Surya Danturi introduces the idea of combining the Code Interpreter with plugins. He has been working on a plugin that essentially creates a user's vector database, and combining this with the Code Interpreter might enhance results. He also hints at the potential of uploading an entire GitHub repository to the Code Interpreter."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls5-img1",
              "height": 936,
              "width": 936,
              "filename": "abls5-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692051868-abls5-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Quorum of Models, Continuous Learning, and The Future of External Interactions"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Quorum of Models:"
                      },
                      {
                        "type": "span",
                        "value": " Oren discusses how a model can bounce ideas off various sub-models to refine its output. This continuous feedback system means the model continuously improves its suggestions, moving closer to a near-perfect code output every time."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Memory Limitations & Solutions:"
                      },
                      {
                        "type": "span",
                        "value": " Simon Willison touches on session memory limitations and suggests a potential solution using SQLite to save a session's data and reload it later."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "OCR and Language Learning:"
                      },
                      {
                        "type": "span",
                        "value": " Daniel Wilson introduces a use case where a model, through OCR, interprets and understands old grammatical structures of languages that lack machine translation tools. He particularly mentions languages from Nigeria and Indonesia and the challenges and achievements they've faced."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Enhancements through Plugins:"
                      },
                      {
                        "type": "span",
                        "value": " Surya Danturi and Alex Volkov highlight the potential of plugins, where a model can communicate with an external plugin that can call another external API. This recursive approach could open doors to increased functionality, provided the security concerns are addressed."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Extended Memory Techniques:"
                      },
                      {
                        "type": "span",
                        "value": " There's mention of a potential hack to expand the model's memory using an external text file, which can be read or written to by the code interpreter. This offers a workaround to context length limitations."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Code Interpreter Insights: Bugs, Use Cases, and Education Impact"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "ChatGPT iOS App Bug Discussion:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a reported bug in the ChatGPT iOS app. When users prompt on the web and then switch to the app, the system may continuously self-prompt."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The app seems to generate multiple messages before the user interacts. The history of this behavior is visible on the web."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "InstructorEmbeddings:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A discussion on \"instructor embeddings\" took place, which is different from \"hugging face.\" It tops the leaderboard in its category and may potentially be integrated into a code interpreter."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Code Interpreter's Capabilities:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Gabriel shared his experiment with the code interpreter on sentiment analysis. The system tried various libraries and even created a basic sentiment analysis mechanism when it couldn't access a specific lexicon."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon Willison found it amusing to watch the system try different methods and commented on its adaptability."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon also shared how he used the interpreter to construct a tool that searches Python code based on the Python's Abstract Syntax Tree (AST)."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Personalized Languages and AST/Graphs:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The potential of creating personalized languages that compile to machine code or LLVM was discussed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The system's understanding of graphs and the AST was highlighted."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Feature Request: Token Streaming/Interruption:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's a desire for token streaming on the ChatGPT interpreter, allowing users to interrupt the system if it veers off course."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "OCR from a Graph:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A user expressed interest in extracting values directly from a graph using the code interpreter. Simon was skeptical but encouraged experimentation."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Impact of Code Interpreter on Education:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shyamal from OpenAI emphasized the transformative potential of the code interpreter in the field of education. He cited personal experiences of individuals learning Python and data analysis through the interpreter."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon supported the education perspective, noting the tool bypasses the complexities of setting up a development environment."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Feature Requests Recap:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Users requested more extensibility, such as the reintroduction of binary execution and support for other programming languages like Node and Deno."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring ChatGPT for Business: Insights, Feedback, and Novel Use-Cases"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "ChatGPT for Business Discussion"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The conversation opens with a query about potential B2B applications for ChatGPT, noting that current discussions have been very B2C focused."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shyamal acknowledges the early phase of exploring B2B use cases for ChatGPT. Potential extensions for business might involve plugins and other integrations."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The business version might also emphasize enterprise-level features, such as advanced data security and options to license the software for entire teams."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Code Interpreter Feedback"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A developer, Alex, gives feedback on the Code Interpreter, praising its ability to process and edit videos efficiently. However, he notes memory limitations that restrict file sizes and the inconvenience of the interpreter timing out during prolonged periods of inactivity."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alex expresses interest in a version of the software that offers dedicated, more robust hardware capabilities."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alternative Solutions"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shouminik mentions having created a sandboxing environment for a Discord bot which users can interact with, as an alternative to ChatGPT."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Observations on ChatGPT's Performance"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A noteworthy point is brought up about the perceived decline in ChatGPT's performance quality in recent times. Some users find that the Code Interpreter model provides the level of quality that they originally experienced with ChatGPT."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "While some claim to have evidence of this decline, Simon Willison remains skeptical, noting the challenge in measuring such changes due to the non-deterministic nature of the model."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Takeaway"
                      },
                      {
                        "type": "span",
                        "value": ": The community is actively exploring and providing feedback on OpenAI's offerings, particularly around business use cases and the performance of ChatGPT."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls5-img4",
              "height": 936,
              "width": 936,
              "filename": "abls5-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692052633-abls5-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Feature Requests and the Power of Code Interpreter"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Maxim opens the discussion with a feature request for the platform to support the ability to create music compositions using ABC files. By generating ABC notations and converting them into MP3 files, Maxim believes that this would enhance his learning experience with the piano. There's a shared sentiment that while a built-in player might not be readily available, working with downloadable files could be an alternative."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation shifts as Aravind Srinivas from Perplexity joins. He touches upon the similarities of the challenges they faced in integrating visual representations, like plotting distributions, with GPT-4. There's skepticism about the added value for seasoned coders but also acknowledgment of the advantages for those who don't want interruptions in their thought processes."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Simon Willison offers personal insights on the Code Interpreter. For him, the feature makes coding more ambitious by tackling tedious tasks. Whether it's generating a nested list for a website's table of contents or working with the Python AST library, the Code Interpreter's self-debugging capability is a highlight. Simon humorously compares the experience to mentoring an intern, with the tool sometimes making mistakes and learning from them, albeit much faster."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Al Chang and Simon further discuss the process and psychology of the Code Interpreter. There's an art to guiding and tricking it into solving complex problems. The conversation ends with an emphasis on the value of the tool in writing and running code, highlighting its efficiency and reduced error rate."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI Innovations: Code Interpreter & Multimodal Capabilities Discussed"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "During a discussion on Code Interpreter, several speakers shared insights:"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alex Graveley's View"
                      },
                      {
                        "type": "span",
                        "value": ": He opined that Code Interpreter is valuable due to its feedback loop. Earlier models like Codex wouldn't confirm if the generated code worked. Now, with users running and critiquing the code, the tool is bound to improve significantly in code generation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Context Window Update"
                      },
                      {
                        "type": "span",
                        "value": ": An update was shared about the context window for the code interpreter. It was tested and confirmed that the code interpreter has an 8K context window, similar to some existing models. However, GPT4 default has a 4K context window."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Carl's Input"
                      },
                      {
                        "type": "span",
                        "value": ": Carl highlighted the potential of Code Interpreter for feature requests and its benefit in the OpenAI UI. He also discussed challenges with rendering graphics and data visualizations via an API. Additionally, Carl expressed interest in image processing capabilities, pointing to the potential for image captioning and processing with the OpenAI ecosystem."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Simon Willison's Thoughts"
                      },
                      {
                        "type": "span",
                        "value": ": Simon believed that the maximum potential of Code Interpreter is constrained by the libraries currently installed. He was eager to explore GPT-4's vision capabilities. Simon also requested direct access to the fine-tuned model used in Code Interpreter, so developers could extend its capabilities."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Kyle's Perspective"
                      },
                      {
                        "type": "span",
                        "value": ": Emphasizing the multi-modal capabilities, Kyle spoke about combining data analysis with vision capabilities to provide more insightful analyses."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "API Access Discussion"
                      },
                      {
                        "type": "span",
                        "value": ": There was a collective agreement on the need for direct API access to the Code Interpreter model. Some developers expressed interest in building unofficial APIs if official access isn't provided."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Cryp Law Review"
                      },
                      {
                        "type": "span",
                        "value": ": Mentioned a use case of creating a video from a sample photo and praised the self-debugging nature of the model, echoing Simon's views on the tool's ability to refine and improve on tasks iteratively."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Overall, the conversation centered around the potential of Code Interpreter, its current capabilities, and the hopes and wishes of the developer community for its future iterations."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Social Leap for ChatGPT and Future Aspirations"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a deep discussion about OpenAI's ChatGPT, there is a call for making the AI model more social. The idea stems from allowing users to collaborate with others prompting the model with similar intentions, effectively \"tenderizing\" the AI experience. The goal is not only about sharing individual AI interactions but more about discovering like-minded analysts and forming connections."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "There's also a mention of Shared GT, a way to share one's interactions up to a certain point, which, though effective, has limitations. Simon Willison touches upon a unique experience in the Stable Diffusion discord, emphasizing the value of a public learning sphere where individuals learn from each other."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Further discussion revolves around the 'code interpreter' and how it can be beneficial for business analysts. Gabriel, a participant, points out that while the current capabilities of code interpreter are advanced, there's still a long way to go for seamless data integration and manipulation. An intriguing use-case of the code interpreter is mentioned, where a user uploaded a swift file for a simple game, prompting the AI to analyze and suggest improvements."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation closes with Simon Willison's enthusiasm for the tool and an encouragement for users to explore, share, and collaborate to harness the full potential of the technology."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls5-img3",
              "height": 936,
              "width": 936,
              "filename": "abls5-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692052046-abls5-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "What about Phase 5? and AI.Engineer Summit"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "At a discussion led by Swyx, speakers discuss the current and future state of OpenAI developments. They refer to the current stage as \"Phase 4\" and express anticipation for the subsequent \"Phase 5\". In the current phase, OpenAI is rolling out a vision model, introducing fine-tuning features, and is expected to release a new instruct model. Swyx expresses a desire for more speculative talks on what's next, likening the progression of these phases to the MCU's phases and movies."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx also announces his upcoming conference, \"AI Engineer\", scheduled for October. The conference aims to explore the intersection of coding and large language models, offering both application-based sessions and online streaming. Swyx encourages attendees to check out the event by visiting the \"ai.engineer\" domain, expressing his elation over securing such a relevant domain name."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation concludes with some acknowledgments and thank-yous, with mentions of other AI-focused spaces and events where industry enthusiasts gather to discuss latest advancements. They also touch upon the practicalities and features of the new tools that OpenAI offers, emphasizing their versatility and utility. The overarching sentiment is one of excitement for the current state and future potential of AI."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        }
      ],
      "seo": {
        "description": "Explore ChatGPT's Code Interpreter: a game-changer in AI. Dive into its 1000x capabilities leap with Simon, Alex & top AI experts. ",
        "title": "Latent Space Podcast  [Summary] Code Interpreter = GPT 4.5",
        "twitterCard": null,
        "image": {
          "width": 1596,
          "height": 582,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
        }
      }
    },
    {
      "id": "190259216",
      "topics": [
        "Summary",
        "Open Source"
      ],
      "title": "Latent Space Podcast 7/2/23 [Summary] AI Trends: a Latent Space x Practical AI crossover pod!",
      "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:08:36+01:00",
      "description": "Explore the fusion of Practical AI & Latent Space as they delve into 2023's top AI trends, reflect on standout episodes, and share insights on navigating the AI evolution.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/practical-ai-trends#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "[Practical AI] AI Trends: a Latent Space x Practical AI crossover pod!"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a crossover episode with the Latent Space podcast, host Daniel Whitenack from Practical FM joined co-hosts Alessio Fanelli and Shawn Wang. The discussion began with introductions, with Whitenack highlighting his background in computational physics, his tenure as a data scientist at SIL International, and his recent venture with Prediction Guard. The podcast touched on the rise of AI, its global community, and the practical implications and uses of AI technology in everyday life."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Daniel also shed light on episodes of Practical AI, sharing personal favorites and audience hits. Episodes like \"Fully Connected\" are particularly enlightening, as they delve deep into AI topics such as ChatGPT, diffusion models, and AlphaFold. Another highlight was the \"AI for Africa\" series, which emphasized the importance of AI being inclusive and accommodating for various global use cases."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the conversation, there was a consistent theme of focusing on the practical, day-to-day uses of AI, rather than getting caught up in the hype."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-15-at-5-20-38-pm",
              "height": 532,
              "width": 1600,
              "filename": "screenshot-2023-08-15-at-5-20-38-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI Roundtable: Insights, Excitements, and Challenges in the Modern AI Landscape"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a podcast episode, Shawn Wang, Alessio Fanelli, and Daniel Whitenack discuss their personal episode highlights, trends in the AI industry, and the evolution of model evaluation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Episode Highlights:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio Fanelli's highlight was the episode with Mike Conover from Databricks discussing DALL-E. He emphasizes Mike's passion and the exciting release of the RedPajama dataset."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shawn Wang recalled the news-driven episode on ChatGPT Plugins where 4,000 people tuned in. He finds value in capturing real-time reactions to significant AI developments."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel Whitenack reminisces about the time when image generation was trending but now finds himself immersed in NLP and language models."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Trends in the AI Industry:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The most popular episode was on Metaflow, a Python package for full-stack data science modeling, which resonated with listeners due to the challenges of the model lifecycle in practical applications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel notes that the industry is transitioning from traditional MLOps to a new kind of operations (possibly termed LLMOps), focused more on leveraging pre-trained models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio mentions that their most popular episodes revolved around model-based topics, including discussions about the limitations of traditional benchmarks and the need for better evaluations."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Model Evaluation:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio talked about the rapid evolution of benchmarks, indicating the need for better evaluation metrics for models like GPT-4."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shawn brings up HellaSwag's adversarially-generated benchmarks and the surprising revelation that less than 1% of the data for \"Segment Anything from Meta\" was human-generated."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel observes the growing trend of model-generated output and datasets, emphasizing that the scale of simulated or augmented data is astounding."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shawn voices concerns about \"mode collapse\" and the possibility of models over-optimizing for median use cases, potentially sidelining low-resource applications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Daniel believes that linguistic diversity in large language models can benefit downstream, lower-resource languages."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the discussion, the trio touches upon the evolving landscape of AI, the importance of benchmarks, and the challenges and potential of using models to evaluate other models."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls6-img1",
              "height": 936,
              "width": 936,
              "filename": "abls6-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692149396-abls6-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Grassroots AI Efforts & The Changing Landscape of AI Models"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Shawn Wang"
                      },
                      {
                        "type": "span",
                        "value": " explores the impact and mission of "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Masakhane"
                      },
                      {
                        "type": "span",
                        "value": ", a grassroots organization of African NLP researchers creating relevant technologies for Africa. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Daniel Whitenack"
                      },
                      {
                        "type": "span",
                        "value": " elaborates on the unique challenges faced by African communities, stressing the importance of building AI solutions tailored to specific needs. He cites examples of advanced tech in the U.S., such as tractors running on Kubernetes clusters, versus the contrasting requirements in Africa, like drought identification or disaster relief."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Daniel further delves into the \"AI for Africa\" episodes, highlighting the vast difference in tech applications across regions. He encourages global participation, pointing to Masakhane as a model for how local expertise can shape meaningful technology."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Turning to the topic of AI models, Daniel references an insightful episode from "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Raj Shah"
                      },
                      {
                        "type": "span",
                        "value": " of Hugging Face on the capabilities of Large Language Models (LLMs). The episode discusses various axes like model accessibility, commercial usability, task specificity, and more. This discussion provides a guide for navigating the overwhelming number of models available today."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Both Shawn and Daniel discuss their strategies for staying updated in the rapidly evolving AI landscape. They touch on the role of platforms like Twitter and Hugging Face, emphasizing the importance of keeping an eye on download statistics to gauge model popularity."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Finally, Daniel highlights an interesting collaboration where grassroots efforts led to the creation of language models in six African languages. These models, discovered by Meta on Hugging Face, have now been incorporated into new models released by the tech giant. This showcases the full-circle impact of community-driven AI initiatives, further emphasizing the significance of tailored technological solutions."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls6-img2",
              "height": 936,
              "width": 936,
              "filename": "abls6-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692149410-abls6-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI Landscape Evolution: From Open-Source Advocacy to the Rise of AI Engineering"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a podcast episode, Alessio Fanelli highlights the shift in the AI landscape, pointing to how a proliferation of models are becoming available on platforms like Hugging Face, democratizing access and creating opportunities for more players to participate. The conversation delves into Jonathan Frankle's advocacy for keeping AI models open-source. Shawn Wang and Daniel Whitenack discuss the potential of incorporating audio enhancements to podcasts to maintain engagement. They also discuss a past episode with Kirsten Lum, who addressed the challenges of managing ML tasks in mid-sized organizations compared to larger enterprises."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A significant part of the conversation focuses on the practical implementation of AI in enterprises. Daniel underscores that while many companies experiment with tools like ChatGPT, they often don't progress past superficial usage. He emphasizes the need for businesses to dig deeper into the applications of these models, from prompt engineering to more complex operations. The discussion evolves into the topic of prompt engineering, its hype, and its genuine significance in the AI ecosystem. Shawn Wang introduces the term \"AI engineering,\" suggesting that the discipline is evolving as a subset of software engineering, marking a shift from traditional ML roles to a fusion with general software engineering roles."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls6-img3",
              "height": 936,
              "width": 936,
              "filename": "abls6-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692149425-abls6-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Transitioning to AI: Challenges, the Importance of UX, and the Evolution of Data Labeling"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Unique Challenges of Engineers vs. Data Scientists Transitioning to AI"
                      },
                      {
                        "type": "span",
                        "value": " Daniel Whitenack and Shawn Wang discuss the challenges faced by software engineers and data scientists as they transition into AI-focused roles. For software developers, confronting non-deterministic systems, particularly those they don't fully control, like blackbox models from OpenAI, presents a unique hurdle. They're also working with a model whose capabilities have not been fully tapped into yet."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "From a data scientist's perspective, Whitenack highlights the instinct to jump into model training and fine-tuning, even though significant achievements can be made through data augmentation and prompting. He underscores that data scientists have dealt with uncertainties for a while, but it's different when they aren't in charge of the datasets or the training."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Value of AI User Experience (UX)"
                      },
                      {
                        "type": "span",
                        "value": " Wang introduces the concept of AI UX, emphasizing that the final step of showcasing AI output in a user-friendly manner can be as crucial as training the model. This is evidenced by OpenAI's ChatGPT, which many deem a UX breakthrough. Whitenack concurs, suggesting that while innovations in modeling and data are critical, a poor user experience can nullify those advances. He cites Gmail's smooth AI-powered autocomplete feature as an example of seamless AI integration that provides immediate value to users."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion on Dataset Evolution and Curation"
                      },
                      {
                        "type": "span",
                        "value": " Whitenack mentions the evolution in NLP datasets and the popularity of open-source tools like Label Studio for data labeling. Wang notes that Label Studio has introduced tools for fine-tuning generative AI models. Whitenack discusses the challenges companies face in understanding instruction-tuned models and emphasizes the importance of clear tooling around this process to make it more approachable."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Finally, Wang ponders on why multiple data-labeling companies like Label Box and Label Studio continue to emerge and flourish even when giants like Scale already exist in the market, pointing to the ongoing importance and evolution of data-centric AI."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls6-img4",
              "height": 936,
              "width": 936,
              "filename": "abls6-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692149436-abls6-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Deciphering AI's Shift from Model-Centric to Data-Centric Paradigms"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Customization and The Evolution of Data Use"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Daniel Whitenack"
                      },
                      {
                        "type": "span",
                        "value": " discusses the evolving relationship between AI and businesses, emphasizing a shift from a model-centric to a data-centric approach. Many enterprises, he notes, are now thinking about leveraging state-of-the-art models for their data. This involves either enhancing these models with their data or fine-tuning them, a perspective reflected by the rise of APIs that offer fine-tuning."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Shawn Wang"
                      },
                      {
                        "type": "span",
                        "value": " raises a pertinent point on OpenAI's shift away from fine-tuning for models like GPT-3.5 and GPT-4. He also delves into the gray area of unlabeled datasets for unsupervised and self-supervised learning. The conversation further delves into the challenges of determining the right data mix for training models and highlights the lack of clarity on the best practices."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Whitenack adds insight into the world of data mixes, suggesting that the exact composition of data used by top models like those from OpenAI remains unknown. This creates a challenge for those attempting to emulate such models. He emphasizes the importance of experimenting with different mixes of data to optimize model training. Whitenack encourages AI enthusiasts to remain hands-on, leveraging the array of available tools to gain a better understanding of models and to foster innovation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a lightning round, Whitenack highlights his astonishment at the general-purpose capabilities of large language models, especially beyond traditional NLP tasks. He points out the huge potential for exploration in AI, especially with respect to languages other than English and Mandarin, and also in diverse modalities of communication like sign language. He ends with a call to action, urging individuals to get involved and hands-on with AI models to gain intuition and insight."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "End Note"
                      },
                      {
                        "type": "span",
                        "value": ": The transcript is open source and available on GitHub for improvements."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls6-img5",
              "height": 936,
              "width": 936,
              "filename": "abls6-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692149458-abls6-img5.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "2023's top AI trends, reflect on standout episodes, and share insights on navigating the AI evolution.",
        "title": "Latent Space Podcast 7/2/23 [Summary] AI Trends ",
        "twitterCard": null,
        "image": {
          "width": 1600,
          "height": 532,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
        }
      }
    },
    {
      "id": "190259238",
      "topics": [
        "Hardware",
        "LLM",
        "Summary"
      ],
      "title": "Latent Space Podcast 6/20/23 [Summary] - Commoditizing the Petaflop — with George Hotz of the tiny corp",
      "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:07:15+01:00",
      "description": "George Hotz of tiny corp challenges Nvidia & Google! Dive into the world of AMD collaborations, insights on ggml, Mojo, Elon & GPT-4, plus a peek into AI Girlfriend. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/geohot#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Commoditizing the Petaflop — with George Hotz of the tiny corp"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Summary of Latent Space Podcast with Swyx, Alessio, and Guest Geohot (George Hotz)"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Introduction"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx is the writer and editor of Latent Space."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio is Partner and CTO in residence at Decibel Partners."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Geohot (George Hotz) is the guest, known for his pioneering hacks such as unlocking the first iPhone, breaching the PS3 system, and founding Comma.ai. He has a controversial history with tech giants and regulatory authorities."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion Points"
                      },
                      {
                        "type": "span",
                        "value": ":\nGeohot has concerns about the closed nature of some major tech players in the AI space, emphasizing the need for open-source and accessible tools."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The interview is peppered with technical insights, discussions on AI's future, and Geohot's experiences and beliefs."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Geohot's Achievements"
                      },
                      {
                        "type": "span",
                        "value": ": Traded the unlocked iPhone for a car and iPhones, hacked PS3, faced a lawsuit from Sony, started Comma.ai but faced governmental restrictions. He clarifies that his products are for developers, emphasizing the difference between a dev kit and a standard product."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Hero's Journey"
                      },
                      {
                        "type": "span",
                        "value": ": Discussion on Geohot's blog post relating to the concept of \"The Hero's Journey\" and its relation to TinyGrad, a project he's now heavily involved in."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Concerns on AI Regulation"
                      },
                      {
                        "type": "span",
                        "value": ": Geohot expresses concern about potential government restrictions on AI, using Sam Altman's congressional hearing as a pivotal moment that made him realize the importance of his work."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "TinyGrad & TinyCorp"
                      },
                      {
                        "type": "span",
                        "value": ": Geohot emphasizes the need for simplicity in AI and machine learning models, comparing complex and reduced instruction sets. He advocates for a \"RISC\" approach, simplifying the ML process."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Chips Debate"
                      },
                      {
                        "type": "span",
                        "value": ": The discussion revolves around the efficiency of AI chips and the infrastructure required for optimal performance. George suggests that if one can't develop an efficient ML framework for standard GPUs, they can't for a unique chip."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Turing Completeness"
                      },
                      {
                        "type": "span",
                        "value": ": Both George and Swyx discuss the downsides of Turing Completeness in ML. Turing Completeness makes it easier to write codes but isn't always the most efficient. The conversation touches on TPUs, how they are a better option than CUDA, and the problem with closed-source systems like Google's TPU."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Explanation of Systolic Arrays"
                      },
                      {
                        "type": "span",
                        "value": ": An attempt to demystify the concept of Systolic Arrays, which are efficient for power but may not be the best fit for all computations."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-15-at-10-55-40-pm",
              "height": 508,
              "width": 1586,
              "filename": "screenshot-2023-08-15-at-10-55-40-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring TinyGrad: George's Innovation for Streamlined AI Frameworks"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a conversation between Alessio, Swyx, and George, the trio delves into the intricacies and developments surrounding the 'TinyGrad' framework."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "George introduces TinyGrad, highlighting how it was initially restricted to 1,000 lines of code to ensure efficiency. This constraint was eventually lifted once the core framework was established."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He contrasts TinyGrad with platforms like PyTorch, emphasizing the boilerplate code in PyTorch and its complexity."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "TinyGrad's frontend has a design similar to PyTorch, but with additional features and better support for ONNX, exceeding even Core ML's capabilities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "George elaborates on the problems with PyTorch, pointing out its inability to handle complex operations without unnecessary memory transactions. He also touches upon the limitations of PyTorch Lightning and describes his modifications to optimize TinyGrad's API."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A significant feature of TinyGrad is its operation fusing using a concept called 'laziness'. This allows TinyGrad to achieve better efficiency by delaying the execution of operations until necessary, thereby optimizing resource usage."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The framework also offers enhanced debugging tools. By simply activating the \"debug=2\" feature, users can view the precise details of the GPU operations, offering a more intuitive approach to performance analysis."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Despite its advancements, TinyGrad currently lags in performance on NVIDIA and x86 platforms. However, it has proved to be twice as fast as Qualcomm's library when run on Qualcomm GPUs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A notable highlight is that TinyGrad has been successfully deployed in the OpenPilot model for half a year, further validating its practical application."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Overall, while still a work in progress, TinyGrad represents George's vision for a streamlined, efficient, and intuitive AI framework."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img1",
              "height": 936,
              "width": 936,
              "filename": "abls7-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692159336-abls7-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "TinyGrad's Pursuit of Developer Efficiency in the AI World"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George, in conversation with Swyx and Alessio, highlights the considerable lead NVIDIA has in the market due to the millions of man hours put into it compared to Qualcomm. George's venture, TinyGrad, focuses on increased developer efficiency to bridge the performance gap with competitors. He acknowledges some challenges faced with other platforms, such as the complexity of AMD's framework and PyTorch's occasional performance inconsistencies."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "AMD's kernel issues were a pain point, causing frequent system crashes for George. However, after reaching out to AMD's CEO, Lisa Su, he received considerable support and a fixed driver. This experience highlighted the importance of responsive open-source culture in software development."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George praises the importance of good CI (Continuous Integration) for TinyGrad and mentions a possible API adjustment if PyTorch compatibility becomes a hindrance. The conversation briefly touches upon Mojo, an AI project by Chris Lattner, emphasizing the differences in their project paths."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "While TinyGrad's main goal is to commoditize the petaflop, George's immediate business aspiration is to sell his computers at a profit. Some humor was shared around the visual representation of the TinyGrad project and George's quip on \"giving up.\""
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img2",
              "height": 936,
              "width": 936,
              "filename": "abls7-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692159440-abls7-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Decoding Hardware Choices for Advanced AI Implementation"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio, George, and Swyx engage in a discussion about the complexities of hardware design, especially with regards to GPUs for AI. Key highlights include:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio asks George about the metrics he considers when looking at hardware design. George mentions teraflops per second and memory bandwidth."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "George discusses the concept of \"luxury AI computers\" for users, specifically mentioning the potential of running large AI models such as the \"Large Llama\" or \"Large Falcon\". Swyx mentions the FB-16 Llama."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "George and Swyx then dive deep into the technicalities of quantization, specifically int8 and FB16 standards. George is skeptical about some of the quantization standards that are not based on research papers."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx suggests that when dealing with hundreds of billions of parameters, individual quantization may not matter much."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "George emphasizes the challenges in hardware design, especially when trying to integrate multiple GPUs into one system. He explains the complexities of trying to ensure the system is quiet, efficient, and has enough power while remaining practical for a user."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio and George talk about the potential of \"tiny boxes\" as personal compute clusters or mini data centers for individual developers. George envisions these devices as AI hubs for homes, especially for tasks like home robotics. He argues that it's better than sending data to the cloud due to latency and cost concerns."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx points out the benefits of having a personal compute cluster, and George emphasizes its legality under NVIDIA's licensing terms."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They wrap up with a discussion on the limitations of PCIe connections and the need for bandwidth, especially for training massive models."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img2-5",
              "height": 936,
              "width": 936,
              "filename": "abls7-img2-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692159356-abls7-img2-5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Efficiency in AI: A Glimpse into the Future of Compute and Models"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and George discuss the advancements in AI and the push towards more parameter-efficient models. George highlights Comma's approach, emphasizing the importance of cooling and powering AI models in cars. They touch on the privacy and security aspects, emphasizing how significant breaches could lead to a permanent ban of hardware from their network."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George underlines his skepticism about federated training over the internet due to bandwidth limitations. He delves into the idea of \"tiny boxes\" that aim to be the pinnacle of \"flops per dollar\" and \"flops per watt.\" He sees these tiny boxes as potentially revolutionary for businesses seeking efficient training methods."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George's mention of the comparison between compute power and human cognition leads to a discussion on GPT-4, where he outlines the model's parameters and the strategies behind its training. He hints at the consistent improvements in training techniques, highlighting the importance of newer embedding technologies."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Closing on a philosophical note, the conversation veers towards the \"Bitter Lesson\" from Rich Sutton and the age-old debate between compute power and intricate model design."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img3",
              "height": 936,
              "width": 936,
              "filename": "abls7-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692158820-abls7-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Blending AI and Human Perspectives in Tomorrow's Tech Landscape."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George discusses advancements in AI, mentioning how it has surpassed expectations. He contemplates having multiple AI models like LLMs engage in discussions before producing an answer. He believes that traditional coding and AI model expectations need a shift in perspective. At his company, TinyCorp, he aims to be at the forefront of these technological advancements, integrating machine learning seamlessly."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "George moves on to discuss remote work for TinyCorp, emphasizing the company's evolving culture. He introduces a fresh hiring perspective, highlighting the importance of a practical approach over traditional technical screens. George believes in the symbiotic relationship between tools and humans. He introduces the concept of an \"API line\" to explain the distinction between those controlled by technology and those who control it. He sees the future as a hybrid where humans are supercharged by AI tools, rather than being completely replaced by them."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx brings up the \"API line,\" hinting at its origin. The conversation pivots to the evolving dynamics of task allocation and management, touching upon the concept of a \"Kanban board.\""
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio shifts the conversation towards physical robots, specifically humanoid ones. George contrasts Tesla's complex approach to robotics with Comma's simplified version, which uses minimal hardware to turn the robotics problem into a software challenge."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx mentions \"segment anything\" from Facebook, suggesting it as a significant development in computer vision. George expresses his interest in it but emphasizes the value of integrating speech into AI, wishing for a more natural conversational experience with models like LLMs."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img3-5",
              "height": 936,
              "width": 936,
              "filename": "abls7-img3-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692159096-abls7-img3-5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring the Future of AI: From Machine Integration to Eternal Existence"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": " In an intriguing dialogue, George shares his future plans for AI, illustrating a timeline that moves from building hardware infrastructure with Comma, to software with TinyCorp, culminating in the creation of an 'AI Girlfriend.' George challenges the prevalent notion of neural merging through methods like Neuralink, suggesting that a deeper, more organic connection can exist between humans and AI. Referring to the vast amount of his own data already available online, he speculates on the concept of immortality through digitization. The conversation also delves into the nature and challenges of machine learning, with George emphasizing the importance of accessibility and the quest for improved efficiency. The chat winds down with George discussing 'six tricks' that might propel AI to new heights and sharing insights about transformers in AI."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img4",
              "height": 936,
              "width": 936,
              "filename": "abls7-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692158797-abls7-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Effective Accelerationism, Avatar 2 Critiques, and the AI-Human Content Dilemma"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx opens the discussion with Mark Andreessen's support for effective accelerationism (IAC) and George's criticism of it. George feels that only the left takes ideologies seriously, suggesting that they can effectively mobilize energy around ideologies, unlike the right."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation transitions to two figures named Sam. One is incarcerated, while both are seeking regulation in their respective domains. Swyx and George debate the intentions behind certain key figures' advocacy for IAC and EA. They also discuss Mark Andreessen's late realization about potential deceit in the political sphere, which George thinks was already apparent to many others."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio shifts the topic to the movie, \"Avatar 2.\" George expresses disappointment with the film, saying he rewrote the script to better emphasize character emotions. Swyx attributes the movie's shortcomings to its writing, even though it had impressive CGI."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio and George discuss the possibility of AI, like ChatGPT, being responsible for the movie's script. George raises concerns about distinguishing between AI and human-written content, especially in contexts like spam. He suggests a model where sending emails could have a small cost, deterring spammers."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Closing the discussion, George promotes TinyGrad, aspiring for it to be a significant competitor in the tech space and to eventually innovate in numerous areas, starting with GPUs and scaling up to self-reproducing robots."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio and Swyx thank George for his insights."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls7-img5",
              "height": 936,
              "width": 936,
              "filename": "abls7-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692158781-abls7-img5.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "George Hotz of tiny corp challenges Nvidia & Google! AMD collaborations, insights on ggml, Mojo, Elon & GPT-4, plus a peek into AI Girlfriend. ",
        "title": "Latent Space Podcast 6/20/23 [Summary] - George Hotz ",
        "twitterCard": null,
        "image": {
          "width": 1586,
          "height": 508,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
        }
      }
    },
    {
      "id": "190259294",
      "topics": [
        "LLM",
        "Functions",
        "Summary"
      ],
      "title": "Latent Space Podcast 6/14/23 [Summary] - Emergency Pod: OpenAI's new Functions API, 75% Price Drop, 4x Context Length (w/ Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin et al)",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "Explore the June 2023 OpenAI updates with top AI engineers from Scale, Microsoft, Pinecone, & Huggingface. Dive into the Code x LLM paradigms and discover Recursive Function Agents.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/function-agents#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Emergency Pod: OpenAI's new Functions API, 75% Price Drop, 4x Context Length (w/ Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin et al)"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": " In this special emergency podcast episode, Swyx dives into the June 2023 updates from OpenAI. Key highlights include:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The unveiling of OpenAI's new Functions API which was previously available only for ChatGPT Plus subscribers. This API allows developers to introduce a new 'function' role, making it easier to structure the output, particularly in formats like JSON."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The significant 75% price reduction for embeddings. This is especially noteworthy following a previous 90% reduction, marking OpenAI's push towards making AI more accessible. The cost to embed the entire internet has gone from $50 million to an impressive $12.5 million."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A 4x increase in context length for the GPT-3.5 model, moving from 4,000 to 16,000 tokens."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Observations on long context models indicating that they may not retain context as efficiently across the entire span."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The podcast also touches on discussions about embedding costs, potential use-cases, and comparisons of GPT versions."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Guests Alex Volkov and others express excitement about the price drops and new models but also share some reservations about the reliability of the API in certain applications."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-16-at-5-32-29-pm",
              "height": 606,
              "width": 1626,
              "filename": "screenshot-2023-08-16-at-5-32-29-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "OpenAI's New Functions API: Developer Reactions & Comparisons"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion primarily revolved around OpenAI's new release, addressing the functionality and the potential implications for developers and other AI services."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Introduction to Riley Goodside"
                      },
                      {
                        "type": "span",
                        "value": " - He is known for persuading Bard, an AI model, to return results in JSON format. He praises OpenAI for responding to developer needs and maintaining a \"hacker ethos\". He notes that instead of trying to make the output syntactically perfect, OpenAI has fine-tuned it, though there might be instances of inexact syntax."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Simon Willison's Input"
                      },
                      {
                        "type": "span",
                        "value": " - He discusses the pattern of asking the AI to run functions. Simon appreciates OpenAI's ability to identify and deliver what developers truly want. He's excited about the ability to integrate tools with the model. He also mentions the security implications associated with prompt injection and the need for user approval for actions that might modify the world state."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Eric Elliott's Perspective"
                      },
                      {
                        "type": "span",
                        "value": " - Creator of Sudo Lang, he recommends defining an interface inside prompts for accuracy. He's observed that when the AI is prompted with pseudo code, it tends to be more compliant and accurate."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion on Functions API and Agents"
                      },
                      {
                        "type": "span",
                        "value": " - The conversation shifts to how this new release from OpenAI affects the agent-making space, where tools are created and prompting is used to ask the AI to run those tools."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Contrast with Google Vertex"
                      },
                      {
                        "type": "span",
                        "value": " - Vertex from Google is also known to offer a similar functionality where developers can specify a JSON schema."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Overall, the participants discuss the implications, potential challenges, and the value of the new OpenAI release, emphasizing the importance of reliable outputs and the balance between developer needs and security concerns."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img1",
              "height": 956,
              "width": 956,
              "filename": "abls8-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692224946-abls8-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Challenges and Future of Code-to-English Interface in AI Systems"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Stefania Druga, a researcher with Microsoft Research, discusses her experiences with Fixie AI, emphasizing the spectrum of users from no-code enthusiasts to Python programmers. She raises concerns about the challenges of AI 'hallucinations', controlling outputs, and the balance between natural language prompts and traditional coding. Riley Goodside remarks on the potential shift from English language prompting back to more structured prompts, due to the ambiguity and unpredictability of natural language. The excitement around language models, he mentions, is the potential to democratize automation. Alex Volkov expresses enthusiasm about a transition akin to moving from JavaScript to TypeScript. Roie, from Pinecone, focuses on the surprising reduction in embedding costs, pondering the reasons behind the drastic price drop. Swyx chimes in with potential explanations, mentioning infrastructure improvements and a shift in model versions that could have led to cheaper inferences. He also comments on the strategic significance of reducing embedding costs to potentially lock users into OpenAI's ecosystem. Alex stresses OpenAI's stance on not using data provided via its API for training."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img2-5",
              "height": 956,
              "width": 956,
              "filename": "abls8-img2-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225139-abls8-img2-5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Embeddings and Dynamic Function Selection in AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Xenova and Huggingface on AI Embeddings"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex Volkov"
                              },
                              {
                                "type": "span",
                                "value": " introduces Joshua ("
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Xenova)"
                              },
                              {
                                "type": "span",
                                "value": " from "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Transformers.js"
                              },
                              {
                                "type": "span",
                                "value": " and a recent employee at "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Huggingface"
                              },
                              {
                                "type": "span",
                                "value": "."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussion ensues about the advantages of running embeddings on the client side for reasons such as data privacy and lower costs. Xenova acknowledges the benefits of both large-scale embeddings offered by OpenAI and client-side embeddings. He mentions the constraint on embedding dimensions when run locally."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex"
                              },
                              {
                                "type": "span",
                                "value": " appreciates the utility of "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Transformers.js"
                              },
                              {
                                "type": "span",
                                "value": ", indicating its value extends beyond just experimental use cases."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Function Selection in AI Models"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The panel transitions to discussing the dynamic selection of functions by OpenAI. They address the ability for OpenAI to determine which function to run based on user input."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " raises concerns about the unclear limit on the number of functions that can be assigned. He discusses the contrast between using many functions and having a few highly capable functions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon Willison"
                              },
                              {
                                "type": "span",
                                "value": " proposes having sophisticated functions that are domain-specific, suggesting SQL or even JavaScript as potential languages."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex"
                              },
                              {
                                "type": "span",
                                "value": " highlights a new feature where the AI model can either choose a function on its own or be explicitly told which function to run based on user input. He mentions a new role in the chat interface called "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "function role"
                              },
                              {
                                "type": "span",
                                "value": " to identify which function generated a particular output."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The panel concludes with the idea that decision-making in choosing or directing functions will be a critical aspect of future AI applications."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img3",
              "height": 956,
              "width": 956,
              "filename": "abls8-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225154-abls8-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Leveraging Function API for Advanced Code Agents"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex Volkov"
                              },
                              {
                                "type": "span",
                                "value": " highlighted the potential of utilizing user and system input to innovate function outputs. He envisioned a function role that would be adaptable to the user's needs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " identified the challenges faced by developers with code generation tools, emphasizing the need for more inference time and flexibility in error correction. Swyx introduced the idea of a 'code agent' created through three pathways: generating, testing, and calling existing code."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Stefania Druga"
                              },
                              {
                                "type": "span",
                                "value": " discussed the blurred lines between functions and agents. She mentioned Google's paper, \"Reveal\", which presented an innovative method of encoding diverse knowledge sources into a memory structure for faster response time."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Riley Goodside"
                              },
                              {
                                "type": "span",
                                "value": " saw potential in harnessing AI's documentation expertise to predict software behavior based on descriptions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nisten"
                              },
                              {
                                "type": "span",
                                "value": " talked about the limitations of the model's context window, noting that while the input capacity had increased, the output still seemed limited."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Mayo"
                              },
                              {
                                "type": "span",
                                "value": " expressed skepticism about the hype, questioning the tangible benefits of a larger context window, especially with the rise of retrieval-based approaches."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex Volkov"
                              },
                              {
                                "type": "span",
                                "value": " responded, pointing out the convenience of the larger context window for developers who deal with variable user input sizes."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discourse suggests that while the Function API has exciting potential, there are several challenges and considerations to account for in its practical application."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img5",
              "height": 956,
              "width": 956,
              "filename": "abls8-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225254-abls8-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The 2 Code x LLM Paradigms and Evolving AI Interactions"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Roie expresses interest in Sean's perspective on the distinction between two prevailing paradigms related to language models and code. Swyx shares his view that effective utilization of language models demands a solid grounding in code. He emphasizes the growing tension between two approaches:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Retrieval Augmented Generation"
                              },
                              {
                                "type": "span",
                                "value": ": Where the model takes center stage with surrounding code (LLM Core with a code shell)."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Agent World"
                              },
                              {
                                "type": "span",
                                "value": ": Where the model plays a specific, limited role and the code interprets tasks (LM shell with a code core)."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx acknowledges OpenAI's recent updates, suggesting a shift from the first paradigm to the second. This transition enhances the capability of language models to more seamlessly invoke functions."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Mayo and Alex discuss the evolution from traditional prompt engineering to fine-tuning. They observe that earlier, achieving specific outputs required intricate prompting, but now there's a directness to the tooling, which simplifies things but also has its drawbacks."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Riley points out the benefits of the updated model, noting it streamlines certain tasks but may come with challenges, like the model \"breaking character.\" He suggests that the model should be seen as a reasoning tool, emphasizing the potential of structured outputs."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Stefania predicts that smaller AI models are the future due to benefits like security, affordability, and decentralization. She emphasizes the need for models to be efficient for real-time applications and shares concerns about over-reliance on chat interfaces, which may not be scalable for every application."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Riley conclude that, despite OpenAI's current focus on chat, it's essential to think beyond this format and consider the broader possibilities of AI and UX interactions."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img8",
              "height": 956,
              "width": 956,
              "filename": "abls8-img8.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225542-abls8-img8.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Double-Edged Sword: AI's Power and Vulnerabilities Explored"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex Volkov"
                              },
                              {
                                "type": "span",
                                "value": " opened the conversation about the security concerns tied to developer-friendly tools. He specifically queried about the potential to address prompt injection issues with the new tools."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Simon Willison"
                              },
                              {
                                "type": "span",
                                "value": " expressed concerns, emphasizing that while the new updates reduce the barrier to function access, they could also lead to unintended consequences. He cited the challenge of prompt injections becoming more sophisticated and the need to consider reversibility in AI actions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussing Bing Chat, Alex and Simon touched upon the ability of modern systems to detect prompt injections. Simon voiced skepticism about the effectiveness of filters catching prompt injections, particularly when up against dedicated hackers."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " suggested marking functions as \"reversible\" or \"requires human input\" as potential safety measures."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Nisten"
                              },
                              {
                                "type": "span",
                                "value": " voiced enthusiasm for the game-changing nature of functions, emphasizing their potential to revolutionize operations and scalability in AI. However, he also acknowledged the possible security holes."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Riley Goodside"
                              },
                              {
                                "type": "span",
                                "value": " urged caution, stating that while advancements are exciting, there are still inherent risks such as AI hallucinations. He also highlighted that similar guardrails have been seen in other frameworks, urging moderation in the excitement."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alex Volkov"
                              },
                              {
                                "type": "span",
                                "value": " defended the significance of the advancements, hinting at the success of past OpenAI projects and their potential for transformative change."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The panel touched upon the evolution of function integration, with Simon highlighting how its inclusion in the core platform reduces friction and inspires confidence."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Stefania Druga"
                              },
                              {
                                "type": "span",
                                "value": " mentioned the newly launched Garak, a tool for security probing, and pondered on the ethical implications of exposing vulnerabilities. She left with a thought-provoking question about the future demands from OpenAI."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion ended with an invitation for participants to brainstorm on potential projects and innovations using the new tools."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img7",
              "height": 956,
              "width": 956,
              "filename": "abls8-img7.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225281-abls8-img7.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "GPT Model Discussions and Future Wishes"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "GPT Model Upgrades:"
                              },
                              {
                                "type": "span",
                                "value": " Alex Volkov emphasized the upgrade from the 3.5 model to the current version. He's curious if the new model adheres to system messages more efficiently. Simon Willison discussed how the new models are now more \"steerable\" and highlighted the importance of stability. Simon also mentioned that the problem of easily injecting prompts in 3.5 might be resolved in this upgrade but clarified that it hasn't been officially declared as solved."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "JSONformer Discussion:"
                              },
                              {
                                "type": "span",
                                "value": " Mayo introduced a topic about JSONformer, a tool for generating structured data. Simon provided an explanation of how it functions and its capabilities. The group speculated about OpenAI's choices in terms of implementing similar methods."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Closing Comments - Desired Features:"
                              },
                              {
                                "type": "span",
                                "value": " Participants expressed their hopes for future developments:"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Stefania Druga: Wished for knowledge graphs and better data retrieval."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Simon Willison: Desired widgets in ChatGPT to make it more interactive."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Nisten: Advocated for a 30B open-source model from OpenAI."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Far El: Echoed the desire for more open-source models."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Roie: Wanted an 80% cost reduction for the 32k GPT-4."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Riley Goodside: Expressed excitement for the upcoming virtual hackathon with substantial prizes."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "OpenAI's Open Source Debate:"
                              },
                              {
                                "type": "span",
                                "value": " There was a unanimous desire for OpenAI to lean more into open sourcing their models, as emphasized by Mayo, who pointed out the irony in the company's name."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Developer Perspectives and Future Possibilities:"
                              },
                              {
                                "type": "span",
                                "value": " swyx (Sean) mentioned the concept of \"Franken models\" and the potential to use larger models to guide smaller, specialized models. He expressed excitement about exploring this area and rewriting his developer agent."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Podcasts and Future Developments:"
                              },
                              {
                                "type": "span",
                                "value": " Alex Volkov gave a shoutout to swyx's podcast, Latent Space. swyx also teased an upcoming interview with George Hotz, hinting at some intriguing developments in the tech world."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls8-img6",
              "height": 956,
              "width": 956,
              "filename": "abls8-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692225267-abls8-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Explore the June 2023 OpenAI updates with top AI engineers from Scale, Microsoft, Pinecone, & Huggingface. ",
        "title": "Latent Space Podcast 6/20/23 [Summary] - Emergency Pod",
        "twitterCard": null,
        "image": {
          "width": 1626,
          "height": 606,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
        }
      }
    },
    {
      "id": "190259333",
      "topics": [
        "LLM",
        "Summary",
        "UX"
      ],
      "title": "Latent Space Podcast 6/8/23 [Summary] - From RLHF to RLHB: The Case for Learning from Human Behavior - with Jeffrey Wang and Joe Reeve of Amplitude",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "Explore AI & analytics with Jeffrey Wang & Joe Reeve on Latent Space Live! Dive into why AI values Analytics and the power of first-party behavioral data. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/amplitude#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "From RLHF to RLHB: The Case for Learning from Human Behavior - with Jeffrey Wang and Joe Reeve of Amplitude"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI at Amplitude with Alessio, Jeffrey, Joe, and Swyx"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio, the host, starts by explaining the podcast's focus on AI research and its application, emphasizing the show's technical orientation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Jeffrey, a co-founder and Chief Architect at Amplitude, introduces himself. He’s been in the field of product analytics for about a decade, helping businesses understand user behavior data to make informed product decisions. He finds recent trends in AI especially exciting, recognizing AI's increasing importance in product data and development."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Joe Reeve shares his background in tech startups and mentions his current role leading AI R&D at Amplitude. Both he and Jeffrey express enthusiasm for the innovations they're exploring."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion moves to Amplitude's journey with AI. Jeffrey provides an overview: Amplitude's primary goal is helping customers utilize their product data to enhance their offerings. With digital products generating vast amounts of data, sifting through this information is challenging. Amplitude aims to bridge the gap between the massive data and actionable insights, viewing this as an AI-centric problem. He also recounts the origin of Amplitude, emphasizing the significance of product analytics in the gaming sector, where meticulous analysis of user data is critical."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Drawing parallels, Swyx mentions other tech giants like Slack and Discord that originated from gaming ventures."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation shifts to current R&D efforts. Joe highlights their dual approach: implementing AI in their products and supporting their customers in doing the same. They've developed a framework to identify areas for AI integration by examining collaboration touchpoints, deeply embedding features, and creating supplementary AI tools. One of their recent tools allows users to input queries, which are then translated into charts. However, they faced challenges with AI models losing context or generating errors."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, the conversation offers insights into how a tech company like Amplitude is navigating the ever-evolving world of AI, dealing with challenges, and envisioning the future."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-18-at-3-17-04-pm",
              "height": 550,
              "width": 1674,
              "filename": "screenshot-2023-08-18-at-3-17-04-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Harnessing AI in Product Evolution: Challenges and Breakthroughs"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Joe discuss the evolution and application of machine learning models (ML) and large language models (LLM) in product development."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Products Released"
                              },
                              {
                                "type": "span",
                                "value": ": Joe elaborates on a feature they rolled out called \"question to chart\" which allows users to ask a question and get a chart as a response. This new feature is part of their LLM initiative and was rolled out to AI design partners."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Contrast with Existing ML Models"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx points out a potential conflict in using both traditional ML models and the new AI initiatives. Joe explains that they utilize traditional ML to narrow down data for LLMs, which handles more complex reasoning."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Challenges Faced"
                              },
                              {
                                "type": "span",
                                "value": ": Joe mentions two key pain points: hallucination and multi-query issues. To address these, they're tracking inferences and trying to understand why certain models fail."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Utilizing AI in Amplitude Products"
                              },
                              {
                                "type": "span",
                                "value": ": Joe highlights that they use their own product, Amplitude, to measure and improve AI's performance. They are also working on helping companies build AI products with Amplitude."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Measurement of AI Effectiveness"
                              },
                              {
                                "type": "span",
                                "value": ": Joe touches upon the challenge of assessing AI's performance. Many companies struggle with understanding how effective their AI models are. By measuring user behaviors, like content sharing, Joe believes that they can get a more accurate gauge of AI's value."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Potential for A-B Testing with AI"
                              },
                              {
                                "type": "span",
                                "value": ": They discuss the idea of generating variations in user interfaces and content with AI and testing their effectiveness. This leads to a broader conversation about self-improving products and how generative AI can automate processes. Jeffrey gives an example of how generative models might revolutionize copywriting in the future by auto-generating and optimizing content."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, the conversation revolves around the potential of AI in product development, its challenges, and the innovative solutions being created to address them."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls10-img1",
              "height": 956,
              "width": 956,
              "filename": "abls10-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692389086-abls10-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Just-In-Time UIs and The Evolution of Analytics"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Shaping the Future of User-Interface with Advanced Analytics and AI"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alessio"
                              },
                              {
                                "type": "span",
                                "value": " delves into the concept of Just-In-Time UIs, discussing the preference-based user interactions. He mentions how platforms like Amplitude have transitioned from solely dashboard-driven designs to offering tailored displays based on user preferences."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Jeffrey"
                              },
                              {
                                "type": "span",
                                "value": " envisions multiple paths for the future of analytics. He champions the precision of SQL and code, emphasizing their clarity over natural language. However, he also recognizes the utility of natural language interfaces for those unfamiliar with data structures. Jeffrey believes the balance between natural language expressiveness and code precision will evolve, with natural language leading the initial inquiry phase and precise code defining specifics."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Joe"
                              },
                              {
                                "type": "span",
                                "value": " emphasizes the potential of models becoming more integrated features. He stresses the need for users to understand the model's actions and maintain the ability to intervene. Joe also highlights the importance of providing detailed feedback data for continuous model improvement."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " points out the challenges tied to chat interfaces, raising questions about how to optimize user interaction time. He references Copilot's unique metrics on code retention as a successful approach to gauge product efficacy."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Jeffrey and Joe"
                              },
                              {
                                "type": "span",
                                "value": " further elaborate on selecting the right AI models, with an inclination towards using general models for exploration. They note the efficiency and cost-effectiveness of embedding-based approaches once the utility of a general model is confirmed. Both stress the importance of understanding user intent, with Jeffrey emphasizing the challenges of quantifying match quality with LLMs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The discussion ends with "
                              },
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alessio"
                              },
                              {
                                "type": "span",
                                "value": " posing a thought on the interplay between the quality of the model versus the volume and quality of data, with Jeffrey noting that both are crucial components in the AI ecosystem."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls10-img2",
              "height": 956,
              "width": 956,
              "filename": "abls10-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692389129-abls10-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Striking a Balance: Ethical AI Training and the Nature of Intelligence"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a discussion between Swyx, Joe, Jeffrey, and Alessio, the main topic revolved around the ethics and best practices of training AI models on user data, especially when users might not be fully aware."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Ethics on Training with User Data"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Swyx initiated the conversation, inquiring about the ethical implications of using user data for training without their knowledge."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Joe emphasized the importance of keeping Personally Identifiable Information (PII) away from training data to prevent unintended information leakage, such as an AI accidentally generating a social security number. Joe noted ongoing experiments to strip PII from prompts and other data while still allowing models to operate effectively."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "User Privacy & Tracking"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Jeffrey spoke about the spectrum of user privacy concerning tracking. On one end, some users don't want any tracking, while on the other, there are those who are fine with being tracked across the internet. The challenge is to strike a balance between tracking everything and having insufficient data to improve products. Jeffrey underscored the importance of using pseudo-anonymized first-party data to improve products without breaching privacy."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Creativity & Intelligence in AI"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "During a lightning round of questions, both Jeffrey and Joe touched on the progress of AI in areas previously thought to be purely human domains, like creativity. Jeffrey was surprised by the creative potential of AI in tasks like image and text generation, while Joe discussed the rapid advancements in AI, especially how they've been integrated with the internet."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Defining Intelligence"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Jeffrey posed a fundamental question about the nature of intelligence, noting how traditional benchmarks of human intelligence, like chess, have been surpassed by AI. The conversation touched on concepts like free will and the efficiency of the human brain compared to artificial systems."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Takeaways"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Jeffrey stressed that we are still in the early stages of the AI revolution, implying that there's a lot more to come. Joe highlighted the importance of letting machines augment human capabilities rather than replace them, advocating for the harmony between human skills and machine capabilities."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The session ended with Swyx opening up the floor for audience questions."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls10-img5",
              "height": 956,
              "width": 956,
              "filename": "abls10-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692389175-abls10-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Customized AI Query Mechanisms in Chatbots"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Audience Inquiry"
                      },
                      {
                        "type": "span",
                        "value": ": A member of the audience inquired about the inner workings of an AI-driven chatbot, particularly curious about its model and how it turns single English queries into multiple sub-queries."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Joe's Response"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Their system uses a custom query engine instead of SQL."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They categorize questions to determine chart types, for instance, if they should use segmentation, line, or funnel charts, along with chart naming."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They initially considered Lang chain, a tool great for prototyping, but found it limiting and instead developed an internal wrapper with TypeScript. This allows them to write code and infer transactions within their system."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Currently, they use GPT-3.5 but are considering integrating GPT-4 and other models in the future. They also have fallback plans for clients who prefer not to use OpenAI by employing internal or open-source models trained on smaller datasets."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Jeffrey's Insights"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The key to their system's effectiveness is breaking down problems sufficiently, allowing them to guide the model to make specific decisions like chart type selection."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "GPT models can be overwhelmed by too much information, hence their method of providing contextual prompts and breaking down tasks results in a higher quality output."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Swyx's Questions & Insights"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx was interested in their experience with LangChain and their choice of databases."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Joe mentioned they have been using embedding or vector search in production for a while with Postgres, and recently shifted to PG Vector."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx highlighted the importance of separating taxonomies from actual data to ensure data protection and prevent prompt injection."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, the discussion revolved around the intricacies of implementing a chatbot, the choice of models, and ensuring both efficiency and security in their system."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls10-img6",
              "height": 956,
              "width": 956,
              "filename": "abls10-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692389365-abls10-img6.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Unpacking Future Potential: Behavioral AI and Predictive Patterns"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Audience member inquires about a novel model, hinting at an \"Amplitude GPT\", trained on user behavior data and wonders about its capabilities. Jeffrey elucidates the potential of such models. He anticipates superior predictive capabilities, especially predicting user group behaviors, such as churning, purchasing, or upselling. Jeffrey's vision extends to understanding deeper patterns in sessions, enabling unsupervised categorization of users based on future outcomes. This would assist in discerning the reasons behind behavioral disparities and attempt to answer challenging questions on causation in product analytics. Furthermore, Jeffrey highlights the challenges of data interpretation in tools that automatically record user sessions due to the noise in data. Ideally, a perfect behavioral model could interpret such data, eliminating the need for manual instrumentation. While such a model is still in the realm of speculation, the aspiration is to make the analytics process seamless and more intuitive in the future. The conversation concludes with Swyx expressing gratitude to the listeners."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls10-img4",
              "height": 956,
              "width": 956,
              "filename": "abls10-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692389240-abls10-img4.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Explore AI & analytics with Jeffrey Wang & Joe Reeve on Latent Space Live! Dive into why AI values Analytics and the power of first-party behavioral data. ",
        "title": "Latent Space Podcast 6/8/23 [Summary] - From RLHF to RLHB",
        "twitterCard": null,
        "image": {
          "width": 1674,
          "height": 550,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
        }
      }
    },
    {
      "id": "190260528",
      "topics": [
        "Summary",
        "LLM",
        "UX"
      ],
      "title": "Latent Space Podcast 6/1/23 [Summary] - Building the AI × UX Scenius — with Linus Lee of Notion AI",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "Explore Notion AI's transformative approach to AI and UX. Dive into the future of AI-augmented workspaces, the value beyond chat interfaces, and insights on effective knowledge work. Recap of AI×UX NYC meetup included!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/ai-interfaces-and-notion#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Building the AI × UX Scenius — with Linus Lee of Notion AI"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "On the Road with Latent Space: A Visit to Notion New York"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a special episode of the Latent Space podcast, Alessio from Decibel Partners and Swyx from Latent Space, forgo their usual setting to interview Linus at the aesthetically consistent Notion New York headquarters. Linus reflects on Notion's distinctive design ethos which emanates from the company's founders, with a unique taste and focus."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Discussing Linus's diverse background, the trio delve into his journey from studying computer science at Berkeley to his prolific stint with multiple tech-based entities such as Replit, CatalystX, Hack Club, IdeaFlow, and finally, Notion. They touch upon Linus's Indiana roots, highlighting his fondness for small towns, despite now thriving in the urban buzz of New York."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A significant portion of the conversation centers on the AIUX SF meetup, a gathering that originated from a Twitter conversation and saw a confluence of machine learning and human-computer interaction enthusiasts. The meetup was an effort to bridge the gap between AI technology and intuitive user interfaces. Here, they reminisce about various innovations presented, especially those that moved beyond traditional auto-complete functions. These included Amelia's tool allowing users to alter text tone using brushes and Linus's prototype featuring semantic attribute sliders for text modification."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Towards the end, Alessio and Swyx touch upon Linus's penchant for side projects. Linus shares his philosophy for successful side hustling, emphasizing the importance of manageable scopes, using familiar tools, and consistently learning and iterating."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout, the theme of innovation, the love for creating, and the joy of exploring new technological intersections are evident."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-18-at-4-28-51-pm",
              "height": 546,
              "width": 1614,
              "filename": "screenshot-2023-08-18-at-4-28-51-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring AIUX, Notion AI, and Linus's Sabbatical Journey into AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Alessio interview Linus about AI User Experience (AIUX) and its application, particularly referencing Notion AI. The key points are:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Knowledge Work & AI"
                              },
                              {
                                "type": "span",
                                "value": ": Linus emphasizes that knowledge work is not just about content generation. It's also about understanding, synthesizing, proposing actions, and other knowledge-to-knowledge tasks. AI can greatly assist in these areas."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Potential of AI beyond Text Generation"
                              },
                              {
                                "type": "span",
                                "value": ": While current uses of AI, like in Notion AI, are heavily geared towards text generation, its potential is much broader. Linus talks about using AI for knowledge synthesis and understanding, as well as for automation, like writing code or proposing actions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Flexibility vs. Intuitiveness in Product Design"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio and Linus discuss the trade-offs in product design when using AI. While AI provides unparalleled flexibility, it can overwhelm users if not presented with some guardrails. A key design challenge is to guide users towards actions that AI is good at while also setting their expectations."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Novelty & Flexibility in AI Products"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio contemplates the current enthusiasm in \"prompting\" tools and wonders if, in a few years, most AI products will have a built-in intuitive path, thereby negating the need for users to prompt. Linus thinks that while guardrails and set pathways will likely become more prevalent, having a fully custom prompt or action can remain as an \"escape hatch\" for power users and for discovering new use cases."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Linus's Personal Journey"
                              },
                              {
                                "type": "span",
                                "value": ": Linus shares his transition from web engineering to focusing on AI. He took a year off in 2022, partly as a sabbatical and partly to explore AI more deeply. This period gave him insights into the capabilities and potential of AI, which eventually led him to join Notion."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx is keen on understanding Linus's personal journey and motivations, especially his decision to take a sabbatical to deeply dive into the realm of AI before joining Notion"
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img1",
              "height": 956,
              "width": 956,
              "filename": "abls11-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392605-abls11-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Evolution and Influence of Notation and Interface in the Digital Age"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Linus engage in a deep dialogue about the role of notation in various domains, from medicine to software engineering. Linus emphasizes the importance of custom notations in each discipline that elevates understanding beyond just raw words. This concept, dubbed \"Notational Intelligence,\" highlights the significance of tailored notations allowing experts to work with higher-level concepts with ease."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Linus asserts that while text is a universal notation, its broad scope can be limiting in specialized domains, suggesting a need for advancements in this area. As the conversation segues into the realm of user interfaces (UI), Swyx underscores that while constraints can birth creativity, they alone are insufficient for invention. This leads Linus to share his experience at Notion, emphasizing the pivotal role of dominant market players in defining UI paradigms post the emergence of foundational technologies, such as personal computers and mobile devices."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Diving into the history of user experience, Swyx brings up the iPhone’s influence, hinting at how a small team's UI choices became the standard for modern smartphones. The conversation then touches upon the persistence of the QWERTY keyboard layout despite its lack of ergonomic efficiency and its origins in typewriters."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Finally, Linus offers a unique perspective on the evolution of buttons. From their mechanical origins, where they physically completed circuits, to today's digital world, where on-screen buttons merely simulate the older, physical version. This, Linus says, is a testament to the \"cascade of conceptual backwards compatibility\" in design that continues to shape our digital interactions."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img2",
              "height": 956,
              "width": 956,
              "filename": "abls11-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392640-abls11-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Evolution of Design and the Role of Agents in AI Workspaces."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio initiates a conversation around the love-hate relationship with skeuomorphic design, reminiscing about early iPhone icons. Linus counters by drawing a comparison between design trends and fashion, suggesting skeuomorphism's recurring popularity. Linus goes on to elaborate on how skeuomorphism provides users with an intuitive mental model to engage with interfaces, such as iPhone volume controls."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio shifts the discussion to \"agents\" and how their interfaces remain challenging. He highlights how interfaces like Calendly act as agents, albeit without real AI. Swyx points out how this approach has room for improvement, such as using AI agents for more personalized interactions."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation moves on to the complexities in designing agent interfaces, with Linus emphasizing the balance between trust and control. Linus states that while it's vital for users to trust AI agents, it's equally crucial for users to control and constrain an agent's outputs. He adds that, particularly in collaboration platforms like Notion, it's essential to delineate AI-generated content from human-produced content."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Linus further discuss the potential of agents and the challenges in managing their automated actions. They ponder over reversible changes and batching edits for user approval. Both agree on the parallels between human-AI and human-human collaborations, cautioning against solely anthropomorphizing AI."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Concluding, Swyx asks Linus to define Notion. Linus defines it as a \"connected workspace,\" a hub for company docs, wikis, and workflows. He explains that the core strength of Notion lies in its \"block\" abstraction, where every element, be it a paragraph or page, is a block, emphasizing its fluidity and modular nature."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img3",
              "height": 956,
              "width": 956,
              "filename": "abls11-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392694-abls11-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Notion AI: The Journey to Integrated Artificial Intelligence"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx inquires about Notion AI, seeing it as a startup within Notion itself, and wonders how committed Notion is to the AI wave."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Linus explains that Notion AI originated from an offsite hack weekend by Ivan and Simon. They were inspired by GPT-3 and the broader idea that software tools should be tailored to individual needs, leading to the creation of Notion AI. Notion envisions AI as a crucial part of its platform, just as databases and blocks are."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio brings up the balance between user expectations and innovation, questioning how Notion reconciles the two."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Linus believes that having a vast user base is both a challenge and an advantage. Understanding the diverse uses of Notion helps them determine how to implement AI within it."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx notes that many users struggle with creatively employing Notion AI, feeling restricted by the tool’s open-ended nature."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Linus admits that generality can be intimidating and acknowledges the challenge in striking a balance. He details the different AI facets within Notion: AI writer for content creation, AI block for automatically summarizing content, and AI autofill for databases."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio questions how backlinks, a notable feature, fit into the AI evolution, considering its potential for interlinking documents and concepts."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Linus posits that, just as code files in programming can be seen as a graph of interconnected functions, text documents can be viewed similarly. A future challenge and opportunity lie in creating tools or AIs that can navigate and understand this complex network of knowledge."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img4",
              "height": 956,
              "width": 956,
              "filename": "abls11-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392711-abls11-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Prompts, AI, and the Evolution of Interface Engineering"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx engages in a deep dive with Linus about prompt engineering at Notion, a relatively new yet rapidly evolving discipline."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Prompt Engineering at Notion:"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Notion uses prompts that are complex, particularly in the task of summarizing a wide range of potential content, from meeting notes to news articles."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Notion transitioned from instruction-following models to chat-based ones like Claude and ChatGPT Turbo, which made few-shot prompting easier."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Multilingual prompt support is critical for Notion. This involves handling numerous languages, ensuring the model provides output in the language the document is written in."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Prompt engineering also involves evaluation. The prompts need continuous updating based on feedback, and some prompts are extremely lengthy, reaching thousands of tokens."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "For evaluation, Notion uses language models to judge other language models, questioning the bias in such models."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Challenges & Future of Prompt Engineering:"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "There are concerns about long prompts taking up valuable context window for users."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "There are methods to compress prompts and with advancements in AI, models can handle longer contexts, making this a temporary challenge."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "HCI and AI:"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Historically, HCI (Human-Computer Interaction) and AI were seen as competitors, each aiming to make computers work better with humans through different approaches."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "With AI's growing impact on user interfaces, there's a need for a standardized set of best practices, tools, and frameworks."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "The concept of an AI engineer is emerging, bridging the gap between a software engineer and a machine learning researcher."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Community Building:"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Building a space where interested professionals can share ideas and collaborate is crucial. Past innovations, whether in physics or arts, have flourished when like-minded individuals came together."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "The virtual space also offers an opportunity for collaboration beyond geographical boundaries, allowing talent from around the world to connect and innovate."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img5",
              "height": 956,
              "width": 956,
              "filename": "abls11-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392729-abls11-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Evolution of AI: Costs, Challenges, and the Future of Text Interaction"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Rapid Progress & Cost Efficiency in AI"
                      },
                      {
                        "type": "span",
                        "value": " During a lightning round of questions, Swyx and Linus discuss the surprising speed at which AI costs have decreased, especially evident in models like GPT-3.5 Turbo and DaVinci O3. Linus recalls how he tested the Notion AI autofill on a large database, and despite consuming millions of tokens, the test was cost-efficient, thanks to the affordability of new models. He jestingly mentions that with certain tests, the cost comes close to making Notion lose money, causing Alessio to joke about negative gross margins."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Challenges & Potential in AI"
                      },
                      {
                        "type": "span",
                        "value": " Linus identifies one of the most pressing challenges in AI as building reliable and predictable systems, especially for automation. He points out that while AI can produce varied responses, achieving consistency in outputs is vital. To solve this, he suggests the co-generation of programs and having AI synthesize code for specific tasks, which then can be audited and improved upon by humans. He appreciates the confluence of AI with programming languages, compilers, and interpreters, and hopes the synergy between them will lead to better solutions. Swyx also highlights recent AI guidance solutions like LMQL and Microsoft's Guidance."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "A Forward-looking Perspective on AI & Text"
                      },
                      {
                        "type": "span",
                        "value": " Both Swyx and Linus agree that we're just at the beginning of the AI journey. Linus emphasizes that if humans are to remain for thousands of years more, it's unimaginable to think that our writing tools and systems won't evolve from their present state. He encourages a vision that looks beyond current conventions and expects disruptions, like the potential replacement of transformers in AI models in the years to come."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation concludes with Alessio expressing gratitude for Linus's insights."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img6",
              "height": 956,
              "width": 956,
              "filename": "abls11-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692392748-abls11-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Explore Notion AI's transformative approach to AI and UX. ",
        "title": "Latent Space Podcast 6/1/23 [Summary] - AI × UX Scenius",
        "twitterCard": null,
        "image": {
          "width": 1614,
          "height": 546,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
        }
      }
    },
    {
      "id": "190260557",
      "topics": [
        "Summary",
        "Code",
        "LLM",
        "Agents"
      ],
      "title": "Latent Space Podcast 5/25/23 [Summary] - Debugging the Internet with AI agents – with Itamar Friedman of Codium AI and AutoGPT",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "Explore the future of AI with Itamar Friedman from Codium AI on 'Debugging the Internet'. Dive into 'Extreme DRY' agents, the rapid sync of specs & tests, and the balance between code & testing. Plus, insights from Toran & an exclusive look at AutoGPT's roadmap!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/codium-agents#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Debugging the Internet with AI agents – with Itamar Friedman of Codium AI and AutoGPT"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "url": "https://www.latent.space/p/codium-agents#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "marks": [
                              "strong"
                            ],
                            "value": "Summary"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Evolution of AI in Code Verification: A Deep Dive with Itamar Friedman"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a recent episode of the Latent Space podcast, Alessio, Partner and CTO-in-Residence at Decibel Partners, and Swyx, the writer and editor of Latent Space, sat down with special guest, Itamar Friedman, CEO and co-founder of Codium AI."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Originating from Tel Aviv and an alumnus of Teknion Israel Institute of Technology (often compared to MIT), Itamar brought a rich background in computer vision and machine learning to the conversation. He is most known for co-founding Visualead, which was eventually acquired by Alibaba Group. Visualead's focus on QR codes with varying visibility has seen significant adoption in China, leading to considerable savings for businesses, thanks to the efficiency improvements in QR scanning."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Following his time with Alibaba, Itamar collaborated with a long-time colleague, Debbie, to kickstart Codium AI, which recently secured an impressive $11 million in seed funding. The startup’s mission is to provide an AI-powered coding assistant that assists developers in reaching a stage of zero bugs in their code."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Itamar shed light on the tech behind Codium AI, emphasizing the blend of traditional logical reasoning methods with the power of AI. While large language models (LLMs) alone might not be enough to verify code logic, a combination of AI and conventional techniques, like abstract syntax trees (AST) and dynamic code analysis, can offer an edge. By merging these techniques, developers can achieve better results in code verification. Furthermore, AI can delve into the developer's intentions, making the process more intuitive and dynamic."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The philosophy of Codium AI revolves around enhancing code logic by understanding the intent behind the code. This involves transforming developers from mere coders to pilots, where they guide and direct the process, rather than getting entangled in the nuances of coding."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-18-at-6-10-09-pm",
              "height": 548,
              "width": 1568,
              "filename": "screenshot-2023-08-18-at-6-10-09-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Codium AI: Revolutionizing Code Testing and Debugging for Developers"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio and Swyx discuss with Itamar, CEO of Codium AI, about the tool's functionalities and how it aids developers. Codium AI operates as an IDE extension, currently showcased in VS Code. Once integrated, the AI analyzes code components, conducts static code analysis, and offers insights. It suggests code specifications, tests, and analyses, which provide the user with immediate feedback on their code's quality."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Itamar emphasizes the software's focus on assisting developers in testing their code, making the process enjoyable while enhancing their skills. He showcases the \"given-when-then\" testing format, emphasizing its importance, despite many developers being unfamiliar with it."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "An intriguing feature is the tool's ability to inject humor, with \"pirate-style\" doc strings as a quirky example. Itamar provides a hands-on demonstration by intentionally introducing a bug into a bank account code, changing a deposit function from an addition to a subtraction operation. Codium AI identifies the discrepancy, offering hints and solutions for rectification."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout, Itamar is keen to note the tool's vision: achieving \"zero bugs,\" which Swyx aptly coins as \"debugging the internet.\""
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls12-img1-5",
              "height": 956,
              "width": 956,
              "filename": "abls12-img1-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692399754-abls12-img1-5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Future of Codium AI: Harnessing Multiple Models for Efficient Code Testing"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx inquires about Codium AI's growth since launch, emphasizing its organic expansion. Itamar, valuing transparency, reveals that Codium has thousands of weekly active users, noting its strong intra-company virality rather than wide public awareness. He shares that Codium operates by using different models and algorithms depending on the task at hand, benefiting from hints provided within the code or its documentation. By benchmarking new models, Codium ensures that it uses the best-suited model for each task. StarCoder, a recent model, was mentioned as an example of models they test. Itamar emphasizes the importance of understanding specific challenges and desired properties before choosing or developing a model. He outlines Codium AI's future aim of creating independent models by 2024, focusing first on enhancing user experience and engineering. He advises other developers to understand their challenges and desired properties before diving into model training."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls12-img4",
              "height": 956,
              "width": 956,
              "filename": "abls12-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692399487-abls12-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Codium AI's Vision for 2025: Enhancing Code Integrity and Embracing Extreme DRY Principles"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio, Swyx, and Itamar engaged in a comprehensive discussion on the future of software development, with a special focus on Codium AI's offerings and future plans. Itamar discussed how the world of software development in 2025 will drastically differ from 2020. He introduced the paradigm shift towards intelligent coding assistants and agents."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Currently, Codium AI allows developers to begin with code implementation and then generates the spec and tests for them. In the near future, the aim is to offer the capability to also generate technical specifications and help fill these out quickly, through a spec assistant."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The overarching vision, dubbed \"Extreme DRY (Don't Repeat Yourself)\", proposes a fluid development process where developers can begin from any stage, be it spec, test, or implementation, and the tool will assist in generating the other components. This vision is grounded in the belief that specs, tests, and code have elements that repeat themselves, and extreme automation can aid in reducing this redundancy, ensuring developers remain in the driver's seat but with significant automation support. The ultimate goal is to foster a coding environment where code integrity is paramount, with Codium AI's agents acting as catalysts in this process."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls12-img3",
              "height": 956,
              "width": 956,
              "filename": "abls12-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692399573-abls12-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Intersection of Language, Programming, and AI: A Glimpse into Codium AI's Vision and Relationship with AutoGPT"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio and Swyx discuss the evolving role of developers in a world where Codium AI streamlines the transition between product specifications, tests, and code. Itamar, from Codium AI, emphasizes the company's focus on backend development and their aim to enhance the \"Don't Repeat Yourself\" (DRY) principle across specs, tests, and code. By 2024, Codium may even incorporate visual specs like Figma. As AI-powered tools become more integrated into the development process, developers might need to adapt, understanding higher-level product requirements or refining their programming expertise. Addressing the role of AutoGPT in the broader AI community, Itamar highlights Codium AI's collaboration with the platform, emphasizing their complementary approaches. Codium AI focuses on creating specialized agents for specific tasks, while AutoGPT aims for generalized capabilities. The two organizations share a symbiotic relationship, with Codium AI contributing tests and insights to the AutoGPT community."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Navigating the Evolution of Open Source with AI: A Deep Dive with Itamar"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio probes Itamar on the future of open-source development in an era of AI-driven code generation and tests. Itamar hints at the limitations of tools like AutoGPT and Codium AI in fully comprehending and optimizing repositories, attributing issues to the cascading inaccuracies of concatenated results. However, he remains hopeful about AI's potential, cautioning that while we may overestimate current AI capabilities, we're likely underestimating its future power. The discussion transitions to Israel's booming tech scene, where startups thrive and military tech training intersects with entrepreneurship. Itamar's insights underscore the importance of hands-on exploration for builders. Before making claims about AI's potential, he urges developers to experiment, test, and iterate. Itamar's candid reflections serve as a testament to the fluidity of AI's capabilities and its role in the constantly evolving world of tech."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls12-img1",
              "height": 956,
              "width": 956,
              "filename": "abls12-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692399818-abls12-img1.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive into 'Extreme DRY' agents, the rapid sync of specs & tests, and the balance between code & testing. ",
        "title": "Latent Space Pod 5/25/23 [Summary] Debugging the Internet",
        "twitterCard": null,
        "image": {
          "width": 1568,
          "height": 548,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
        }
      }
    },
    {
      "id": "190260577",
      "topics": [
        "LLM",
        "Small Models"
      ],
      "title": "Latent Space Podcast 5/20/23 [Summary] - MPT-7B and The Beginning of Context=Infinity — with Jonathan Frankle and Abhinav Venigalla of MosaicML",
      "slug": "latent-space-podcast-5-20-23-summary-mpt-7b-and-the-beginning-of-context-infinity",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:57:33+01:00",
      "description": "Dive into MosaicML's 9-day, $200k \"llongboi\" MPT-7B training, data prep insights, & the rise of open AI models with experts Frankle & Venigalla.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/mosaic-mpt-7b#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "MPT-7B and The Beginning of Context=Infinity — with Jonathan Frankle and Abhinav Venigalla of MosaicML"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In an episode of the Latent Space podcast, Alessio and co-host Swyx welcome guests Jonathan and Abhinav (Abhi) from Mosaic ML."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Key Takeaways:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Introductions"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Jonathan, a former student of Princeton and MIT, made significant contributions with his research on the \"lottery ticket hypothesis\" in 2018. He delayed his PhD defense for two years due to commitments with Mosaic and has been appointed as an assistant professor at Harvard."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Abhinav, an MIT graduate and former researcher at Cerebras, now works with Mosaic. He mentions Cerebras' innovative approach to use an entire wafer for computing, introducing a wafer-scale computing system for training models."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Mosaic's Journey"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Mosaic ventured into building its own model, the MPT-7B, after profiling various models and realizing training costs could be considerably lowered. Mosaic's focus is not on a single standout model but on empowering clients to create their own optimized models using Mosaic’s tools."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Training and Model Creation"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Mosaic initiated its MPT-7B project as a base model, inspired by LLaMA 7B, trained on a trillion tokens. They over-trained the model intentionally to ensure it was effective for inference. Abhinav mentions a term \"chinchilla laws\" which dictate efficient compute spend, and this was one principle guiding their training decisions."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Data Choices"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "The duo discussed the challenge of determining the right balance between quality and quantity of data for model training. Repetition of high-quality data might be as effective, if not more so, than a larger volume of diverse, lower-quality data."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-18-at-9-49-21-pm",
              "height": 556,
              "width": 1568,
              "filename": "screenshot-2023-08-18-at-9-49-21-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Deciphering the Ingredients for Optimal Language Models: Data Mixes, Evaluations, and Technical Innovations"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Discussion Topic: Mix of Data Sets for Large Language Models (LLMs)"
                      },
                      {
                        "type": "span",
                        "value": " "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Swyx"
                      },
                      {
                        "type": "span",
                        "value": " asks about the essential question of what mix of data sets should be used for training LLMs. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Jonathan"
                      },
                      {
                        "type": "span",
                        "value": " shares his experience consulting with law students from Georgetown Law on the optimal data mix. Some considerations include:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The volume of English text."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Multilingual data."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The inclusion of code in the dataset."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The value of using reputable sources like Wikipedia. He further elaborates on different data sets, including c4 and mc4, discussing their unexpected performances and preprocessing anomalies. Jonathan emphasizes the importance of diverse data for different user purposes and the challenges in model evaluation."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Evaluation Challenges for LLMs"
                      },
                      {
                        "type": "span",
                        "value": " "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Swyx"
                      },
                      {
                        "type": "span",
                        "value": " mentions benchmarks like MMLU and Big Bench. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Jonathan"
                      },
                      {
                        "type": "span",
                        "value": " notes the difficulty in evaluating models since they are primarily used for open-ended generation, not multiple-choice questions. Existing metrics don't capture what users expect from the models. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Abhinav"
                      },
                      {
                        "type": "span",
                        "value": " highlights challenges related to the scale of models, evaluation metrics diversity, and the variance in user purposes."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Flash Attention"
                      },
                      {
                        "type": "span",
                        "value": " "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Abhinav"
                      },
                      {
                        "type": "span",
                        "value": " introduces flash attention as a faster implementation of full attention developed by Stanford's Hazy Research, providing speed improvements during training and inference. This implementation is unique compared to other models available on Hugging Face."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alibi Position Encodings"
                      },
                      {
                        "type": "span",
                        "value": " "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Abhinav"
                      },
                      {
                        "type": "span",
                        "value": " explains the Alibi position encoding, which eliminates the need for positional embeddings in the model, allowing models to handle longer context lengths more stably. It works by adding a bias to the attention map, which can be stretched during inference for longer positions. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "emphasis"
                        ],
                        "value": "Jonathan"
                      },
                      {
                        "type": "span",
                        "value": " points out that with enough memory, the context length could technically be infinite, and they chose 84k as the practical longest length."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion also touched upon other topics like the choice of evaluation metrics, the emergence phenomenon, and training stabilities."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img1",
              "height": 956,
              "width": 956,
              "filename": "abls13-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692415990-abls13-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Fine-Tuning for Creative Outputs & Open Source Ethical Dilemmas"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Jonathan discuss the nuances of fine-tuning AI models for creative tasks. Alex had once fine-tuned a model on books to achieve a story writer, emphasizing the significance of feedback in fine-tuning. Swyx draws parallels with computer vision, hinting at potential applications in the language domain, despite some strategies not always translating well from vision to text. Alessio introduces the complications around redistributing content, and the duo further dives into licensing challenges with Jonathan emphasizing the unforeseen issues surrounding AI-generated content and the implications of using open-source licenses in ways they weren't originally intended for. Swyx raises the topic of what's considered \"fair use\" in training models, while Jonathan encourages a community-driven decision on comfort levels in using AI outputs. The conversation shifts to technical details with Abhinav, as they discuss training stability enhancement. Mosaic's solution offers stability improvements to mitigate loss spikes during training. Both Jonathan and Abhinav emphasize the significance of the infrastructure, noting challenges and breakthroughs they faced, particularly with hardware failures during model training. The segment ends with a comparison between CPU and GPU failure management."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img2",
              "height": 956,
              "width": 956,
              "filename": "abls13-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416022-abls13-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Data Readiness & Training Preparation"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Synchronous Data Pluralism:"
                              },
                              {
                                "type": "span",
                                "value": " The process where every GP works in sync and averages their gradients. The aim is determinism, the ability to replicate a run perfectly."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Inference, Training, and Composer Products:"
                              },
                              {
                                "type": "span",
                                "value": " The starting point for many customers, evolving from the traditional LOP stack. There are two main uses: using Mosaic's checkpoints or starting from Mosaic's configuration."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Data Preparedness:"
                              },
                              {
                                "type": "span",
                                "value": " Abhinav emphasizes the importance of having proper evaluation metrics and cleaned data before training models. The goal is predictability in outcomes before significant financial investments are made."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Dynamic Real-time Model Evaluation"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Evaluation Techniques:"
                              },
                              {
                                "type": "span",
                                "value": " Discussion on the significance of various evaluation metrics, such as human eval and vibe-based evaluation. Jonathan emphasizes the importance of real-world prompts for evaluating model performance."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Live Evaluations:"
                              },
                              {
                                "type": "span",
                                "value": " LLM Foundry provides tools for model evaluation, boasting a fast framework compatible with multiple GPUs. It allows real-time monitoring of model training."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open Science for Affordable AI Research"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Cost and Efficiency:"
                              },
                              {
                                "type": "span",
                                "value": " The high cost of training has limited experiments in the past. Mosaic's objective is to reduce costs to enable more experiments and thus better insights."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Value of Openness:"
                              },
                              {
                                "type": "span",
                                "value": " Mosaic emphasizes the importance of being open with the community. They believe in sharing insights as their primary aim is to help clients train better models and provide superior infrastructure."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img3",
              "height": 956,
              "width": 956,
              "filename": "abls13-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416037-abls13-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Balancing Open Approaches and the Dynamic Journey of Mosaic in AI Evolution"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Open Approach"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Alessio"
                              },
                              {
                                "type": "span",
                                "value": " questions the requirements and feasibility of the open approach, mentioning GPT-4 and its state-of-the-art capabilities. He seeks insights on whether current methods will suffice or if more advancements are needed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Jonathan"
                              },
                              {
                                "type": "span",
                                "value": " believes in the coexistence of different technologies, using Linux and Windows as an analogy. He highlights the importance of having domain-specific models and expresses concern over the diminishing open-source ecosystem. He fears the stagnation of innovation due to reduced openness and shares that the collaborative exchange of ideas was crucial for technological progress."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Future of Mosaic"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Swyx"
                              },
                              {
                                "type": "span",
                                "value": " brings up the evolution and plans of Mosaic, remarking on the company's recent dive into inference despite earlier claims."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Jonathan"
                              },
                              {
                                "type": "span",
                                "value": " emphasizes the importance of focus for startups, sharing Mosaic's initial reluctance towards inference. Despite that, they ventured into it due to customer demand and business benefits. He recalls Mosaic's vision of efficient training and its realization of the changing needs of inference. He stresses the continuous nature of model training and improvement."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Abhinav"
                              },
                              {
                                "type": "span",
                                "value": " points out the evolving nature of data and the continuous need to update models accordingly. He notes that the current models aren't the endpoint; they will evolve, improving in various aspects."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Jonathan"
                              },
                              {
                                "type": "span",
                                "value": " ends by debunking the idea of training as a one-time cost. He cites a stat from Google, illustrating the split between inference and training costs, emphasizing the significant investment in training."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "This transcript sheds light on the evolving world of AI, emphasizing the importance of the open approach, the need for continuous learning and improvement, and the dynamic nature of startups in the tech industry."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img4",
              "height": 956,
              "width": 956,
              "filename": "abls13-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416082-abls13-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Evolution of Speed and Efficiency in AI Training"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Swyx"
                      },
                      {
                        "type": "span",
                        "value": " delves into the topic of efficiency and speed in AI model training, questioning how fast the process can get given the current durations varying from three to 10 days. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Abhinav"
                      },
                      {
                        "type": "span",
                        "value": " highlights this year as crucial for training efficiency, emphasizing new hardware like Nvidia's H 100 and the new floating point format, FP8. These innovations significantly reduce training time and costs. The discussion dives into the evolution from 32-bit to 16-bit precision in training, foreseeing FP8 bringing about even greater improvements."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Furthermore, Abhinav touches on Mosaic's advancements using FP8 with H 100s and the architectural applications in the pipeline. By year's end, the cost of training could drop significantly – from 500k to an ambitious 100k for specific models. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Jonathan"
                      },
                      {
                        "type": "span",
                        "value": " chimes in, stating that cost reductions for new models can be substantial because they often begin inefficient. As an example, Mosaic reduced costs by 12x for the stable diffusion model due to its newness and inherent inefficiencies."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "On the topic of model contexts, "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Alessio"
                      },
                      {
                        "type": "span",
                        "value": " brings up the challenge of determining the right number, suggesting customer needs and specific tasks as potential determinants. Jonathan offers a critical view of long contexts and attention methods, emphasizing the importance of firsthand implementation and testing. He raises concerns about relying solely on published papers, indicating that practical results often differ from promises made in research."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Toward the end, the group draws parallels between RAM in computers and context in AI models. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Swyx"
                      },
                      {
                        "type": "span",
                        "value": " mentions a comparison made by Andrej Karpathy, suggesting context is the RAM of AI. "
                      },
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Jonathan"
                      },
                      {
                        "type": "span",
                        "value": " humorously alludes to Bill Gates' famed statement on RAM and speculates about the future. As AI gets more ambitious, so will the demands on context. Future models might process complex data forms, like images and videos, further intensifying the need for efficient and rapid training."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img5",
              "height": 956,
              "width": 956,
              "filename": "abls13-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416098-abls13-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Evolution and Endurance of Transformers in AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "During the \"Trends and Transformers\" discussion, Swyx and Jonathan explore the longevity of transformer models in AI, suggesting that, just like Convolutional Neural Networks, they could remain in use for a long time. They delve into the nuances of attention mechanisms, with Jonathan emphasizing the importance of historical model architectures and how challenging it is to find fundamental improvements. He also mentions the significance of demos for their business, as they demonstrate capabilities without giving everything away."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Discussing the open research ethos, Jonathan explains the balance they strike between open work and proprietary customer solutions. Abhinav introduces the topic of model sparsity, pointing out the current lack of hardware to accelerate sparse models, though he acknowledges certain advancements like those from Cereus. The conversation concludes with a discussion about the hardware-software co-evolution: how new architectures need to pair well with emerging hardware, much like how transformers are apt for GPUs, albeit initially designed for TPUs."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls11-img5-5",
              "height": 956,
              "width": 956,
              "filename": "abls11-img5-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416160-abls11-img5-5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Unraveling AI's Unexpected Strides and the Road Ahead"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI's Surprising Progress and Future Predictions"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a lively discussion, Alessio prompted guests to share their views on AI's trajectory. Jonathan expressed surprise at the swift progress, particularly in models like GPT-3. He admitted to being wrong about the scalability and usefulness of such models. Abhinav was similarly astonished by the rapid adoption and emotional connections users are making with large-scale chatbots. They both reflected on the boundaries of AI, from Abhinav's curiosity about the potential of quantizing models down to analog levels to Jonathan's desire to explore efficient paths to achieve AI capabilities without massive scale. The conversation ended with a call for balance in the AI discourse. Jonathan urged listeners to remain grounded, avoiding hyperbolic fear and embracing the constructive tools AI provides. Abhinav emphasized the importance of open research, championing collaborative oversight for AI's safety and real-world implications. The segment closed with gratitude for keeping AI discussions and advancements open to the public."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls13-img5-5",
              "height": 956,
              "width": 956,
              "filename": "abls13-img5-5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692416183-abls13-img5-5.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive into MosaicML's 9-day, $200k \"llongboi\" MPT-7B training, data prep insights, & the rise of open AI models ",
        "title": "Latent Space Podcast 6/25/23 [Summary] MosaicML",
        "twitterCard": null,
        "image": {
          "width": 1568,
          "height": 556,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
        }
      }
    },
    {
      "id": "190260597",
      "topics": [
        "LLM",
        "Structured Data"
      ],
      "title": "Latent Space Podcast 5/15/23 [Summary] - Guaranteed quality and structure in LLM outputs - with Shreya Rajpal of Guardrails AI",
      "slug": "latent-space-podcast-5-15-23-summary-guaranteed-quality-and-structure-in-llm-outp",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:56:26+01:00",
      "description": "Explore Ep. 12 with Shreya Rajpal of Guardrails AI: Dive deep into validating LLM outputs, refining answers through re-asking loops, and establishing SLAs for models. Master the nuances of AI quality assurance.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/guaranteed-quality-and-structure#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Guaranteed quality and structure in LLM outputs - with Shreya Rajpal of Guardrails AI"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring Guardrails: Shaping AI Outputs with Shreya Rajpal"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "On the Latent Space Podcast, hosted by Alessio and Swyx, they welcomed Shreya Rajpal, an AI expert with a background in AI from IIT Delhi and a master's from UIUC. She started her AI journey in 2014, expressing how she felt the field has always been on the brink of global change. Shreya's professional trajectory took her through Drive.ai, Apple's Special Projects Group alongside Ian Goodfellow, and a recent transition from Pretty Base to focus on her project, Guardrails. On a personal note, Shreya revealed she enjoys pottery, drawing a light-hearted comparison between her professional and personal interests."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The main topic of discussion was Guardrails, Shreya's initiative. Stemming from her own experiences with AI outputs and the desire for greater control, Guardrails was designed to offer a more structured and reliable output from Large Language Models (LLMs). The system consists of a specification framework to guide outputs and code to enforce them. It is designed to offer both coarse and detailed output parameters. Additionally, Guardrails uses a unique markup language, Reliable AI Markup Language (RAIL), which ensures the outputs adhere to the specified criteria. One of the tool's key features is its model-agnostic nature, meaning it can be integrated with any AI model that uses string inputs and outputs."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A point of contention was Shreya's choice of XML over more popular formats like JSON or YAML. She explained that XML, despite its criticisms, offered her a clean, English-like structure and greater control over output properties. However, Shreya did acknowledge the criticisms and hinted at future updates that might bring other markup languages or even a code-first version to Guardrails."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The podcast touched upon the growing community of non-technical individuals leveraging AI tools, emphasizing the importance of building tools that cater to both beginners and experts. They concluded by highlighting the potential for third-party developers to build on top of Guardrails, equating its foundation to how HTML paved the way for platforms like WordPress."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-19-at-9-38-27-pm",
              "height": 512,
              "width": 1580,
              "filename": "screenshot-2023-08-19-at-9-38-27-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring Developer Ergonomics: SQL vs. XML and the Evolution of Guardrails"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Swyx and Shreya on SQL and XML"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx inquires about Shreya's exploration of SQL syntax in comparison with a project named \"l m qr\"."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya explains that she prioritized developer ergonomics in her project. Rather than introducing a new SQL-like dialect, which she perceived as high friction, she opted for XML or markup language due to its intuitive nature."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx recognizes SQL's reputation among business analysts but ultimately agrees with Shreya's stance."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya points out that many enterprises, including medium-tech individuals, find XML familiar."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "React's Influence and Guardrails Design"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx mentions his background in React, a JavaScript framework that utilizes an XML-like language for templating. He wonders if Shreya took inspiration from it."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya, while not deeply versed in frontend, acknowledges the appeal of combining event handlers with a declarative framework. She compares Guardrails to inserting dynamic scripting and event handling into applications, likening it to JavaScript within HTML."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx brings up the composability feature in React, questioning if Guardrails projects can be imported into others, suggesting potential for a Guardrails package manager or reusable components."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya acknowledges the feasibility of the idea, linking it to chaining and composing LLM API calls with Guardrails ensuring the integrity of each call."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Models Creating Their Own Rails"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio, speaking on Guardrails, asks if models can create their own specifications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya admits she hasn't tested this but sees potential in the idea."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussing agents, Shreya acknowledges their potential but also their unpredictability. She likens ML application design to self-driving systems, emphasizing the need for guaranteeing outputs, especially in auto-generated goals."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Future of AI Progress"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx reflects on AI's trajectory, wondering what constant aspects Shreya is focusing on with Guardrails and what she expects will improve."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya believes longer context lengths will emerge and become a standard in applications, but the essence of ensuring guaranteed outputs remains vital."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls14-img1",
              "height": 930,
              "width": 930,
              "filename": "abls14-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692497775-abls14-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Innovations and Challenges in AI Research and Development"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Shreya delve into recent advancements in AI architecture and research. Here are the key points:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx brings up a recent 'transformer thing' that's been circulating, with Shreya connecting it to her husband's work at Stanford's Hazy research lab. The lab focuses on innovative and efficient architectures for AI models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya highlights the lab's endeavor into newer architectures that don't solely depend on transformers. The goal is to achieve longer context lengths, lower latency, and better memory efficiency."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya expresses her expertise in these advancements due to her background and previous work in similar areas. She emphasizes that even with advancements, determining the exact configurations for efficiency requires extensive experimentation."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A significant challenge discussed is the determinism on machine learning models. It's stated that even with consistent inputs and certain control parameters (like temperature zero), the outputs aren't always identical. This poses a challenge, especially when external factors like model updates affect the system's functioning."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya then transitions to \"guardrails\", a tool she seems to be involved with. It assists in prompt engineering, ensuring users get quality outputs without much intervention. One of its strengths is that it reduces the burden on the user by maintaining consistency, even when underlying models change frequently."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Another highlighted issue is the lack of reproducibility in AI models due to the vast range of inputs and outputs that can't always be covered by tests and training data. Shreya mentions that merely scaling the models or adding more data doesn't address the problem. Instead, a more holistic approach, which combines powerful AI models with rule-based heuristics and traditional machine learning tools, might offer a solution."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx and Shreya also discuss \"guardrails'\" various features, like checking SQL syntax against a schema and ensuring structured outputs. They touch on the potential of such a tool in enhancing the user experience."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Overall, the conversation paints a vivid picture of the current AI landscape, shedding light on both the thrilling advancements and the persistent challenges."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls14-img3",
              "height": 930,
              "width": 930,
              "filename": "abls14-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692497969-abls14-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Guardrails in AI Application Development"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Swyx and Shreya discuss the integration of AI and its implications on the machine's readability."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Highlights:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx points out potential issues with machine readability when integrated with platforms like Datadog."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio introduces the challenge of Service Level Agreements (SLAs) for ambiguous outputs such as drafting marketing articles. How does one measure quality and latency in such situations?"
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya highlights that SLAs in this context focus more on content quality rather than time. Breaking down a task into smaller components, like content creation, allows for more explicit guarantees and expectations. For instance, specifying the reading time for a summary."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio touches upon the idea that products will soon differentiate based on the number of guardrails they incorporate. This differentiation is visible with platforms like OpenAI, where some responses might be seen as too verbose or too cautious."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shreya brings forth the concept of 'authenticity' in content, which may sometimes require fewer guardrails. The intention with designing Guardrails is to offer a framework, and developers can adapt this based on their needs."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio delves into 'chat plugins' and how guardrails might assist in ensuring brand-focused content generation, preventing mentions of competitors, for example."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The conversation pivots to the notion of the LLM API wrapper, with Swyx noting that various players are competing for this foundational layer. Shreya emphasizes collaboration over competition, stating her intent to integrate with everyone rather than own this real estate."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls14-img4",
              "height": 930,
              "width": 930,
              "filename": "abls14-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692498039-abls14-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Balancing Innovation and Feedback: Insights from Shreya on Guardrails and Collaborative AI Development"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In an insightful conversation between Swyx, Shreya, and Alessio, the dynamics of AI project development, particularly in the context of Shreya’s Guardrails, were discussed. Shreya, despite being new to running a company, has shown remarkable agility, launching multiple projects simultaneously. The conversation touched on:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "numbered",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Prioritization in AI Projects"
                              },
                              {
                                "type": "span",
                                "value": ": Shreya’s approach to development is instinctive, and she often stack ranks her ideas. Community feedback and failure reports take precedence in her list of priorities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Engagement Metrics"
                              },
                              {
                                "type": "span",
                                "value": ": A major part of Shreya's week varies between calls with potential users, gaining insight on their use cases, and building. She emphasized the importance of user empathy and understanding their needs to ensure the product aligns well."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Open Source as a Tool"
                              },
                              {
                                "type": "span",
                                "value": ": Alessio pointed out the interesting dynamics of open source projects. While Shreya has been the primary contributor to Guardrails, with her husband being the second most significant contributor, she sees the value in community contributions. The goal now is to get more engagement from the open-source community."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Business Model Exploration"
                              },
                              {
                                "type": "span",
                                "value": ": Swyx was curious about Shreya’s plans for the future of Guardrails. While Shreya is dedicated to her open-source work full-time, she expressed interest in exploring various entrepreneurial paths. She sees the problems Guardrails addresses as crucial for the success of large-scale machine learning systems."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Learning from Mentors"
                              },
                              {
                                "type": "span",
                                "value": ": An interesting anecdote was shared about Shreya's time at Apple, where she worked alongside Ian Goodfellow, known for his creation of Generative Adversarial Networks (GANs). Shreya praised Ian for his creative approach to machine learning and shared insights on effective management."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, the conversation shed light on the complexities of managing and growing an AI project, the importance of community feedback, and the potential paths one can take with open-source projects."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls14-img5",
              "height": 930,
              "width": 930,
              "filename": "abls14-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692498097-abls14-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring the Future of AI and Automation"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a candid conversation between Swyx, Shreya, and Alessio, the trio delves into the cutting-edge developments emerging from Stanford and their implications on the broader AI ecosystem. Shreya, with proximity to Stanford, has a keen interest in the academic outputs, particularly the areas of guardrails and ML efficiency techniques."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "\"Guardrails\" has become a popular term, and Swyx can't help but express his admiration every time he hears it. Shreya is curious about the ongoing advancements in efficient ML inference, hoping to see improvements in context length and better fine-tuning capabilities with minimal data."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "When the topic of efficiency surfaces, Swyx inquires about Shreya's perspective on various optimization techniques. She advocates for a holistic approach, employing an ensemble of methods. Shreya acknowledges the delicate balance between enhancing an AI model's efficiency and ensuring its performance remains uncompromised. This trade-off is inherently experimental, as solutions vary depending on use cases, architectures, and hardware."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio then initiates a \"lightning round\" of questions, with the first being about favorite AI products. Shreya cites \"co-pilot\" as a game-changer. Further discussion reveals a shared enthusiasm for the automation of coding and testing processes, with Shreya highlighting a tool called AutoPR that converts GitHub issues into pull requests. Alessio introduces another tool, Wolverine, that specializes in self-healing code."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Predictions for the AI industry's trajectory in the upcoming year are broached. Shreya anticipates challenges in transitioning from AI's current potential to delivering consistent, top-notch user experiences."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The dialogue culminates with a discussion on an AI solution that can draft emails reflecting one's unique tone and style. Both Shreya and Alessio express a desire for such a product. The conversationalists underscore the progress in AI, yet also note the occasional humorous and unexpected missteps in the technology's current state."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls14-img6",
              "height": 930,
              "width": 930,
              "filename": "abls14-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692498196-abls14-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Explore Ep. 12 with Shreya Rajpal of Guardrails AI: Dive deep into validating LLM outputs.",
        "title": "Latent Space Podcast 5/15/23 [Summary] Quality LLM Outputs",
        "twitterCard": null,
        "image": {
          "width": 1580,
          "height": 512,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
        }
      }
    },
    {
      "id": "190260606",
      "topics": [
        "LLM",
        "Training",
        "Agents",
        "Multimodal"
      ],
      "title": "Latent Space Podcast 5/8/23 [Summary] - The AI Founder Gene: Being Early, Building Fast, and Believing in Greatness — with Sharif Shameem of Lexica",
      "slug": "latent-space-podcast-5-8-23-summary-the-ai-founder-gene-being-early-building-fast",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:52:09+01:00",
      "description": "Ep.11 with Sharif Shameem of Lexica: Dive into the AI founder mindset, uncovering the secrets to pioneering innovation, building game-changing tech, training models, and the intriguing potential of Agents and genomic sequencing. ",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/sharif-shameem#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "The AI Founder Gene: Being Early, Building Fast, and Believing in Greatness — with Sharif Shameem of Lexica"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Sharif Amin's Tech Odyssey: From University Dropout to AI Pioneer"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In the episode of the Latent Space podcast, Alessio and his co-host Swyx, interview Sharif Amin. Sharif delves into his educational journey, sharing that he dropped out of the University of Maryland to pursue a side project, inspired by advice from an investor and a book he read. He then worked at Mitra, a federally funded research and development center, where he was involved in computer vision projects."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Sharif later founded VectorDash, inspired by the costly GPU requirements for machine learning research versus the potential of utilizing GPUs used for cryptocurrency mining. The platform evolved into a GPU cloud provider for video games, somewhat ahead of Google's Stadia, though it faced bandwidth challenges."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In 2020, Sharif was intrigued by OpenAI's GPT-3, which led him to develop debuild. His project's potential was amplified when a tweet showcasing it caught traction and was later featured in various tech publications."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "By 2022, Sharif had transitioned to Lexica, a search engine born out of the need to better navigate the stable diffusion discord, which he felt had a deficient search functionality. Sharif's ability to identify gaps in current tools and his innovative mindset stands out through his journey."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-19-at-11-24-05-pm",
              "height": 550,
              "width": 1606,
              "filename": "screenshot-2023-08-19-at-11-24-05-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Sharif Amin's Tech Odyssey: From University Dropout to AI Pioneer"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In the episode of the Latent Space podcast, Alessio and his co-host Swyx, interview Sharif Amin. Sharif delves into his educational journey, sharing that he dropped out of the University of Maryland to pursue a side project, inspired by advice from an investor and a book he read. He then worked at Mitra, a federally funded research and development center, where he was involved in computer vision projects."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Sharif later founded VectorDash, inspired by the costly GPU requirements for machine learning research versus the potential of utilizing GPUs used for cryptocurrency mining. The platform evolved into a GPU cloud provider for video games, somewhat ahead of Google's Stadia, though it faced bandwidth challenges."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In 2020, Sharif was intrigued by OpenAI's GPT-3, which led him to develop debuild. His project's potential was amplified when a tweet showcasing it caught traction and was later featured in various tech publications."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "By 2022, Sharif had transitioned to Lexica, a search engine born out of the need to better navigate the stable diffusion discord, which he felt had a deficient search functionality. Sharif's ability to identify gaps in current tools and his innovative mindset stands out through his journey."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls15-img1",
              "height": 930,
              "width": 930,
              "filename": "abls15-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692504586-abls15-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Lexica's Rapid Rise and Technical Backbone"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Launch Impact"
                              },
                              {
                                "type": "span",
                                "value": ": Within 24 hours of launching Lexica, the platform saw a staggering 51,000 queries, and by the second day, it doubled to 111,000 queries. They went on to serve over 5 billion images per month, an impressive growth trajectory Sharif hadn't anticipated."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Tech Insights"
                              },
                              {
                                "type": "span",
                                "value": ": Lexica's initial search system relied on Postgres' full text search but was later inspired by \"Same Energy\" for a semantic image search. The upgraded system was developed on clip embeddings of images, utilizing FAISS (a Facebook library) for efficient KNN search on embeddings. This semantic search was a hit with users, significantly increasing engagement."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Funding and Focus"
                              },
                              {
                                "type": "span",
                                "value": ": Lexica, which started as a side project, caught investor attention after an exponential user growth in its initial weeks. They raised $5 million from Daniel Gross and participated in AI Grant, subsequently making Lexica the main focus of their efforts."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "From Search to Generation"
                              },
                              {
                                "type": "span",
                                "value": ": Noticing user behavior, Sharif decided to integrate generation features directly within Lexica. This allowed users to not just search but also edit and generate images, enhancing user experience and streamlining their interaction."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Learning from AI Grant"
                              },
                              {
                                "type": "span",
                                "value": ": The program emphasized that while there's abundant potential in advanced AI models, there's a dearth of compelling products for the average user. The goal is to prioritize product development that addresses real user needs over simply achieving state-of-the-art benchmarks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "The Data Factor"
                              },
                              {
                                "type": "span",
                                "value": ": The success in training high-quality models, especially diffusion models, leans heavily on the quality and quantity of data. For Lexica, aesthetic scoring of images and user rankings play a critical role. Using traffic from their platform, they refine data sets and improve their models' aesthetics."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls15-img2",
              "height": 930,
              "width": 930,
              "filename": "abls15-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692504642-abls15-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Bridging the Gap: Transitioning to AI and Enhancing Web Interactivity for Models"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring Machine Learning and Training Models"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx interviewed Sharif about his transition from an infrastructure background to training machine learning models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Sharif discussed the challenges and parallels between learning programming and learning how to train AI models. He stressed the importance of persistence, leveraging online resources, and learning from open-source communities."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Both discussed the uniqueness of AI in terms of costing as running machine learning models might burn through credits, unlike typical programming."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Sharif highlighted the efficiency of fine-tuning open-source models, mentioning specific models like FLAN-T5 and GPT-J. He further discussed the potential of newer models and their advancements."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A brief discussion ensued about Dolly, a commercial version of the Vicuna model."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "On the Rise of AI Agents"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio shifted the conversation towards AI agents and their potential after Sharif's past demo using the GPT-3 API."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Sharif explained a past project that aimed to let agents browse documentation, summarize it, and potentially perform online tasks like creating API keys."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "He delved into the challenges of converting web pages into a format digestible for AI and how the AI can act on this information."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Sharif introduced a potential solution using terminal-based browsers that turn graphical elements into ASCII and maintaining textual content. He also highlighted challenges in making an AI interact accurately with elements on a web page and proposed solutions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Swyx raised a concern about how models would act when they lack sufficient information, and Sharif suggested training models using sessions of agents browsing the web."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Alessio and Sharif discussed the potential of reshaping the Document Object Model (DOM) to make web pages more accessible and intuitive for AI models to interact with, highlighting the importance of a more annotated and accessible web."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls15-img3",
              "height": 930,
              "width": 930,
              "filename": "abls15-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692504683-abls15-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Multimodal Models and the Evolution of Lexica"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Multimodal Capabilities of GPT-4"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Sharif highlights the potential of GPT-4's multimodal capabilities, especially for graphically dense web pages. Its dense multimodal input means it could even extract text from PDFs and summarize content from complex web pages."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Compared to Clip, GPT-4 has both text and vision understanding, offering the best of both worlds."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Ensemble models, like the combination of Blip and Lama, can be useful. An ensemble provides the benefits of multiple models, but there are advantages when different modalities are trained within the same model."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Sharif’s Startup Manual"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Sharif shares his startup advice, emphasizing the importance of launching a minimal version of a product to gather user feedback."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "He stresses the significance of not over-engineering, shipping early, and ensuring that a product is loved by users before focusing on growth."
                                      }
                                    ]
                                  }
                                ]
                              },
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "The journey of Lexica's versions (Aperture V1 to V3) highlights the importance of iteration based on user feedback. V1 was less popular, leading to improvements in V2 and V3 based on users' preferences for non-photorealistic images."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Request for AI Startup - LLM Tools"
                              },
                              {
                                "type": "span",
                                "value": ":"
                              }
                            ]
                          },
                          {
                            "type": "list",
                            "style": "bulleted",
                            "children": [
                              {
                                "type": "listItem",
                                "children": [
                                  {
                                    "type": "paragraph",
                                    "children": [
                                      {
                                        "type": "span",
                                        "value": "Sharif expresses interest in developing better tools for language models themselves, such as giving them access to browsers and payment systems."
                                      }
                                    ]
                                  }
                                ]
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls15-img4",
              "height": 930,
              "width": 930,
              "filename": "abls15-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692504751-abls15-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Unlocking the Potential of Genomics and Future of AI-driven Tools"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Unlocking the Potential of Genomics and AI:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe podcast kicks off with a discussion about the incredible power of consumer genomics. Tools like 23andMe allow individuals to export their entire genome as a text file, which can then be interpreted by platforms such as Prometheus. This information provides insights into specific traits and predispositions that individuals possess, from being a night owl to the likelihood of contracting certain diseases."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Importance of Novel Ideas in Tech:"
                      },
                      {
                        "type": "span",
                        "value": "\nSwyx and Sharif emphasize the need for more innovative ideas in the tech space. While many are creating uninspiring B2B SaaS apps, there's a desire to motivate people to think outside the box. Projects like the baby AGI and GPT Agent are not necessarily useful in their current form but serve to inspire and show what's possible. The discussion moves to video games, highlighting how NPCs (non-playable characters) in games like \"The Last of Us Part Two\" have become remarkably realistic through conditional rules. Imagine the game-changer it would be if each NPC was driven by an AI model like GPT-4."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI in Everyday Tools:"
                      },
                      {
                        "type": "span",
                        "value": "\nSharif mentions ChatGPT as one of his favorite AI products and expresses excitement about a company working on a version of VS code with an AI-powered cursor. This cursor aims to help users refine their code simply by describing desired changes. Furthermore, they discuss the need for more language model tools that can perform tasks autonomously, emphasizing the potential for such tools to revolutionize many sectors."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Final Takeaway:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe podcast concludes with a crucial message from Sharif. He stresses that individuals often believe their ideas have been executed before, but in reality, many of these ideas are unique and have not been tried. Sharif's encouragement is for people to bring their unusual and innovative ideas to life, emphasizing that the tech world needs more of such pioneering ideas rather than mere incremental improvements on existing concepts."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls15-img5",
              "height": 930,
              "width": 930,
              "filename": "abls15-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692504815-abls15-img5.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Ep.11 with Sharif Shameem of Lexica: Dive into the AI founder mindset, uncovering the secrets to pioneering innovation.",
        "title": "Latent Space Pod 5/8/23 [Summary] The AI Founder Gene",
        "twitterCard": null,
        "image": {
          "width": 1606,
          "height": 550,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
        }
      }
    },
    {
      "id": "190260640",
      "topics": [
        "Summary",
        "Open Source",
        "LLM"
      ],
      "title": "Latent Space Podcast 5/5/23 [Summary] - No Moat: Closed AI gets its Open Source wakeup call — ft. Simon Willison",
      "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:49:18+01:00",
      "description": "Explore 'No Moat: Closed AI's Open Source Awakening' with Simon Willison. Dive into leaked Google Moat memo insights, Google Brain Drain, and Python's speed boost with Mojo.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: No Moat: "
                      },
                      {
                        "url": "https://www.latent.space/p/no-moat#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Closed AI gets its Open Source wakeup call — ft. Simon Willison"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Open Source AI Models Challenge Tech Giants"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "\nThe Google Memo and Open Source Rise"
                      },
                      {
                        "type": "span",
                        "value": " Simon Willison highlighted a leaked memo titled \"We Have No Moat and neither does OpenAI\" suggesting that while Google and OpenAI are building bigger language models, open source projects are quickly catching up. He mentioned Facebook's Lama as a milestone and Stanford's Alpaca as a substantial improvement. The memo argues against the belief that larger models mean more power, suggesting instead that smaller, flexible models could be the future. The high quality and richness of the analysis within the memo was stressed."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open Source vs. Closed Systems"
                      },
                      {
                        "type": "span",
                        "value": " swyx commented on how traditionally, the narrative was that open source would lag behind closed systems because closed systems could adopt from open. However, this memo suggests the opposite is now occurring, with open source outpacing closed models. Travis Fischer echoed this sentiment, noting that the rapid pace of AI advancements could only be matched by open source. He questioned the real competitive advantage when models become commoditized and how companies like Google can engage with open source without compromising their position in the market."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Infrastructure and Practicality"
                      },
                      {
                        "type": "span",
                        "value": " Alessio Fanelli argued that while building the best model is essential, it's equally crucial to consider the infrastructure around running these models. Although many open-source tools are freely available, the cost and expertise required to run them might be prohibitive for many."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Running Models On Device"
                      },
                      {
                        "type": "span",
                        "value": " Simon discussed the capabilities of current models, particularly how they can be run on personal devices. He cited Vicuna 13B, a model derived from Facebook's Lama, as an example of a model running directly in the browser. He also mentioned the emerging techniques to compress these models, making them even more accessible to everyday devices."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Google Moat and Future Directions"
                      },
                      {
                        "type": "span",
                        "value": " swyx raised a question about Google's apparent panic, considering their vast resources and existing user base with tools like Google Calendar, Docs, and more. He wondered why, given these advantages, there's a sense of urgency within Google concerning the advances of open-source AI."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the discussion, the underlying theme was the shifting dynamics between closed systems and the rapidly advancing open-source world in AI. The rapid strides open source has made, the possibility of 'installable' abilities on models, and Google's position in this changing landscape were all debated."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-20-at-5-25-53-pm",
              "height": 532,
              "width": 1602,
              "filename": "screenshot-2023-08-20-at-5-25-53-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI's Competitive Landscape: Talent Drain, Data Loops, and the Promise of LoRA"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Travis Fischer touched on a significant challenge faced by companies like Google: retaining top talent. When the perception is that they are lagging in advancements, their best researchers may consider opportunities elsewhere, such as OpenAI or academic institutions. However, Fischer argued that Google, with its vast resources, shouldn't be underestimated and has the potential to regain momentum."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio Fanelli highlighted the importance of high-quality data. While Google possesses vast amounts of data from their platforms, startups face the daunting task of accumulating enough high-quality data to compete. The idea is not to have the most data but to have the right kind of data. This is where first-party data loops become crucial."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Simon Willison and swyx discussed the emergence of the Open Source Models that are trained on publicly available data, reducing dependency on large-scale, proprietary datasets. They dove into the concept of LoRA (Lower Rank Adaptation), a technique where a portion of the model is frozen, and only a smaller segment is trained, saving computational costs and time. However, these LoRAs are tied to specific model versions, raising the question of compatibility and the relevance of constantly retraining base models."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In conclusion, the AI landscape is rapidly evolving, with the focus shifting from the sheer size of data and models to the quality and adaptability of models. It remains to be seen which strategies will prove most successful in the long run."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls16-img2",
              "height": 930,
              "width": 930,
              "filename": "abls16-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692568229-abls16-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Power of Optimized AI Models and Language Supersets"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Optimized Models"
                              },
                              {
                                "type": "span",
                                "value": ": Simon Willison and Travis Fischer discussed the need for specialized AI models that can run directly on devices without requiring external API calls, especially in critical contexts where precision and speed are vital, like in fighter jets. Milliseconds can make a difference in such scenarios, and using an external API is not feasible."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Mojo - The Next Big Programming Language"
                              },
                              {
                                "type": "span",
                                "value": ": Simon introduced \"Mojo\", a newly announced programming language that acts as a superset of Python, which means any Python code will work in Mojo. However, Mojo introduces features that allow for highly optimized code. What sets Mojo apart is its ability to significantly improve the performance of existing Python code, evidenced by a demo that increased matrix multiplication performance by 2000 times. The language was designed by Chris Lattner, who had a hand in creating significant computing products like LLVM and Swift."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Potential of Language Supersets"
                              },
                              {
                                "type": "span",
                                "value": ": A topic raised by swyx revolves around the concept of language supersets and their transformative potential. He expressed intrigue on why the idea of Mojo wasn't conceived earlier, given the existing concept of language supersets. Simon explained that Mojo built upon a platform called MLIR, another Lattner project optimized for multiple cores and GPU access. This gave Mojo a robust foundation to build on. The ability to enhance performance while staying in a familiar ecosystem (like Python) was touted as its standout feature."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Google and AI Strategy"
                              },
                              {
                                "type": "span",
                                "value": ": The conversation shifted to strategic moves in the AI space. There were hints that Facebook might officially release the Lama weights, a significant development that could influence the AI landscape."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion overall touched on the importance of AI optimization, the introduction and potential of the Mojo programming language, and strategic moves by tech giants in the AI domain."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls16-img3",
              "height": 930,
              "width": 930,
              "filename": "abls16-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692568243-abls16-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google and the AI Landscape"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google Leak Confirmed"
                      },
                      {
                        "type": "span",
                        "value": ": Simon Willison revealed that insiders have confirmed the legitimacy of a leaked Google document."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google's Ad Model at Risk"
                      },
                      {
                        "type": "span",
                        "value": ": Both Simon and swyx discussed how ChatGPT, and other chatbots that don't serve ads, could pose a threat to Google's ad-driven revenue model. They also touched on the future of ad-supported chat models like a prototype of Bing with ads."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Safety Concerns"
                      },
                      {
                        "type": "span",
                        "value": ":"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Simon distinguished between \"science fiction\" concerns of AI, like it turning against humans, and immediate threats, such as the misuse of AI for scams. He particularly highlighted the risk of AI-enabled romance scams."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussions hinted at an undercurrent of unease among key industry figures about AI safety."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "swyx suggested Simon could document real, non-science fiction threats posed by AI today."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Prompt Injection"
                      },
                      {
                        "type": "span",
                        "value": ": Simon expressed concern about the current risk from AI, where systems could be easily manipulated by attackers. swyx humorously suggested that individuals might start incorporating \"prompt injections\" into their bios to detect AI scraping."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google vs. OpenAI"
                      },
                      {
                        "type": "span",
                        "value": ": The document indicated that there might be internal concerns within Google about AI competition. swyx felt the document provided a glimpse into Google's internal sentiments. The debate also touched on the assertion that OpenAI, despite its innovations, lacked a sustainable competitive advantage or \"moat\"."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion concluded with Travis Fischer's perspective on the eventual commoditization of large language models, agreeing with the document's sentiment about OpenAI's uncertain edge in the long run."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls16-img1",
              "height": 930,
              "width": 930,
              "filename": "abls16-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692568257-abls16-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI Innovations and Concerns: A Dialogue with Simon Willison and Travis Fischer"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Simon Willison discussed the challenge posed to his open-source project \"datasets\" by Chat GPT's capabilities, which could perform many of the tasks he had planned for the project's future. Nonetheless, he emphasized the growing convergence of data and AI and promoted his blog, simonwillis.net, and his newsletter which updates on AI advancements."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Travis Fischer announced the founding of his new company, aiming to develop a framework for creating reliable AI agents for specific use cases. He likened the broader AI projects to the complexities of self-driving vehicles and mentioned his desire to build from foundational, reliable primitives. Additionally, he referenced the success of his Chat PT Twitter bot which has amassed over 125,000 followers and has been sponsored by OpenAI, after a brief branding alteration."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation concluded with swyx highlighting the shifting boundaries in AI usage and copyright, and expressing gratitude to the contributors and audience for their involvement."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls16-img4",
              "height": 930,
              "width": 930,
              "filename": "abls16-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692568279-abls16-img4.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Explore 'No Moat: Closed AI's Open Source Awakening' with Simon Willison. Dive into leaked Google Moat memo insights.",
        "title": "Latent Space Podcast 5/5/23 [Summary] - No Moat",
        "twitterCard": null,
        "image": {
          "width": 1602,
          "height": 532,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
        }
      }
    },
    {
      "id": "190260671",
      "topics": [
        "LLM",
        "Code",
        "Summary"
      ],
      "title": "Latent Space Podcast 5/3/23 [Summary] - Training a SOTA Code LLM in 1 week and Quantifying the Vibes — with Reza Shabani of Replit",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "Ep. 10 with Reza Shabani: Dive deep into the rapid training of a state-of-the-art Code LLM, explore Replit Ghostwriter's future, and journey from Finance to AI. Discover the transition from Kaplan to Chinchilla and more!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/reza-shabani#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "Training a SOTA Code LLM in 1 week and Quantifying the Vibes — with Reza Shabani of Replit"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "From Quantitative Trading to AI Leadership: Reza Shabani’s Journey and Predictions"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio Fanelli, partner and CTO in residence at Decibel Partners, and co-host swyx, a writer and editor of the Latent Space podcast, invite Reza Shabani, the Head of AI at Replit, for a chat. Reza details his surprising background, beginning with a PhD in economics from Berkeley, moving on to startup founding, followed by a stint in systematic equity trading at BlackRock and Wellington. A common assumption is that Reza doesn't know how to code given his econ background, but he clarifies that coding and data analysis were indeed part of his wheelhouse."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation takes a deep dive into quantitative finance and data engineering. Reza describes his grad school experience, which entailed extracting and analyzing data from financial news channels to gauge the market response to specific companies. He touches on his experiences at BlackRock, where he dabbled in utilizing emerging technologies, like NLP and machine learning, to trade effectively. They further discuss how identifying early adoption of emerging technologies by companies can serve as an indicator of their potential success in the stock market. For instance, Walmart's early focus on mobile technology as opposed to Sears’ lack of attention to it was discussed as an example. The conversation also touches on the challenge of signals being overshadowed by noise in the finance world. Towards the end, Reza raises an intriguing question about the potential for AI to excel in quantitative finance."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-08-20-at-10-17-26-pm",
              "height": 530,
              "width": 1566,
              "filename": "screenshot-2023-08-20-at-10-17-26-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "From Data Foundations to Cutting-Edge AI: Reza Shabani's Work at Replit"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Reza Shabani, during his tenure at Replit, has played an instrumental role in transforming the company's data infrastructure. When he first came on board about a year and a half ago, the company was grappling with scalability issues. The primary challenge was the inability to query vast amounts of data effectively. For instance, a seemingly simple question, such as identifying the most forked repository, could not be answered due to system limitations."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Shabani's initial efforts centered around building and modernizing Replit's data infrastructure. By streamlining processes, they were able to extract data insights within minutes rather than the earlier timelines of days, weeks, or even months. This robust foundation was pivotal for the next steps - venturing into artificial intelligence and model training, particularly using Replit's data."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "As time progressed, Replit expanded its AI and data team, working on a range of AI-driven features. Notably, the team developed 'Ghostrider', a suite of tools designed for tasks like code explanation, code generation, code transformation, and in-context IDE chats. The foundation of Ghostrider was built on open-source initiatives, like Salesforce's 'cogen' model, which was optimized for Replit's user base."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Alessio Fanelli pointed out the evolving nature of Shabani's role - transitioning from analytical tasks, focusing on data insights, to more production-oriented roles that encompass the latest language model systems (LMS). Shabani highlighted a noticeable trend - the shift from traditional machine learning approaches to more natural language processing-based techniques. While the hype around language models has overshadowed other ML realms, Shabani emphasized the continuing value of other ML expertise areas."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Adding to the discussion, swyx underscored the pivotal moment most startups experience as they mature: the realization of the need for a robust data team. This is especially pertinent as companies grow, and data-driven decisions become crucial. Interestingly, many finance professionals, like Shabani, are well-equipped for this transition given their knack for building reliable and scalable systems in fast-paced environments."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Ending the conversation on a high note, Shabani teased the imminent release of Replit's first open-source code model, signifying another milestone in their AI journey."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img1",
              "height": 930,
              "width": 930,
              "filename": "abls17-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692587658-abls17-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Evaluating Code Generative Models"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a lively discussion between Alessio Fanelli, Reza Shabani, and Swyx, the trio delves into the intricacies of benchmarking and evaluating code-generating AI models. They use two primary benchmarks: the \"human eval\", where a model is given a function definition and then tested based on its completion of that function, and the \"Amjad eval\", an informal vibe test named after an individual with a knack for quickly gauging a model's performance."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Interestingly, models might ace the \"human eval\" but flunk the \"Amjad eval\". This highlights the disparity between quantitative benchmarks and qualitative user experience. The conversations illustrate that while some models excel in traditional tasks, they might perform poorly when posed with nuanced, context-heavy challenges or even straightforward instructions. Conversely, certain models, though lesser-known, may outperform their high-end counterparts in specific scenarios."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The \"vibe test\", as elaborated, doesn’t solely rely on the correctness of the model’s output but also factors in the latency, productivity enhancements, and user experience. The discussion closes with an acknowledgment of the challenges in benchmarking, stressing the importance of holistic model evaluation beyond just performance metrics."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img2",
              "height": 930,
              "width": 930,
              "filename": "abls17-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692587578-abls17-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring the Nuances of AI Model Vibes and Advanced Coding Tools"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a thought-provoking discussion, Alessio Fanelli and Reza Shabani delve deep into the challenges and nuances of training AI models for optimal \"vibes.\" They highlight the intricate balance between training data and resulting model outputs. Shabani emphasizes the inherent difficulty in refining certain vibe elements in models like \"Bard.\" The optimal strategy hinges on feeding the model the right type of data and hoping for a generative output that aligns with desired outcomes. It's asserted that you can't merely add vibes; it's inherently present or absent."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation pivots to the evolution of coding assistance tools. Initially dominated by Co, a myriad of new tools have emerged, raising the question of differentiation. Ghost Rider, one such tool, promises not just to complete codes but to offer a more holistic support in the software development process. The vision for Ghost Rider is to generate software scaffolding, assist in backend database creation, and even automate tasks like setting up new service accounts. The true ambition is to help generate entire software applications, not just specific code sections."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Introducing the concept of the Ghostwriter Autonomous Agent, Shabani envisions an autonomous system that can drive the IDE (Integrated Development Environment). Such an agent can predict sequences of actions, extending beyond just predicting the next line of code. The goal is to create software, fully incorporating the steps of cloning repos, editing, adding files, and deploying."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "As the talk concludes, attention is directed towards the release of Replit-code-v1-3b, a 2.7 billion parameter model trained on a massive 525 billion tokens of code. The uniqueness of this model lies in its tailor-made vocabulary specifically for coding, leading to faster inference and more relevant content generation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discussion provides an exciting glimpse into the advancements of AI in coding, painting a future where AI does not just assist but actively participates in the software development process."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img3",
              "height": 930,
              "width": 930,
              "filename": "abls17-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692587596-abls17-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Adventurous Journey to the YOLO Training Run"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "During a recent discussion, Reza Shabani recalled the events leading up to a major developer day. The team at Reza's organization had been tirelessly working on building infrastructure for training their own models for months. This required creating an extensive data infrastructure to handle vast amounts of data and content."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "By the end of the previous year, they had successfully built a system capable of parsing vast datasets in record time. As they approached the developer day, they had built pipelines, started training models, and were deploying them into production. However, they were somewhat limited in their approach, focusing on single-language models and not fully leveraging the potential of their data."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A pivotal moment came when Amjad proposed the idea of just 'yoloing' the process. Instead of meticulously planning, he suggested they run the models on all the data they had. This was a risky move, given the cost, time, and potential for error in such a massive data processing task. Yet, driven by this adventurous spirit, they went ahead and even resampled their data multiple times, which is generally viewed as a risky method that can lead to model overfitting. Still, the results were surprisingly good."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "An ongoing debate emerged regarding the most efficient way to train the models, reflecting on the \"scaling laws\" of model training. They debated whether they should strictly adhere to accepted scaling laws like Chinchilla's or venture into the unknown. The overarching sentiment was that perhaps the community has been undertraining models and that there's room for pushing boundaries."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation also touched upon other significant figures in the field, like Jonathan from Mosaic, who's working on massive language models, highlighting that while there might be limitations with code models due to data shortages, there's vast potential in the broader language model arena."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img4",
              "height": 930,
              "width": 930,
              "filename": "abls17-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692587616-abls17-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Replit & MosaicML: Advancing AI Infrastructure and Embracing the Future"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a recent conversation between \"swyx\" and \"Reza Shabani\", the success and advantages of MosaicML were discussed. Shabani highlighted that Mosaic provides a beneficial separation between GPU offerings and cloud providers, offering a versatile training infrastructure. One of Mosaic's significant advantages includes sourcing GPUs from various providers, which makes the training infrastructure more fault-tolerant. They also bring expertise in training models, providing pre-configured setups that optimize GPU utilization and ensure efficient model training."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Despite the efficiency Google claims its TPUs have, Reza emphasized a preference for systems that the majority uses, indicating TPUs lack widespread adoption."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Furthermore, Reza delved into the future plans for Replit, mentioning current hiring needs. Positions include an Applied AI/ML Engineer focused on data pipelines and an Applied AI Full Stack Engineer that combines model training with user-focused application integration. Notably, Replit's team comprises skilled individuals, like Bradley, an early YouTube employee who contributes significantly to Replit's inference stack."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation underlines the complexity and potential of modern AI infrastructure, the importance of strategic hardware choices, and the dynamic future that Replit envisions for its team."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img5",
              "height": 930,
              "width": 930,
              "filename": "abls17-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692587633-abls17-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Embracing the Future: Understanding AI's Rapid Evolution and Societal Impact"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a \"Lightning Round\" discussion with Alessio Fanelli and swyx, Reza Shabani touches on the rapid evolution of AI, especially in replicating human communication, as seen in popular culture like Black Mirror. Shabani highlights societal concerns over AI's potential to replace both blue and white-collar jobs. He stresses the importance of harnessing AI to assist rather than displace human workers and touches on the unforeseen applications of advanced AI in industries beyond chat. Discussing prompt engineering in AI models, Shabani expects it will diminish in certain algorithmic models, but will remain vital for more human-like interactions. As a final takeaway, Shabani encourages embracing AI by learning its benefits and potential, comparing its societal impact to the internet's transformative role."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "abls17-img6",
              "height": 930,
              "width": 930,
              "filename": "abls17-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1692588012-abls17-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Ep. 10 with Reza Shabani: Dive deep into the rapid training of a state-of-the-art Code LLM!",
        "title": "Latent Space Pod 5/3/23 [Summary] - SOTA Code LLM",
        "twitterCard": null,
        "image": {
          "width": 1566,
          "height": 530,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
        }
      }
    },
    {
      "id": "190629271",
      "topics": [
        "LLM",
        "Small Models",
        "Summary"
      ],
      "title": "Latent Space Podcast 4/28/23 [Summary] - Mapping the future of *truly* Open Models and Training Dolly for $30 — with Mike Conover of Databricks",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "Explore the future of open models with Mike Conover of Databricks. Dive deep into Dolly's creation, its transition from 1.0 to 2.0, & the influences behind its development. Ep.9 touches on model infrastructure, Databricks' vision, & more. #AI #OpenModels #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/mike-conover#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "https://www.latent.space/p/mike-conover#details"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In this episode of the Latent Space Podcast, hosts Alessio Partner, CT and Residence and Decibel Partners, Joan Bama, and swyx Brighter welcome guest Mike Conover."
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Introduction of Mike Conover"
                              },
                              {
                                "type": "span",
                                "value": ": Mike is a staff software engineer at Databricks. His educational background is rooted in complex systems analysis at Indiana University, where he performed analysis of clusters on Twitter. He has worked at LinkedIn, where he focused on the homepage news relevance, later moved to SkipFlag, an enterprise knowledge graph, and then transitioned to Workday after its acquisition. At Workday, he took on the role of the director of machine learning engineering."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Personal Insights"
                              },
                              {
                                "type": "span",
                                "value": ": Mike shares his love for exploring off-trail in the backcountry, drawing a parallel between understanding topographic maps and the way he looks at high-dimensional spaces in machine learning. He also enjoys camping trips and archery."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "About Dolly"
                              },
                              {
                                "type": "span",
                                "value": ": Dolly, a project from Databricks, quickly became a significant open-source sensation. In its initial version, Dolly 1.0 was based on the GPT-J model with 6 billion parameters and was trained using the alpaca training set. The choice to use GPT-J instead of LLaMA was due to its accessibility and familiarity."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Development of Dolly"
                              },
                              {
                                "type": "span",
                                "value": ": Mike discussed the creation of Dolly and how it was driven by his interest in how information moves through networks of people. The inspiration for Dolly was to improve the developer experience, making it more intuitive and interactive."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Dolly 2.0"
                              },
                              {
                                "type": "span",
                                "value": ": A significant upgrade was introduced with Dolly 2.0, which has 12 billion parameters. This version was based on the Elu model family. Instead of using the alpaca training set, Dolly 2.0 was trained with a new dataset created by Databricks employees. The shift to a more personalized dataset came as a bid to make the tool more comprehensive and user-centric."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the podcast, Mike emphasizes the passionate drive behind Databricks projects and the collaborative spirit that allows for rapid innovations like Dolly."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-09-06-at-3-12-24-pm",
              "height": 628,
              "width": 1572,
              "filename": "screenshot-2023-09-06-at-3-12-24-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring AI’s Evolution: From Data Synthesis to Geopolitical Negotiations"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Gamifying Instruction Tuning:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Discussing the FLAN dataset, which has thousands of tasks, it's highlighted how it prevents models from overfitting as it requires generalization across tasks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The dataset's brief response structure makes models generate shorter results."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They touched on the leaderboard's gamification and how certain participants tended to dominate contributions, likening it to the \"long tail\" distribution observed in human systems."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They emphasize the importance of genuine usefulness rather than just perceived performance."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Summarization - Thumbnails for Language:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Summarizing data is challenging due to its need for synthesis, especially when the source material is lengthy."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They delve into the idea of \"thumbnails for language,\" drawing a parallel with how the visual cortex processes images quickly. They discuss how AI might shape the way we process large text chunks, optimizing comprehension."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They jokingly mentioned using emojis as potential textual thumbnails."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "CICERO and Geopolitical AI Agents:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They explore the potential for AI in resolving geopolitical disputes. The Cicero paper from Meta illustrates this, where AI was used in a negotiating game simulating diplomacy."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "They envision nation-states deploying AI systems that can find non-exploitable, game-theoretically optimal solutions to geopolitical problems."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Additionally, they speculate on AI's potential to personalize information compression for individuals to maximize comprehension."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Datasets vs Intentional Design:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Comparing the traditional design of items like jet turbines with AI, the conversation leans into the discovery of latent capabilities in models."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The Pithia Suite is introduced as a matrix of model checkpoints and sizes, exploring how behaviors evolve during training."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's discussion about reproducing the LLaMA dataset, especially concerning the challenges of managing such large datasets. They emphasize the potential for more intentional AI training in the future, tailoring models for specific tasks."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img1",
              "height": 930,
              "width": 930,
              "filename": "lsn-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694040869-lsn-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring the Intersection of Biology, Classic NLP, and Generative AI in Modern Tech Development"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Biological Foundations of AI:"
                      },
                      {
                        "type": "span",
                        "value": " The discussion revolved around understanding AI's development using a biological approach. The idea of \"speed running evolution\" was presented, emphasizing AI's rapid development. The differences in the evolution of artificial and biological life were also discussed, citing Richard Dawkins' \"bio morphs\" as an example. These bio morphs are vector-art-looking insects where parameters like the number of legs, antennas, etc., are recombined using genetic algorithms, offering a visual representation of synthetic evolution based on aesthetic preferences."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Training and Adapting LLMs (Large Language Models):"
                      },
                      {
                        "type": "span",
                        "value": " The conversation shifted to how businesses could adapt technologies like Dolly. While some might think Databricks’ work with Dolly is merely to showcase capabilities, the primary intent is to assist businesses in understanding and implementing these technologies effectively. The difference between an LLM’s generic outputs and a business-specific requirement was highlighted, like the difference between writing a generic moody letter and crafting a business-centric message. The process of instruction tuning and the importance of understanding model size relative to the task was touched upon."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Evaluation and Efficiency:"
                      },
                      {
                        "type": "span",
                        "value": " The discussion emphasized the importance of effective evaluation benchmarks. Although models like GPT-J and Dolly might score similarly in benchmarks, their qualitative outcomes are vastly different. The challenge lies in measuring a model's desired behavior, especially in enterprise contexts. The idea of human-in-the-loop feedback and active learning was introduced, emphasizing the importance of humans guiding AI systems."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Balancing Old Techniques with New:"
                      },
                      {
                        "type": "span",
                        "value": " There's still value in classical machine learning techniques. Not everything needs a generative AI approach. For instance, named entity recognition or multi-class classification for categorizing customer support tickets are simple yet valuable tasks. The speed of inference was discussed, noting that Databricks' system is notably faster than many others. Classical ML models could be used in conjunction with generative models for efficiency, challenging the notion that agents will only communicate with agents."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Future and Best Use Cases of LLMs:"
                      },
                      {
                        "type": "span",
                        "value": " Generative AI remains an exciting field with many potential branches yet to be explored. However, there's a belief that a blend of older techniques with new ones might yield optimal results. Generative models excel in tasks only they can achieve, like generating customer support replies in a company's specific tone and voice. This could revolutionize how businesses approach problem-solving, making tasks that took machine learning teams weeks to complete doable in minutes. However, the true cost-saving potential remains to be seen."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img2",
              "height": 930,
              "width": 930,
              "filename": "lsn-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694040949-lsn-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Understanding Dolly's Cost-Effective Training on Databricks"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Dolly, a model developed on Databricks, garnered attention for its cost-effective training price point of just $30. This intriguing value was achieved by training the original Dolly on Databricks clusters, a platform that proved efficient for multi-node distributed fine-tuning. Utilizing Databricks allowed the researchers to train Dolly in less than an hour for 50,000 records, demonstrating both the power and efficiency of the platform."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Open-sourcing has been integral to the success and approach of Databricks, with its founders holding strong beliefs in communal benefits and mutual success. They've consistently released technologies to the public that most would view as valuable IP. This has created an ecosystem where innovation thrives and the community reaps mutual benefits."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Moving into the domain of \"LM ops\", which refers to language model operations, there's a recognized need for new and efficient tools. Developers require platforms that not only provide quantitative benchmarks but also qualitative subjective benchmarks, along with human-in-the-loop feedback. Databricks aims to address this gap by developing solutions that cater to the evolving requirements of AI developers."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Despite available tools like Prompt Layer, a significant need remains for a comprehensive tool that merges speed, efficiency, and user-friendliness, offering an improved alternative to traditional methods like spreadsheets."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img3",
              "height": 930,
              "width": 930,
              "filename": "lsn-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694041016-lsn-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI, Spreadsheets, and the Evolution of Productivity: A Glimpse into Future Workspaces"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a discussion on AI's role in modern technology:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The speaker references an investment called \"Quadra\" which seems to be a tool similar to Google Sheets but has features such as web assembly, canvas, and the capability to use languages like Python, SQL, and Scala. The value proposition is to improve the utility of sheets-like platforms by integrating AI-like template filling without obstructing experimentation."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The conversation then shifts to AI's role in workplace productivity. The impact of AI is compared to the introduction of spreadsheets in the 1980s. Professionals initially resisted spreadsheets but later embraced them as they realized that the technology eliminated tedious aspects of their jobs, allowing them to focus on more valuable tasks."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The topic of AI-driven writing is touched upon. The speaker believes that although there's stigma around AI-generated content now, in the future, AI might be trusted to draft emails or negotiate contract details on behalf of users."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Mention is made of \"OpenAssistant,\" \"CerebrasGPT,\" and \"Red Pajama\" - each being different AI projects or technologies. The speaker praises OpenAssistant for its open data set and suggests it will significantly impact future AI endeavors."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A method for paraphrasing prompts is discussed which involves translating a prompt to another language and back to get a differently worded prompt."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "\"Red Pajama\" seems to be related to a paper named \"LLaMA\" which uses multiple data sources, including common crawl and Wikipedia, to train its model. The complexities and challenges of using such large datasets for training are discussed."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Note: This summary encapsulates the primary themes and topics discussed in the transcript and streamlines the content for easier understanding."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img4",
              "height": 930,
              "width": 930,
              "filename": "lsn-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694041040-lsn-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exploring the Versatility and Evolution of AI Models: Dolly, OpenAI, and Self-Reflection."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Dolly's Edge Over OpenAI GPT"
                      },
                      {
                        "type": "span",
                        "value": " The distinction between \"open\" and commercially usable tools was discussed, emphasizing how Dolly provides clarity in its licensing for commercial use. Many businesses found it hard to use Dolly 1.0 due to its training data sources. However, Dolly's recent advancements are clear and designed for business applications, from processing public web data to managing customer support tickets. One significant value proposition is that businesses can confidently build on Dolly without licensing ambiguities, and this clarity has garnered a positive response."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Open Source Licensing for AI"
                      },
                      {
                        "type": "span",
                        "value": " The shift from traditional open-source licensing that revolves around code to newer paradigms that emphasize the importance of the model's weights was explored. The licensing regime needs clarity, and while external validations, like the Open Source Initiative, might be ideal, clarity in semantics is paramount."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Value of Open-Sourcing AI Models"
                      },
                      {
                        "type": "span",
                        "value": " Open-sourcing AI models can help in addressing challenges more comprehensively. By exposing these models to a wider audience, especially those who can critically evaluate them from different perspectives, like ethics or security, we can get a more holistic understanding of potential pitfalls. The alternative is to blindly trust internal teams, which may not always have a comprehensive view."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Moving Between Models"
                      },
                      {
                        "type": "span",
                        "value": " Transitioning between models, even iterations of the same model (e.g., GPT-3.5 to GPT-4), can produce varied behaviors. A future product class could involve meta-models that evaluate the outputs and facilitate such migrations. A need for an infrastructure that aids in moving prompts from one model to another was also highlighted."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Learning in a Simulation"
                      },
                      {
                        "type": "span",
                        "value": " Drawing parallels to real-world experiences, the discussion veered towards the concept of models facing repercussions. Just as humans learn from mistakes, models currently don't have a mechanism to \"suffer\" consequences from the suggestions they make. There's intrigue around how future models might evolve if they face \"repercussions\" for incorrect suggestions."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Model Reflection & Self-Criticism"
                      },
                      {
                        "type": "span",
                        "value": " One fascinating concept touched upon was the self-reflexivity of models. AI models, such as those from Lang Chain, can judge the correctness of their generated content when presented with it, post-generation. This \"reflection\" allows the model to attend to the entirety of its generated content and judge its validity. The hope is that models can become more accurate by playing against themselves, similar to how AlphaGo improved by playing against itself."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img5",
              "height": 930,
              "width": 930,
              "filename": "lsn-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694041284-lsn-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Lightning Round Discussion on AI's Impact"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Favorite AI Product"
                              },
                              {
                                "type": "span",
                                "value": ": Google Maps was highlighted due to its ability to adaptively visualize information, integrate machine learning, and personalize user experiences. The speaker uses it reflexively and appreciates the unseen design that makes the application so intuitive."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "AI in Advertising"
                              },
                              {
                                "type": "span",
                                "value": ": The potential for advertising on Google Maps was mentioned, emphasizing its prime real estate for businesses."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Influential AI Communities"
                              },
                              {
                                "type": "span",
                                "value": ": The hugging face group was commended for simplifying complex processes in the AI industry. Their commitment to open source projects such as Transformers and diffusers was appreciated."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Future Surprises in AI"
                              },
                              {
                                "type": "span",
                                "value": ": The imminent possibility of AI-generated music and the rise of \"character AI\" was discussed. There's potential for high-fidelity avatars that represent individuals' beliefs and intents based on their past communication. This development may challenge societal norms and perceptions."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "AI in Music"
                              },
                              {
                                "type": "span",
                                "value": ": AI's capability to produce music that feels organic was discussed, with reference to a song by Kanye West and Weekend. The implications for music labels and the blurring distinction between true creativity and formulaic production were touched upon."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "marks": [
                                  "strong"
                                ],
                                "value": "Desired AI Applications"
                              },
                              {
                                "type": "span",
                                "value": ": The potential for AI in optimizing outdoor experiences was emphasized. The U.S.'s vast public lands could be better utilized with AI-guided exploration. Another idea proposed was the use of AI for swarm management – using multiple sensors and inputs from various agents to, for instance, monitor backcountry trail conditions."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation revolved around the ever-expanding applications of AI, from the mundane to the profound, and the impacts of these advancements on society, creativity, and business."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn-img6",
              "height": 930,
              "width": 930,
              "filename": "lsn-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694041302-lsn-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Ep.9 touches on model infrastructure, Databricks' vision, & more. #AI #OpenModels #Dolly",
        "title": "Latent Space Pod 4/28/23 [Summary] - Mike of Databricks",
        "twitterCard": null,
        "image": {
          "width": 1572,
          "height": 628,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
        }
      }
    },
    {
      "id": "191164291",
      "topics": [
        "LLM",
        "Enterprise",
        "Summary"
      ],
      "title": "Latent Space Podcast 4/21/23 [Summary] - AI-powered Search for the Enterprise — with Deedy Das of Glean",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "Ep.8: Dive into AI in enterprise search with Deedy Das of Glean. Unpack challenges in creating an AI search giant, Google vs ChatGPT comparisons, AI infrastructure intricacies, spotting AI-generated text, and why businesses need more than just Document QA.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Original Link: "
                      },
                      {
                        "url": "https://www.latent.space/p/deedy-das#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "https://www.latent.space/p/deedy-das#details"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Introduction"
                      },
                      {
                        "type": "span",
                        "value": " Alessio from Decibel Partners welcomes listeners to the Latent Space Podcast, introducing his cohost Swyx, and their special guest Deedy Das from Glean."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "About Deedy Das"
                      },
                      {
                        "type": "span",
                        "value": " Deedy, who prefers to go by this name over his formal name Debarghya, shares his professional journey:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Completed his bachelor's and master's in Computer Science from Cornell."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Worked at Facebook and Google, specializing in search."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Led a sports team with a focus on cricket."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Transitioned to Glean, contributing to its evolution into a search unicorn that optimizes intelligent search for workplaces. Outside of his professional life, Deedy is an avid reader, particularly of fiction. He praises the book \"The Three Body Problem\", appreciating its unique blend of alien fiction with physics and its contrast to Western literature."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Origin and Evolution of Glean"
                      },
                      {
                        "type": "span",
                        "value": " Deedy explains that Glean's inception wasn't about creating a product in search of a problem; instead, it aimed to address a significant issue prevalent in many companies. He references Google's internal tool, MoMA, which indexes various internal resources, suggesting that many Google employees miss this functionality upon leaving the company. Glean's purpose was to address the \"information retrieval problem\" many faced in their workplaces. Historically, the concept of enterprise search isn't new, but technological advances, the proliferation of SaaS apps, and the increasing importance of remote work have made Glean's solution timely and relevant."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "From Syntactic to Semantic Search"
                      },
                      {
                        "type": "span",
                        "value": " The conversation then shifts to the changing nature of web search: from being syntax-driven to now leaning towards semantic understanding. Glean aids in transforming the enterprise experience by focusing more on the intent behind questions rather than the specific wording or syntax used. For Glean to remain impactful, Deedy believes it's essential not just to offer search functionality but to serve as a comprehensive employee portal, providing features like Go Links, feeds, and mentions, which amalgamate notifications across different platforms like Slack, Jira, and GitHub."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, Glean is bridging the gap in information retrieval in modern workplaces, integrating the convenience of intuitive search with the comprehensive offerings of an employee portal."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-09-07-at-5-43-48-pm",
              "height": 530,
              "width": 1608,
              "filename": "screenshot-2023-09-07-at-5-43-48-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Evolution of Employee Portals and the Shift from Google to AI-Powered Search"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Challenges of Employee Portals Like Glean:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe adoption of employee portals is not widespread because selling them involves addressing less tangible benefits like productivity, which doesn't fit the common enterprise sales metrics of increasing revenue or cutting costs. While tools like Glean enhance productivity, showcasing a direct monetary value remains a challenge."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Enterprise Search Technology:"
                      },
                      {
                        "type": "span",
                        "value": "\nAlthough buzzwords like \"AI-powered\" and \"vector search\" are prevalent, it's essential to realize that user experience matters more than the complexity of the technology. Glean, while utilizing advanced technology, prioritizes the meticulous tuning of its ranking algorithm and takes a hybrid approach combining core IR signal, synonymy, query accentuation, and vector search. Personalization plays a pivotal role in their system, ensuring that users receive relevant search results based on their role and interactions."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Glean Chat and Future Products:"
                      },
                      {
                        "type": "span",
                        "value": "\nWhile Glean is always exploring new technologies and products, no specific confirmation about a \"Glean chat\" was given."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Google vs. ChatGPT:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe user shared their personal inclination towards ChatGPT for many queries, emphasizing that it offers answers to questions one wouldn't typically think the internet could address. However, while ChatGPT is efficient in specific areas, like answering rare or \"tail queries\", Google is superior in providing comprehensive responses and navigating to relevant resources. There is a decline in traffic on platforms like Stack Overflow, possibly indicating a shift in users seeking technical answers. Finally, the shift of enterprise product search away from Google might impact its AdWords revenue, although the implications of this weren't elaborated upon."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn2-img1",
              "height": 1024,
              "width": 1024,
              "filename": "lsn2-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694149146-lsn2-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "The Future of Search: Freshness, Ad Revenue, and AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Freshness in Search:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Large language models currently can't rapidly index new information, which Google labels as \"freshness.\""
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Retrieval-augmented generation is a workaround, utilizing search results in the background to generate a response. Bing currently employs this method."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Ad Revenue Implications:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Google's predominant revenue comes from placing ad links above search results."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Chat interfaces disrupt this model, as users typically don't click in chat."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "A shift from the conventional search to chat might endanger the web ecosystem. Websites might not see the incentive to exist if they're just sources for AI to train on."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Shifting from ad revenue to subscription-based models may not yield similar profits."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Latency Concerns:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Latency affects user engagement; more latency generally leads to less engagement."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "However, technological improvements over time are expected to reduce latency."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Google's LamDA model, for instance, employs tools for factual, deterministic information and modifies its response accordingly."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Accuracy and Memorization:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "GPT-4's accuracy is primarily due to memorizing facts rather than understanding context or current events. Its factual recall has limitations."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "For instance, it can recall data pre-2021 but struggles with events after."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Tool Use and LLMs (Large Language Models):"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "There's currently a lot of experimentation in how LLMs are used."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Examples like \"react\" and \"tool form\" are essentially trial methods that have stuck."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "LLMs can also be used to generate synthetic data to bootstrap smaller models, a process that can greatly reduce development times."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Other AI Search Tools - Perplexity and Neeva:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Both products aim to synthesize search results."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Their reliance on existing indexes like Bing, combined with unclear monetization strategies, raises concerns about their long-term viability."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In essence, while AI and search interfaces like chatbots present promising avenues for user interaction, there are inherent challenges tied to information freshness, revenue generation, response times, and the accuracy of results."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn2-img2",
              "height": 1024,
              "width": 1024,
              "filename": "lsn2-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694149286-lsn2-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Navigating the Future of AI: Challenges, Opportunities, and Imagination"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Challenge with Document QA and LM Startups"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The current AI landscape, particularly concerning Language Models (LMS), reveals that while excitement exists around new technologies, there's an over-emphasis on solution-first approaches rather than problem-first ones. Many startups are venturing into the LM space, but their value proposition often lacks distinctiveness, leading to an overwhelming number of companies offering similar products, such as Q&A for documents. This approach tends to be ill-conceived as users don't usually ask questions of their documents. There’s a clear indication that more startups should engage with genuine user problems rather than merely incorporating AI for its novelty."
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Investment in AI Startups"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Investors are often more inclined to back founders who exhibit a genuine understanding of the technology they’re working with and its application in a relevant problem space. A major red flag for investors is startups that seem to be led by the sentiment \"LMS are cool, so we should build something with them,\" rather than a well-defined problem thesis. Trusting the founder’s expertise and intuition about their specific industry often outweighs other concerns."
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Emerging Ideas in AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Beyond the language models, there's a burgeoning space of innovation in image and video AI applications. The image space, in particular, is producing mind-blowing results that have far-reaching appeal, even to non-tech audiences. Voice synthesis, such as the one being developed by 11 labs, is another area with enormous potential, with applications stretching into areas like podcasting."
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "The Ultimate AI Dream: Harry Potter IRL"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A convergence of advancements in AI – from image generation, voice recognition, language modeling, to tts – could bring about an evolution reminiscent of the living pictures in the Harry Potter series. This involves creating digital avatars that can interact in real-time, using the voice, language, and even the image of the person it's based on. Such advancements have the potential to revolutionize how we interact with technology and possibly immortalize personal interactions and memories."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn2-img3",
              "height": 1024,
              "width": 1024,
              "filename": "lsn2-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694149325-lsn2-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Unpacking AI: Infrastructure Costs, Open Source Dynamics, and the Horizon of Innovations"
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "AI Infrastructure Costs and Transparency"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The speaker emphasizes the lack of transparency in large companies regarding the true costs of AI infrastructures. Despite the detailed information on technical specifications, such as TPUs and training durations, the actual financial cost of developing models remains undisclosed. The speaker points out that understanding these costs is vital, especially for startups focusing on unit economics. He even offers a rough estimate on the cost of training some models and mentions the potential discrepancies when calculating these costs."
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Open Source Language Models: Advantages and Ethical Concerns"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Open source large language models (LLMs) have become a significant talking point in the AI community. Comparing with the image generation models, the speaker notes the success and benefits of open sourcing. However, text generation poses more potential risks. While image forgeries can often be discerned, deceitful or malicious text content is harder to detect. This power, when accessible to individuals, may be misused. Yet, the counterpoint is that democratizing this technology can lead to widespread innovation and prevent monopolies."
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 3,
                    "children": [
                      {
                        "type": "span",
                        "value": "Future Innovations in AI"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Runway ML is highlighted as an emerging player focusing on video editing with generative techniques. The speaker believes that the future of AI will see advancements in streaming voice recognition, text-to-speech (TTS) systems, and multi-modality applications like video editing and 3D modeling. The speaker also envisions a future where dynamic moving and speaking images, akin to Harry Potter's magical photos, become a reality."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": []
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Exam Fraud, Text Generation, and the Art of Detection"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "AI Models and Text Watermarking:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe conversation delves into the potential harms of unrestricted access to AI language models, emphasizing the need for watermarking to differentiate between human and machine-generated text. The guest advocates for standardized watermarking across various language models for easy detection and understanding."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Examination Fraud and Data Anomalies:"
                      },
                      {
                        "type": "span",
                        "value": "\nDrawing from personal experience, the speaker sheds light on the manipulation of exam results in the Indian educational system. With the board exams playing a pivotal role in determining college admissions, the conversation unveils data inconsistencies and arbitrary marking. For instance, certain scores like 91 never appeared in any subject in any year, hinting at non-transparent grading manipulation. The speaker mentions an effort in 2013 to scrape and analyze the data, revealing alarming patterns that questioned the legitimacy of the scores."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Comparative Insight:"
                      },
                      {
                        "type": "span",
                        "value": "\nThe discussion transitions to similarities between the examination fraud and financial discrepancies in hedge fund returns. Just as the Indian exam data showed inexplicable patterns, Madoff funds and certain hedge fund returns also exhibited non-normal distributions, suggesting fabricated numbers. Such anomalies serve as \"watermarks\" that betray human or systemic manipulation. Despite the significant implications, the speaker laments the lackluster response to the exam data inconsistencies in India."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn2-img5",
              "height": 1024,
              "width": 1024,
              "filename": "lsn2-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694149441-lsn2-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Lightning Round"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In the lightning round of the discussion, the guest emphasizes their preferred AI communities and sources. While Reddit isn’t frequently used by them for AI, Twitter emerges as a prime learning platform. AI Pub is particularly highlighted due to its round-up of AI content, which aids in catching up with the latest in the AI world. On the topic of future AI developments, the guest is optimistic about models becoming cheaper and faster, although they believe there might be a cap soon on the quality of AI advancements."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation touches upon practical applications of AI, including a tool that auto-responds to certain messages and drafts answers for more significant ones. While a basic version has been developed, refining it is still ongoing. Another area of interest is an AI system that manages GitHub issues efficiently, even generating PRs to address vulnerabilities."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In wrapping up, the guest stresses the importance of bridging the gap between AI research and end consumers, advocating for more people to delve into AI research papers and watch explanatory content like that of Andre Kapai's YouTube channel. The guest, known as Didi, can be followed on Twitter via \"debark_das\" and also has a personal website linked from their Twitter profile."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn2-img6",
              "height": 1024,
              "width": 1024,
              "filename": "lsn2-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694149483-lsn2-img6.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Ep.8: Dive into AI in enterprise search with Deedy Das of Glean. Unpack challenges in creating an AI search giant, Google vs ChatGPT ...",
        "title": "Latent Space Podcast 4/21/23 [Summary] - with Deedy Das ",
        "twitterCard": null,
        "image": {
          "width": 1608,
          "height": 530,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
        }
      }
    },
    {
      "id": "191165673",
      "topics": [
        "Summary",
        "Vision"
      ],
      "title": "Latent Space Podcast 4/13/23 [Summary] - Segment Anything Model and the Hard Problems of Computer Vision — with Joseph Nelson of Roboflow",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "Explore Ep.7 with Joseph Nelson on the Segment Anything Model by Meta. Dive deep into Computer Vision's future, the significance of OCR, Image Segmentation, and beyond. #Roboflow #AI",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "contentBlock": [
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Link to Original: "
                      },
                      {
                        "url": "https://www.latent.space/p/segment-anything-roboflow#details",
                        "type": "link",
                        "children": [
                          {
                            "type": "span",
                            "value": "https://www.latent.space/p/segment-anything-roboflow#details"
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Summary"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In this engaging chat, swyx hosts Joseph Nelson, a dynamic individual with a background that spans from economics to politics to tech. Their camaraderie is evident as they discuss past affiliations, with swyx recalling first hearing about Joseph on the Source Graph podcast. Joseph's notable journey includes:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Earning a Bachelor of Economics degree from George Washington University."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Engaging in political activism, notably his creation of \"Representing\", a tool likened to Zendesk but tailored for Congress to manage their voluminous constituent communications."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Diversifying his experience with roles like a data science instructor at General Assembly and a consultant."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "His transition from natural language processing to computer vision, inspired by his ventures at hackathons, specifically his challenges with a chess project at TechCrunch Disrupt in 2019."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "The foundation and leadership of Roboflow, his current venture in the AI space."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Joseph exudes pride in his Iowan roots, emphasizing the genuine, caring nature of its people and recounting notable individuals who share his Iowan heritage. He shares a behind-the-scenes look at Roboflow, noting its Des Moines origin, the bond with his co-founder Brad, and their experiences building the company, especially during the Covid-19 pandemic."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The duo hint at exploring the potential applications of computer vision, such as assisting with groceries, and anticipate discussing Roboflow's product 'Segment Anything' in the next part of the conversation."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "screenshot-2023-09-07-at-10-15-52-pm",
              "height": 604,
              "width": 1604,
              "filename": "screenshot-2023-09-07-at-10-15-52-pm.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Origin of Roboflow"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The podcast discussed the origin and development of \"Roboflow\". The journey began with an app called Magic Sudoku, an augmented reality game designed to solve Sudoku puzzles by hovering the phone over it. The creators, after gaining attention for this concept, explored other potential applications. They aimed to add a software layer to the real world, allowing users to interact with objects through a mobile app. They focused on board games initially, starting with Boggle, a game that has players form words from adjacent letter tiles. They then moved onto Chess, developing an app within 48 hours during a hackathon at TechCrunch Disrupt in 2019. This app recognized a chessboard's state and suggested moves. Evan Spiegel, the founder of Snapchat, took an interest in their work at this hackathon. Though they didn't win awards at Disrupt, they gained recognition and subsequently won a $15,000 grant from a Des Moines contest. The podcast also touched upon the confusion around John Papa John, a supporter of the Iowa entrepreneurial scene, who is often mistakenly associated with the pizza brand due to the similarity in name."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img1",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img1.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694153885-lsn3-img1.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Unlocking the Potential of Computer Vision"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a comprehensive discussion about the potential and reach of computer vision, the underlying mission of making the world more programmable through computer vision is emphasized. This technology allows us to interact with our surroundings in a more entertaining, intuitive, and efficient manner. The company aims to provide engineers with the tools, data, and models necessary to develop programmable interfaces swiftly. The scope of computer vision applications is extensive and can range from microscopic tasks to astronomical observations. Several real-world use cases were highlighted:"
                      }
                    ]
                  },
                  {
                    "type": "list",
                    "style": "bulleted",
                    "children": [
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Recognizing specific ingredients in sushi."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Estimating damages on rooftops."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Monitoring worker safety in workplaces through hardhat detection."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Environmental monitoring to keep track of species count and changes in natural habitats."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Medical applications like early cancer detection by analyzing cell structures."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "City planning and traffic management based on real-time vehicle detection."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Home automation projects, such as package arrival notifications or ensuring gates are closed."
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "type": "listItem",
                        "children": [
                          {
                            "type": "paragraph",
                            "children": [
                              {
                                "type": "span",
                                "value": "Unique DIY projects like a workout machine for a cat powered by computer vision."
                              }
                            ]
                          }
                        ]
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Major enterprises like Walmart and Cardinal Health, as well as over 250,000 developers, have employed these computer vision tools, testifying to the technology's adaptability and relevance across sectors. Whether it's enhancing self-driving car datasets or innovatively utilizing computer vision for personal home projects, the overarching message is clear: computer vision holds the key to making the world more interactive, informed, and innovative."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img2",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img2.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694153902-lsn3-img2.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "Understanding the Economics of Annotation in Computer Vision"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The discourse begins by addressing the challenges of annotation in computer vision. Annotation is often a necessary step when introducing computer vision to a business, especially when an off-the-shelf dataset is unavailable. The speaker highlights the difficulty in estimating the time, effort, and cost involved in annotation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "However, there's optimism in the field. Advancements are ensuring that annotation will become less of a roadblock for computer vision applications. There are emerging models that can recognize items zero-shot, without any annotation. Yet, unique and proprietary data, such as specifics about a product, will still require annotation."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The complexity of the problem and the variance in the scene dictate the number of images required. For instance, recognizing a scratch on a specific part in controlled lighting might need fewer images than recognizing that scratch in varied lighting conditions. There are rough estimates, like using 200 images per class to achieve a 90% accuracy model, but it depends on the specific use-case. The focus is not always on achieving 100% accuracy; sometimes it's about whether a model can outperform a human or at least be a more economical alternative."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Additionally, the value a model provides can sometimes outweigh its accuracy. For instance, in sports analytics, it may be more efficient for a model to track certain movements, even if it's less accurate, due to the cost savings over a human doing the same task."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The conversation then transitions to the topic of computer vision annotation formats. The challenge lies in the myriad ways to describe an object's position in an image. There are multiple formats, such as using the top-left coordinate and bottom-right or using the center of the box with its length and width. Different models and datasets often come with their distinct annotation formats, causing conversion challenges. The speaker mentions the inception of Robo Flow, a tool to convert between these formats, alleviating this common pain point. The discussion also touches upon the worst annotation formats they've encountered, with a mention of a particularly challenging format from a university in China."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img3",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img3.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694153917-lsn3-img3.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Exploring Computer Vision: From Basics to YOLO v8"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a comprehensive discussion on computer vision segmentation, the main themes revolve around the different types of tasks that computer vision can accomplish. These range from straightforward image classification to object detection and advanced tasks like instance segmentation. Instance segmentation, for example, uses polygon shapes for precise area measurements, which can be crucial in applications such as determining the square footage of homes from aerial photos for insurance estimates."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Another interesting point brought up was the key point detection task, which identifies joints or specific points on objects. Visual question answering tasks are also emerging as a game-changer, where an image is presented and the system identifies objects within it, potentially useful for activities like recipe creation based on food items identified in a photo."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A significant portion of the discussion focused on object detection. Here, bounding boxes play a critical role as they provide a versatile solution compared to other methods. Within object detection, different model frameworks have emerged over time. The earlier models, like R-CNN, were relatively slower due to their two-pass method of first identifying potential bounding box candidates and then classifying them."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A revolutionary change came with single-shot detectors, which, as the name suggests, perform object detection in a single pass. The most popular among these is the YOLO (You Only Look Once) family of models introduced by Joseph Redmon at the University of Washington. This model has undergone several versions, with YOLO v5 and its subsequent naming controversy being a notable point. As of the discussion, YOLO v8 stands as the state-of-the-art, marking the continued evolution and sophistication of this framework in the realm of computer vision."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img4",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img4.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694153949-lsn3-img4.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "value": "SAM: Revolutionizing Object Segmentation with World Knowledge"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Foundational Models and World Knowledge in Computer Vision"
                      },
                      {
                        "type": "span",
                        "value": " Discussing the evolution of computer vision, the conversation highlights how recent models incorporate a vast amount of contextual world knowledge. Rather than manually collecting images for training (like for a bus or chair detector), models are now trained on extensive datasets sourced from the internet. The aim is to make the model's corpus as vast as the internet itself. This approach reduces the need for extensive manual annotations. The conversation transitions to talk about distilling the knowledge of large models into smaller, efficient architectures for real-time processing on devices like edge devices."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Segment Anything Model (SAM) Overview"
                      },
                      {
                        "type": "span",
                        "value": " SAM, introduced by Facebook as the 'Segment Everything Model', garnered significant attention with 24,000 GitHub stars within its first week. This model is a zero-shot segmentation tool, designed to identify and mask all objects in an image without any prior training on that specific object. What sets SAM apart is its dataset: 11 million images with 1.1 billion segmentation masks. This dataset size surpasses its predecessors, such as Open Images, by a significant margin. SAM facilitates the creation of new applications ranging from background removal to video editing, making object segmentation and recognition significantly more accessible."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Technical Dive into SAM"
                      },
                      {
                        "type": "span",
                        "value": " The zero-shot capability of SAM means that it can recognize objects it hasn't been explicitly trained on. SAM's architecture comprises an image encoder and a transformer trained on its massive dataset. When an image is passed through SAM during inference, it first goes through the image encoder to produce an image embedding. This embedding is then passed through a mask decoder, producing multiple candidate masks. SAM can be prompted to focus on particular areas of an image or interact with specific parts, offering a fine-tuned object segmentation process."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img5",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img5.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694154098-lsn3-img5.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "RoboFlow's SAM Demonstration: A Glimpse into the Future of Computer Vision"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a multimodal podcast demonstration, the interface of RoboFlow, a computer vision platform, was showcased. Two models were compared: one before SAM (Segmentation and Annotation Model) integration and one post SAM. The primary focus was on image segmentation, particularly on a challenging weld image where two pipes come together. Traditional methods like the Smart Poly, which existed pre-SAM, required multiple clicks to accurately segment the weld, often producing inaccurate selections."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "However, with SAM, the precision and efficiency increased dramatically, demonstrating that it could pinpoint details like the weld with significantly fewer clicks. SAM's capabilities were further showcased with various images, including one of two kids with a background brick wall and another with a chihuahua. Its ability to discern and segment specific details (like the eyes of the chihuahua) was underlined."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "The broader implications of such advancements were discussed. The ease of creating custom models and IP with RoboFlow was emphasized, suggesting that SAM's introduction has simplified dataset preparation. The hosts also touched upon the imminent potential of GPT-4's multimodality, speculating that features like code generation from imagery and sophisticated OCR using large language models instead of dedicated OCR models might be on the horizon."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img6",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img6.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694154115-lsn3-img6.png"
            }
          ]
        },
        {
          "mainContent": {
            "value": {
              "schema": "dast",
              "document": {
                "type": "root",
                "children": [
                  {
                    "type": "heading",
                    "level": 2,
                    "children": [
                      {
                        "type": "span",
                        "marks": [
                          "strong"
                        ],
                        "value": "Expanding Computer Vision and Roboflow's Journey"
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "In a deep discussion about AI and computer vision, the challenges of expanding the capabilities of AI models like GPT-4 were brought to light. The speaker likened the progression of AI vision to a bell curve, where the center represents common objects and contexts like chairs, cars, and food. This center is steadily growing to encompass less common data and problems, but there are still challenges to face, especially with proprietary information."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "A significant portion of the conversation also revolved around Roboflow, a platform to help with computer vision tasks. The speakers touched upon Roboflow's early days, discussing how they started with the idea of translating Stack Overflow to multiple languages, which eventually morphed into the broader Roboflow platform we see today."
                      }
                    ]
                  },
                  {
                    "type": "paragraph",
                    "children": [
                      {
                        "type": "span",
                        "value": "Throughout the discussion, there was an emphasis on the importance of both ingesting knowledge and producing content to truly understand and expand in the AI realm. The conversation concluded with some general advice for staying updated in AI, including being genuinely curious, engaging with various sources, and participating actively in the community."
                      }
                    ]
                  }
                ]
              }
            }
          },
          "topImages": [
            {
              "basename": "lsn3-img7",
              "height": 1024,
              "width": 1024,
              "filename": "lsn3-img7.png",
              "format": "png",
              "alt": null,
              "url": "https://www.datocms-assets.com/101962/1694154131-lsn3-img7.png"
            }
          ]
        }
      ],
      "seo": {
        "description": "Dive deep into Computer Vision's future, the significance of OCR, Image Segmentation, and beyond. #Roboflow #AI",
        "title": "Latent Space Podcast 4/13/23 [Summary] - Segment Anything ",
        "twitterCard": null,
        "image": {
          "width": 1604,
          "height": 604,
          "title": null,
          "alt": null,
          "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
        }
      }
    }
  ],
  "blogContent": {
    "id": "190259129",
    "topics": [
      "LLM",
      "Hardware",
      "Summary",
      "Edge"
    ],
    "title": "Latent Space Podcast 8/10/23 [Summary]: LLMs Everywhere: Running 70B models in browsers and iPhones using MLC — with Tianqi Chen of CMU / OctoML",
    "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T09:18:37+01:00",
    "description": "Explore the magic of MLC with Tianqi Chen: deploying 70B models on browsers & iPhones. Dive into XGBoost, TVM's creation, & the future of universal AI deployments. ",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Original Link: "
                    },
                    {
                      "url": "https://www.latent.space/p/llms-everywhere#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "LLMs Everywhere: Running 70B models in browsers and iPhones using MLC — with Tianqi Chen of CMU / OctoML"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Summary"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 3,
                  "children": [
                    {
                      "type": "span",
                      "value": "About TQ and XGBoost"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In the recent episode of the "
                    },
                    {
                      "type": "span",
                      "marks": [
                        "emphasis"
                      ],
                      "value": "Latent Space"
                    },
                    {
                      "type": "span",
                      "value": " podcast, hosts Alessio and Swyx sat down with Tianqi Chen (TQ), an assistant professor at Carnegie Mellon University and a leading figure in the machine learning community. Tianqi wears many hats, including being associated with Catalyst Group and OctoML, and has a significant footprint in the open-source ecosystem, especially with projects like Apache TVM, XGBoost, and MXNet."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a candid conversation, TQ shared that beyond his technical persona, he has a unique hobby of sketching design diagrams in real sketchbooks, chronicling his journey through various projects. These sketches serve as a blueprint for his software projects and provide a tangible record of his thought processes over the years."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Tianqi’s acclaimed project, XGBoost, came up for discussion, highlighting its origins and unexpected success. Originally designed as an alternative to the rising trend of deep learning models, XGBoost ended up establishing its own niche, particularly for tabular data where tree-based models excel. The discussion gravitated toward the balance and potential amalgamation of tree-based models and deep learning. TQ believes in the lasting relevance of tree-based models, especially considering their natural rules, scalability, and interoperability. The talk wrapped up with a glimpse into the future, hinting at the merging of transformer models and tree-based algorithms for enhanced data processing."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-12-at-10-42-43-pm",
            "height": 548,
            "width": 1538,
            "filename": "screenshot-2023-08-12-at-10-42-43-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "TVM Compiler, MXNet"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio brought up Tianqi's development of the TVM compiler framework for models, which was released around the same time as ONNX, seeking clarity on their relationship. Tianqi recalled his history with deep learning, mentioning his work on ImageNet classification using convolutional restricted Boltzmann machines before the emergence of AlexNet. He shared challenges faced while handcrafting NVIDIA CUDA kernels, which took months, only to find the model wasn't highly effective. This experience introduced him to the complexities of optimizing performance on GPUs."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Following his work on XGBoost, Tianqi collaborated on MXNet, which came before frameworks like CAFE and PyTorch. Recognizing the difficulties in optimization for different hardware, Tianqi sought to create a more automated and general solution, leading to the development of TVM. The TVM compiler can intake machine learning programs, apply optimization techniques, and generate low-level code compatible with various backends, including NVIDIA and non-NVIDIA platforms."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "While Tianqi's shift from XGBoost to TVM seemed significant to Alessio, Tianqi clarified his motivation was less about impact and more about enjoying the coding process and addressing challenges. He identified as a problem-solver, and when faced with challenges, he seeks out tools or creates new ones to address them. This approach, he mentioned, is in line with an emerging trend in machine learning systems that consider both algorithmic and system optimizations."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Discussing the community's growth, Tianqi highlighted MLsys, a conference focusing on machine learning systems. Swyx noted Tianqi's involvement in major conferences like ICML and NeurIPS, suggesting that community organization plays a role in his work, to which Tianqi responded affirmatively, noting it's part of his academic responsibilities."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls3-img1",
            "height": 936,
            "width": 936,
            "filename": "abls3-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1691897144-abls3-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "MLsys, MCLLM & MLC"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a conversation between Swyx, Tianqi, and Alessio, the discussion revolves around MLsys, MLCLLM, and machine learning compilation (MLC). Here are the key takeaways:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "MLsys and MLCLLM"
                            },
                            {
                              "type": "span",
                              "value": ": Swyx notes Tianqi's recent venture in MLsys and its integration with MLCLLM on mobile phones. He mentions using Llama 2 and Vicuña but seeks clarity about other models on offer."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Tianqi's MLC Journey"
                            },
                            {
                              "type": "span",
                              "value": ": Tianqi explains his venture into MLC as an evolution from their initial project TVM. The main goal is to build an effective machine learning compiler. From the experience gained with TVM, they embarked on a second iteration named TVM Unity. MLCLLM is essentially an MLC initiative to develop machine learning compilation technology that can be applied widely. One achievement is getting machine learning models to run on phones and other universal platforms, including Apple's M2 Macs."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Integration with PyTorch"
                            },
                            {
                              "type": "span",
                              "value": ": Addressing Swyx's query about model integrations, Tianqi highlights that while many models are built in PyTorch, the aim is to bring them into the TVM's program representation called TVM script. The goal is to optimize the models across various platforms and ensure they're portable and efficient."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "MLC as a Discipline"
                            },
                            {
                              "type": "span",
                              "value": ": Swyx points out that while many people specialize in compilers, Tianqi's niche in MLC seems innovative. Tianqi believes machine learning compilation will grow as a field, drawing inspiration from existing compiler optimizations and incorporating knowledge from machine learning and systems."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Optimization and Libraries"
                            },
                            {
                              "type": "span",
                              "value": ": Discussing the limitations of relying on existing libraries for optimization, Tianqi elaborates on TVM's approach, which combines using available libraries and automatically generating libraries. This method facilitates support for less well-supported hardware."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Core Optimization Techniques"
                            },
                            {
                              "type": "span",
                              "value": ": Tianqi touches upon four essential optimization techniques: Kernel fusion (combining operations smartly), memory planning (allocating memory efficiently), loop transformation (ensuring code runs efficiently), and weight quantization (reducing memory usage). He explains that these methods allow for both efficiency and portability in running machine learning models across various platforms."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In essence, the conversation underscores the significance of MLC and the evolution of platforms and optimization techniques to make machine learning models more universally applicable and efficient."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls3-img2",
            "height": 936,
            "width": 936,
            "filename": "abls3-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1691897165-abls3-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "LLM in Browser"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In a discussion with Swyx, Tianqi sheds light on the emerging trend of academics, like himself, transitioning from solely publishing insights to building tangible products, such as open-source projects and applications. Tianqi believes this hands-on approach enables academics to confront real-world problems directly and to ensure that their research provides immediate value to the public. In his field, machine learning systems, Tianqi sees the potential of deploying these systems into users' hands to drive innovation and solve genuine problems."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "He elaborates on his experience with running a 70 billion parameter model in a browser, specifically highlighting the challenges and requirements of executing such a feat. Using the latest MacBook with an M2 Max and WebGPU technology, Tianqi's team was able to successfully run the model, showcasing the possibility of operating powerful models on consumer devices without needing installations. He envisions diverse application scenarios, including hybrid models that run both on-edge and server components."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio queries about browser model integrations, and Tianqi introduces an NPM package, WebILM, which allows developers to embed their models onto web apps. Additionally, an OpenAI compatible REST API is under development to streamline integration further."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Lastly, Swyx touches upon the challenges of model downloads, wherein Tianqi mentions the Chrome cache system which prevents redundant downloads for similar web apps. When asked about the proliferation of local model projects, Tianqi emphasizes the importance of enhancing API capabilities and encourages a collaborative ecosystem that focuses on universal deployment."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls3-img3",
            "height": 936,
            "width": 936,
            "filename": "abls3-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1691897179-abls3-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Octomel & Conclusion"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "\nAlessio initiates the conversation by discussing Tianqi's involvement as the co-founder of Octomel and its recent release of OctoAI, a compute service focused on model runtime optimization. He inquires about Octomel's evolution from being a traditional MLOps tool to its current stance with OctoAI, particularly in the context of the market's shift towards pre-trained generative models."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Tianqi explains that they identified challenges related to scalability, integration, and optimization. As the market shifts towards generative AI, OctoAI aims to simplify the process and alleviate the complexity for users, allowing them to focus on their models while Octomel handles the underlying infrastructure."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Alessio points out that a significant bottleneck in the market is around the execution of AI models. Earlier, the challenge was around building models due to a lack of talent, but now, with numerous models available, the challenge lies in running them efficiently."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Tianqi underscores the nuances associated with \"running\" AI models. Given the diversity in hardware availability and ever-changing user requests, execution challenges have multiplied. Efficiently managing model locations and ensuring proximity to the execution environment are paramount. The future, according to Tianqi, involves leveraging all available hardware to reduce costs and optimize the interplay between edge devices and the cloud."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "When Alessio probes about the challenges of abstracting hardware details from end users, Tianqi emphasizes the importance of compatibility with various hardware and the ongoing iterative process of refining their product based on user needs and feedback."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx steers the conversation towards the broader AI landscape, where Tianqi shares his enthusiasm for open-source projects, especially those that champion inter-model interactions, and the prospect of a diverse ecosystem of AI agents."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Swyx then inquires about potential architectures succeeding transformers. Tianqi mentions models like RWKV and other recurrent networks integrated with transformers, emphasizing the ongoing growth in the model space."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "In the lightning round, Tianqi reveals his surprise at the swift emergence of conversational chatbots. When questioned about the most intriguing unsolved question in AI, he expresses his fascination with continuous learning and lifelong learning for AI."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "As a final takeaway, Tianqi encourages listeners to adopt a holistic approach when building AI applications. A successful AI system demands the fusion of algorithms, system optimizations, and data curations."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls3-img4",
            "height": 936,
            "width": 936,
            "filename": "abls3-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1691897193-abls3-img4.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Explore deploying 70B models on browsers & iPhones. Dive into XGBoost, TVM's creation, & the future of universal AI deployments. ",
      "title": "Latent Space 8/10/23 [Summary]: LLMs Everywhere",
      "twitterCard": null,
      "image": {
        "width": 1538,
        "height": 548,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      }
    }
  },
  "i18n": {
    "navigationTopic": {
      "bitcoin": "Bitcoin",
      "gems": "Gems",
      "how_to": "How To",
      "analysis": "Analysis",
      "opinion": "Opinion"
    },
    "navigationCategories": {
      "ai": "AI",
      "ai-research": "AI Research",
      "crypto": "Crypto",
      "bitcoin": "Bitcoin",
      "startup": "Startups",
      "investing": "Investing",
      "bitcash": "bitcash"
    },
    "searchInputPlaceholder": "Search",
    "backHome": "Go back home",
    "backBitcash": "Back to bitcash.org",
    "navigationPoliciesTerms": {
      "privacy_policy": "Privacy Policy",
      "terms_and_conditions": "Terms and Conditions"
    },
    "subscriptionTitle": "Subscribe For The Latest Updates",
    "subscriptionSubtitle": "Subscribe to the newsletter and never miss the new post every week.",
    "subscriptionInputPlaceholder": "Enter your email here …",
    "subscriptionCta": "Subscribe",
    "homeFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg",
      "threads": "https://threads.net/@bitcashorg"
    },
    "cryptoFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg.crypto",
      "threads": "https://threads.net/@bitcashorg"
    },
    "bitcoinFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg.bitcoin",
      "threads": "https://threads.net/@bitcashorg"
    },
    "aiFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg.ai",
      "threads": "https://threads.net/@bitcashorg"
    },
    "investingFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg.investing",
      "threads": "https://threads.net/@bitcashorg"
    },
    "startUpsFollowLinks": {
      "telegram": "https://t.me/bitcash_org",
      "twitter": "https://twitter.com/bitcashorg.startups",
      "threads": "https://threads.net/@bitcashorg"
    },
    "cookieConsentDescription": "This website uses cookies to improve user experience. By using our website you consent to all cookies in accordance with our Cookie Policy.",
    "cookieConsentCta": "Accept"
  },
  "topics": [
    "LLM",
    "Hardware",
    "Summary",
    "Edge"
  ]
}