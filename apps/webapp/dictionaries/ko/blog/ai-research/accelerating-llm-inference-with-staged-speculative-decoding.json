{
  "relatedBlogs": [
    {
      "id": "198277124",
      "topics": [
        "LLM",
        "금융",
        "헬스케어",
        "법률",
        "프롬프팅"
      ],
      "title": "대규모 언어 모델을 통한 독해력 향상",
      "slug": "adapting-large-language-models-via-reading-comprehension",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:22+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 통한 독해력 향상",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277342",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 seq2seq 모델 오픈 소스",
      "slug": "openba-an-open-sourced-15b-bilingual-asymmetric-seq2seq-model-pre-trained-from-sc",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:02+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 모델",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277117",
      "topics": [
        "LLM",
        "검색"
      ],
      "title": "PDFTriage: 긴 구조화된 문서에 대한 질문 답변",
      "slug": "pdftriage-question-answering-over-long-structured-documents",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:49+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "PDFTriage: 긴 구조화된 문서에 대한 질문과 답변",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277138",
      "topics": [
        "LLM",
        "미세 조정"
      ],
      "title": "Sorted LLaMA: 대규모 언어 모델의 중간 레이어를 사용한 동적 추론의 잠재력 해제",
      "slug": "sorted-llama-unlocking-the-potential-of-intermediate-layers-of-large-language-mod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:31+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Sorted LLaMA: 미세 조정을 사용한 동적 추론",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277150",
      "topics": [
        "LLM",
        "지시 조정",
        "다중 모달"
      ],
      "title": "대규모 다중 모달 모델의 지시 조정 확장에 대한 경험적 연구",
      "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:15+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 다중 모달 모델의 지시 조정 확장에 대한 경험적 연구",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277160",
      "topics": [
        "LLM",
        "에이전트",
        "게임"
      ],
      "title": "MindAgent: 신흥 게임 상호작용",
      "slug": "mindagent-emergent-gaming-interaction",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:32:58+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "MindAgent: 신흥 게임 상호작용",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277196",
      "topics": [
        "LLM",
        "구조화된 데이터"
      ],
      "title": "Struc-Bench: 대규모 언어 모델이 복잡한 구조화된 데이터 생성에 정말 능숙한가?",
      "slug": "struc-bench-are-large-language-models-really-good-at-generating-complex-structure",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:38+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Struc-Bench: 복잡한 구조화된 데이터 생성",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277217",
      "topics": [
        "LLM",
        "개인 정보",
        "엣지"
      ],
      "title": "대규모 언어 모델을 사용한 개인 정보 보호 마스킹 복구",
      "slug": "recovering-from-privacy-preserving-masking-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:26+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 사용한 개인 정보 보호 마스킹 복구",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277239",
      "topics": [
        "LLM",
        "채팅"
      ],
      "title": "S3-DST: 대규모 언어 모델 시대의 구조화된 오픈 도메인 대화 분할 및 상태 추적",
      "slug": "s3-dst-structured-open-domain-dialogue-segmentation-and-state-tracking-in-the-era",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:11+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "S3-DST: 구조화된 오픈 도메인 대화 분할 및 상태 추적",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277253",
      "topics": [
        "LLM",
        "오디오"
      ],
      "title": "대규모 언어 모델을 사용한 구어 이해를 위한 텍스트 보강",
      "slug": "augmenting-text-for-spoken-language-understanding-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:49+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 사용한 구어 이해를 위한 텍스트 보강",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277277",
      "topics": [
        "LLM",
        "압축"
      ],
      "title": "언어 모델링은 압축입니다",
      "slug": "language-modeling-is-compression",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:32+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "언어 모델링은 압축입니다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277345",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "백천 2: 대규모 언어 모델 오픈",
      "slug": "baichuan-2-open-large-scale-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:59:10+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "백천 2: 대규모 언어 모델 오픈",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277360",
      "topics": [
        "LLM",
        "RLHF"
      ],
      "title": "RLHF를 통한 안정화: 이점 모델 및 선택적 복습을 통한",
      "slug": "stabilizing-rlhf-through-advantage-model-and-selective-rehearsal",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:22:15+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "RLHF를 통한 안정화: 이점 모델 및 선택적 복습을 통한",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277446",
      "topics": [
        "LLM",
        "환각"
      ],
      "title": "검증 체인은 대규모 언어 모델에서 환각을 줄입니다",
      "slug": "chain-of-verification-reduces-hallucination-in-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:21:05+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "검증 체인은 대규모 언어 모델에서 환각을 줄입니다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277458",
      "topics": [
        "LLM",
        "환각",
        "엔티티",
        "구조화된 데이터"
      ],
      "title": "LMDX: 언어 모델 기반 문서 정보 추출 및 위치 지정",
      "slug": "lmdx-language-model-based-document-information-extraction-and-localization",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:20:31+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "LMDX: 언어 모델 기반 문서 정보 추출 및 위치 지정",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277109",
      "topics": [
        "LLM",
        "추론"
      ],
      "title": "대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킵니다",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:18:11+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킵니다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277099",
      "topics": [
        "LLM",
        "다국어",
        "데이터"
      ],
      "title": "CulturaX: 깨끗하고 거대하며 167개 언어로 된 다국어 데이터셋",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:14:53+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "CulturaX: 깨끗하고 거대하며 다국어 데이터셋",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198044900",
      "topics": [
        "LLM",
        "엔티티",
        "미세 조정"
      ],
      "title": "효과적인 엔티티 중요성 감지를 위한 문맥 정보 활용",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:30:50+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "효과적인 엔티티 중요성 감지를 위한 문맥 정보 활용",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198044892",
      "topics": [
        "LLM",
        "에이전트"
      ],
      "title": "웹 탐색을 위한 상태 공간 탐색을 갖춘 LLM 에이전트 LASER",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:26:17+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "웹 탐색을 위한 상태 공간 탐색을 갖춘 LLM 에이전트 LASER",
        "description": "추상적 코멘트 & 평가"
      }
    }
  ],
  "blogContent": {
    "id": "198277209",
    "topics": [
      "LLM",
      "데이터"
    ],
    "title": "SlimPajama-DC: LLM 교육을 위한 데이터 조합 이해",
    "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-04T23:43:32+01:00",
    "description": "추상적 코멘터리 및 평가",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "게시일: 9월 19일"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "저자:"
                    },
                    {
                      "url": "https://huggingface.co/Jason0214",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Zhiqiang Shen"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/Tianhua",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Tianhua Tao"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/LiqunMa",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Liqun Ma"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/willieneis",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Willie Neiswanger"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/jthestness",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Joel Hestness"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/vnata",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Natalia Vassilieva"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/daria-soboleva",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Daria Soboleva"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/EricX003",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Eric Xing"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "초록"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 논문은 SlimPajama를 사용하여 대규모 언어 모델의 교육에 다양한 데이터 조합(예: 웹 텍스트, 위키백과, 깃허브, 책)이 미치는 영향을 이해하려고 합니다. SlimPajama는 엄격하게 중복 제거된 다중 소스 데이터 세트로, Together가 기여한 방대한 1.2T 토큰의 RedPajama 데이터 세트에서 627B 토큰으로 세련되고 추가적으로 중복 제거되었습니다. 우리는 우리의 연구를 SlimPajama-DC라고 명명했으며, SlimPajama를 사용하여 대규모 언어 모델 교육에 관련된 기본 특성과 최선의 관행을 밝히기 위해 설계된 경험적 분석입니다. SlimPajama와의 연구 중에 두 가지 중요한 관찰이 나타났습니다: (1) 전역 중복 제거 대 지역 중복 제거. 우리는 전역(다양한 데이터 소스 간) 및 지역(단일 데이터 소스 내) 중복 제거가 훈련된 모델의 성능에 미치는 영향을 분석하고 논의합니다. (2) 고품질/고도로 중복 제거된 다중 소스 데이터 세트의 비율. 이를 연구하기 위해 SlimPajama 데이터 세트의 여섯 가지 구성을 구축하고 각각을 Alibi 및 SwiGLU가 있는 1.3B Cerebras-GPT 모델로 교육합니다. 우리의 최고 구성은 동일한 수의 교육 토큰을 사용하여 RedPajama에서 교육된 1.3B 모델보다 상당한 차이로 우수한 성능을 보입니다. 우리의 모든 1.3B 모델은 총 80 PFLOP/s의 bf16 혼합 정밀도에서 Cerebras 16배 CS-2 클러스터에서 교육됩니다. 우리는 또한 전역 중복 제거 후 데이터 다양성 증가가 중요하다는 발견을 7B 모델에서 대규모 배치 크기 교육으로 확장합니다. 우리의 모델과 별도의 SlimPajama-DC 데이터 세트는 다음에서 사용할 수 있습니다: https://huggingface.co/MBZUAI-LLM 및 https://huggingface.co/datasets/cerebras/SlimPajama-627B."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.10818",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "arXiv 페이지 보기"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.10818",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "PDF 보기"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "코멘터리"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "논문 \"SlimPajama-DC: LLM 교육을 위한 데이터 조합 이해\"는 SlimPajama 데이터 세트를 사용하여 대규모 언어 모델(LLM) 교육에 다양한 데이터 조합이 미치는 영향을 검토합니다. SlimPajama는 엄격하게 중복 제거된 다중 소스 데이터 세트입니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "주요 요약:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "SlimPajama 데이터 세트"
                            },
                            {
                              "type": "span",
                              "value": ": 이 데이터 세트는 방대한 1.2T 토큰의 RedPajama 데이터 세트의 세련되고 중복 제거된 버전입니다. 목표는 더 깨끗하고 중복 제거된 데이터 세트를 사용하여 LLM을 교육하는 것입니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "경험적 분석"
                            },
                            {
                              "type": "span",
                              "value": ": SlimPajama-DC 연구는 SlimPajama를 LLM 교육에 사용할 때 내재된 특성과 최선의 관행을 검토합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "전역 대 지역 중복 제거"
                            },
                            {
                              "type": "span",
                              "value": ": 다양한 데이터 소스 간의 전역 중복 제거와 단일 데이터 소스 내의 지역 중복 제거 사이의 중요한 구분이 이루어지며 각각이 훈련된 모델의 성능에 미치는 영향을 설명합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "데이터 품질 및 중복 제거"
                            },
                            {
                              "type": "span",
                              "value": ": 조합된 고품질/고도로 중복 제거된 다중 소스 데이터 세트의 비율이 미치는 영향을 평가합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "성능 지표"
                            },
                            {
                              "type": "span",
                              "value": ": 그들의 최고 구성은 동일한 수의 교육 토큰을 사용하여 더 큰 RedPajama 데이터 세트에서 교육된 1.3B 모델보다 상당히 우수한 성능을 보입니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "대규모 교육 인프라"
                            },
                            {
                              "type": "span",
                              "value": ": 그들은 bf16 혼합 정밀도에서 총 80 PFLOP/s의 용량을 갖춘 강력한 컴퓨팅 설정을 사용했습니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "잠재적 실제 세계 영향:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "효율적인 모델 교육"
                            },
                            {
                              "type": "span",
                              "value": ": 데이터 조합과 중복 제거가 모델 교육에 미치는 영향을 이해함으로써 더 효율적이고 효과적인 LLM 교육 프로세스를 초래할 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "개선된 LLM"
                            },
                            {
                              "type": "span",
                              "value": ": 교육에 사용된 데이터 세트를 정제함으로써 결과 모델은 다양한 NLP 애플리케이션에서 더 정확하고 유용한 출력을 제공할 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "향후 연구를 위한 지침"
                            },
                            {
                              "type": "span",
                              "value": ": 이 경험적 분석은 대규모 언어 모델 교육 분야의 연구자 및 산업 전문가에게 통찰력과 최선의 관행을 제공합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "자원 할당"
                            },
                            {
                              "type": "span",
                              "value": ": 중복 제거 및 데이터 조합의 중요성을 인식함으로써 조직이 데이터 정리 및 중복 제거를 위한 자원을 할당하는 데 도움이 될 수 있습니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "도전 과제:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "일반화 가능성"
                            },
                            {
                              "type": "span",
                              "value": ": 이 논문은 SlimPajama에서 유망한 결과를 보여 주지만 이러한 발견이 다른 데이터 세트 및 모델에서 어떻게 일반화될지는 아직 미지수입니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "데이터 조합, 중복 제거 및 그들이 LLM 교육에 미치는 영향을 이해하는 데 중점을 둔 점을 감안할 때:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 논문의 실제 세계 영향을 10점 만점에 8점으로 평가합니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 연구는 대규모 언어 모델 교육에 사용되는 데이터를 최적화하는 데 유용한 통찰력을 제공하며, 더 나은 모델과 더 효율적인 교육 프로세스로 이어질 수 있습니다. 이러한 발견은 제한된 자원을 사용하여 LLM의 성능을 극대화하려는 조직 및 연구자에게 특히 관련이 있을 수 있습니다."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper8a",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper8a.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "추상적 코멘터리 및 평가",
      "title": "SlimPajama-DC: LLM 교육을 위한 데이터 조합 이해",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Data"
  ]
}