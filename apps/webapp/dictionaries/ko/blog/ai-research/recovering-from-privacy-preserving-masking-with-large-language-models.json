{
  "relatedBlogs": [
    {
      "id": "198277124",
      "topics": [
        "LLM",
        "금융",
        "헬스케어",
        "법률",
        "프롬프팅"
      ],
      "title": "대규모 언어 모델을 통한 독해력 향상",
      "slug": "adapting-large-language-models-via-reading-comprehension",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:22+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 통한 독해력 향상",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277342",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 seq2seq 모델 오픈 소스",
      "slug": "openba-an-open-sourced-15b-bilingual-asymmetric-seq2seq-model-pre-trained-from-sc",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:02+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 모델",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277117",
      "topics": [
        "LLM",
        "검색"
      ],
      "title": "PDFTriage: 긴 구조화된 문서에서의 질문 답변",
      "slug": "pdftriage-question-answering-over-long-structured-documents",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:49+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "PDFTriage: 긴 구조화된 문서에서의 질문과 답변",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277138",
      "topics": [
        "LLM",
        "미세 조정"
      ],
      "title": "Sorted LLaMA: 대규모 언어 모델의 중간 계층을 활용하여 동적 추론을 위한 정렬된 미세 조정 (SoFT) 가능",
      "slug": "sorted-llama-unlocking-the-potential-of-intermediate-layers-of-large-language-mod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:31+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Sorted LLaMA: 동적 추론을 위한 정렬된 미세 조정 (SoFT) 가능",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277150",
      "topics": [
        "LLM",
        "지시 조정",
        "다중 모달"
      ],
      "title": "대규모 다중 모달 모델의 지시 조정 확장에 관한 경험적 연구",
      "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:15+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 다중 모달 모델의 지시 조정 확장에 관한 경험적 연구",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277160",
      "topics": [
        "LLM",
        "에이전트",
        "게임"
      ],
      "title": "MindAgent: 게임 상호작용의 출현",
      "slug": "mindagent-emergent-gaming-interaction",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:32:58+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "MindAgent: 게임 상호작용의 출현",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277196",
      "topics": [
        "LLM",
        "구조화된 데이터"
      ],
      "title": "Struc-Bench: 대규모 언어 모델이 복잡한 구조화된 데이터 생성에 정말 능숙한가?",
      "slug": "struc-bench-are-large-language-models-really-good-at-generating-complex-structure",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:38+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Struc-Bench: 복잡한 구조화된 데이터 생성",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277239",
      "topics": [
        "LLM",
        "채팅"
      ],
      "title": "S3-DST: LLM 시대의 구조화된 오픈 도메인 대화 분할 및 상태 추적",
      "slug": "s3-dst-structured-open-domain-dialogue-segmentation-and-state-tracking-in-the-era",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:11+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "S3-DST: 구조화된 오픈 도메인 대화 분할 및 상태 추적",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277253",
      "topics": [
        "LLM",
        "오디오"
      ],
      "title": "대규모 언어 모델을 사용한 구어 이해를 위한 텍스트 증강",
      "slug": "augmenting-text-for-spoken-language-understanding-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:49+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 사용한 구어 이해를 위한 텍스트 증강",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277277",
      "topics": [
        "LLM",
        "압축"
      ],
      "title": "언어 모델링은 압축이다",
      "slug": "language-modeling-is-compression",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:32+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "언어 모델링은 압축이다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277345",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "백천 2: 대규모 언어 모델 오픈",
      "slug": "baichuan-2-open-large-scale-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:59:10+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "백천 2: 대규모 언어 모델 오픈",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277360",
      "topics": [
        "LLM",
        "RLHF"
      ],
      "title": "RLHF 안정화를 위한 이점 모델 및 선택적 반복",
      "slug": "stabilizing-rlhf-through-advantage-model-and-selective-rehearsal",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:22:15+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "RLHF 안정화를 위한 이점 모델 및 선택적 반복",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277446",
      "topics": [
        "LLM",
        "환각"
      ],
      "title": "검증 체인은 대규모 언어 모델에서 환각을 줄인다",
      "slug": "chain-of-verification-reduces-hallucination-in-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:21:05+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "검증 체인은 대규모 언어 모델에서 환각을 줄인다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277458",
      "topics": [
        "LLM",
        "환각",
        "엔티티",
        "구조화된 데이터"
      ],
      "title": "LMDX: 언어 모델 기반 문서 정보 추출 및 위치 지정",
      "slug": "lmdx-language-model-based-document-information-extraction-and-localization",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:20:31+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "LMDX: 문서 정보 추출 및 위치 지정",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277209",
      "topics": [
        "LLM",
        "데이터"
      ],
      "title": "SlimPajama-DC: LLM 훈련을 위한 데이터 조합 이해",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T23:43:32+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "SlimPajama-DC: LLM 훈련을 위한 데이터 조합 이해",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277109",
      "topics": [
        "LLM",
        "추론"
      ],
      "title": "대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킨다",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:18:11+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킨다",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198277099",
      "topics": [
        "LLM",
        "다국어",
        "데이터"
      ],
      "title": "CulturaX: 167개 언어로 대규모 언어 모델을 위한 깨끗하고 거대하며 다국어 데이터셋",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T22:14:53+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "CulturaX: 167개 언어로 대규모 언어 모델을 위한 깨끗하고 거대하며 다국어 데이터셋",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198044929",
      "topics": [
        "LLM",
        "데이터",
        "에이전트"
      ],
      "title": "추론을 위한 데이터 소스",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:33:25+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "추론을 위한 데이터 소스",
        "description": "추상적 코멘트 & 평가"
      }
    },
    {
      "id": "198044900",
      "topics": [
        "LLM",
        "엔티티",
        "미세 조정"
      ],
      "title": "효과적인 엔티티 중요성 감지를 위한 문맥 정보 활용",
      "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:30:50+01:00",
      "description": "추상적 코멘트 & 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "효과적인 엔티티 중요성 감지를 위한 문맥 정보 활용",
        "description": "추상적 코멘트 & 평가"
      }
    }
  ],
  "blogContent": {
    "id": "198277217",
    "topics": [
      "LLM",
      "개인 정보",
      "엣지"
    ],
    "title": "개인 정보 보호 마스킹에서 회복하기 위한 대형 언어 모델",
    "slug": "recovering-from-privacy-preserving-masking-with-large-language-models",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2024-05-25T03:38:26+01:00",
    "description": "추상적인 해설 및 평가",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "2023년 9월 12일 발행"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "저자:"
                    },
                    {
                      "url": "https://huggingface.co/arpita08",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "아르피타 바츠"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",제 류,펑 수,데브요티 폴,"
                    },
                    {
                      "url": "https://huggingface.co/yingyima",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "잉이 마"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ",유통 팡,지샨 아메드,오즐렘 칼린리"
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "초록"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "프록시 훈련 데이터와 실제 사용자 데이터 간의 차이를 처리하기 위해 모델 적응이 중요합니다. 적응을 효과적으로 수행하기 위해 사용자의 텍스트 데이터는 일반적으로 서버 또는 로컬 장치에 저장되며, 이러한 내부 데이터를 사용하여 하류 자연어 처리(NLP) 모델을 직접 훈련할 수 있습니다. 그러나 이는 사용자 정보를 적대자에게 노출시킬 수 있는 추가 위험으로 인해 개인 정보 및 보안 문제를 야기할 수 있습니다. 텍스트 데이터에서 식별 정보를 일반적인 표시로 대체하는 것이 최근에 탐구되었습니다. 이 연구에서는 대형 언어 모델(LLM)을 활용하여 마스크된 토큰의 대체물을 제안하고 하류 언어 모델링 작업에서 그 효과를 평가합니다. 구체적으로, 다양한 데이터 세트에서 이러한 방법들을 비교하기 위해 여러 사전 훈련 및 미세 조정된 LLM 기반 접근 방식을 제안하고 경험적 연구를 수행합니다. 실험 결과는 개인 정보 보호 토큰 마스킹 없이 원본 데이터에서 훈련된 모델과 비교할 수 있는 성능을 달성할 수 있음을 보여줍니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.08628",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "arXiv 페이지 보기"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.08628",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "PDF 보기"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "해설"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "\"개인 정보 보호 마스킹에서 회복하기 위한 대형 언어 모델\"이라는 논문은 사용자 데이터를 개인화하는 모델의 필요성과 사용자 데이터 개인 정보를 유지해야 하는 요구 사이의 긴장을 다룹니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "주요 요약:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "개인 정보 우려"
                            },
                            {
                              "type": "span",
                              "value": ": 개별 사용자 데이터를 더 잘 처리하기 위해 모델을 적응시킬 때 사용자의 원시 텍스트 데이터가 일반적으로 저장되며, 이는 민감한 사용자 정보를 노출시킬 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "토큰 마스킹"
                            },
                            {
                              "type": "span",
                              "value": ": 이러한 우려를 해결하기 위한 방법으로, 사용자를 식별할 수 있는 토큰은 일반적인 표시로 대체됩니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "LLM을 사용한 회복"
                            },
                            {
                              "type": "span",
                              "value": ": 이 작업은 대형 언어 모델(LLM)을 사용하여 이러한 마스크된 토큰의 대체물을 찾는 것을 제안하며, 데이터의 하류 작업에 대한 사용 가능성을 보장합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "성능 동등성"
                            },
                            {
                              "type": "span",
                              "value": ": 연구는 이러한 방식으로 처리된 데이터에서 훈련된 모델이 원본, 마스크되지 않은 데이터에서 훈련된 모델과 비교할 수 있는 성능을 달성할 수 있음을 보여줍니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "잠재적인 실제 세계 영향:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "개선된 개인 정보"
                            },
                            {
                              "type": "span",
                              "value": ": 시스템이 입력에 적응할 때 사용자는 자신의 민감한 데이터가 개인 정보를 보장하기 위해 마스크되었다는 사실을 알고 더 안심할 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "유연한 배치"
                            },
                            {
                              "type": "span",
                              "value": ": 회사 및 서비스 제공업체는 개인 정보 규정을 위반하거나 데이터 유출 위험 없이 개인화된 사용자 데이터를 사용하는 모델을 구현할 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "보편적 적용 가능성"
                            },
                            {
                              "type": "span",
                              "value": ": 개인 정보에 대한 우려가 전 세계적으로 증가함에 따라, 이 방법론은 사용자 생성 콘텐츠를 사용하는 모든 애플리케이션 또는 서비스에 대한 표준 관행이 될 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "신뢰 및 채택"
                            },
                            {
                              "type": "span",
                              "value": ": 데이터 개인 정보를 보장하는 것은 사용자로부터의 신뢰를 증가시킬 수 있으며, 이는 차례로 AI 기반 도구 및 애플리케이션의 채택률을 높일 수 있습니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "도전 과제:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "구현의 복잡성"
                            },
                            {
                              "type": "span",
                              "value": ": 마스크된 토큰에 대한 대체물을 찾기 위해 LLM을 사용하는 것은 시스템에 또 다른 복잡성 계층을 추가할 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "견고성"
                            },
                            {
                              "type": "span",
                              "value": ": 토큰 대체가 데이터에 우연히 편견이나 기타 문제를 도입하지 않도록 견고성을 보장하는 것이 필수적입니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "데이터 개인 정보의 중요성이 전 세계적으로 강조되고 있으며, 이 방법이 데이터 사용성을 희생하지 않고 보장할 수 있는 잠재력을 감안할 때:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 논문의 실제 세계 영향을 10점 만점에 9점으로 평가합니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "모델 적응을 허용하면서 데이터 개인 정보를 유지하는 것은 사용자 신뢰와 규제 준수 모두에 있어 중요합니다. 이 균형을 효과적으로 해결하는 솔루션은 데이터 중심의 세계에서 큰 가치가 있습니다."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "추상적인 해설 및 평가",
      "title": "LLM을 사용한 개인 정보 보호 마스킹에서의 회복",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Privacy",
    "Edge"
  ]
}