{
  "relatedBlogs": [
    {
      "id": "198277124",
      "topics": [
        "LLM",
        "재정",
        "헬스케어",
        "법률",
        "프롬프팅"
      ],
      "title": "언어 모델을 통한 독해력 향상",
      "slug": "adapting-large-language-models-via-reading-comprehension",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:22+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "언어 모델을 통한 독해력 향상",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277342",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 seq2seq 모델 오픈 소스화",
      "slug": "openba-an-open-sourced-15b-bilingual-asymmetric-seq2seq-model-pre-trained-from-sc",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:34:02+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "OpenBA: 처음부터 훈련된 15B 이중 언어 비대칭 모델",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277117",
      "topics": [
        "LLM",
        "검색"
      ],
      "title": "PDFTriage: 긴 구조화된 문서에서의 질문 답변",
      "slug": "pdftriage-question-answering-over-long-structured-documents",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:49+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "PDFTriage: 긴 구조화된 문서에서의 질문과 답변",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277138",
      "topics": [
        "LLM",
        "미세 조정"
      ],
      "title": "Sorted LLaMA: 대규모 언어 모델의 중간 레이어를 이용한 동적 추론의 잠재력 활용",
      "slug": "sorted-llama-unlocking-the-potential-of-intermediate-layers-of-large-language-mod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:31+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Sorted LLaMA: 동적 추론을 위한 정렬된 미세 조정 사용",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277150",
      "topics": [
        "LLM",
        "지시 조정",
        "다중 모달"
      ],
      "title": "대규모 다중 모달 모델의 지시 조정 확장에 관한 경험적 연구",
      "slug": "an-empirical-study-of-scaling-instruct-tuned-large-multimodal-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:33:15+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 다중 모달 모델의 지시 조정 확장에 관한 경험적 연구",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277160",
      "topics": [
        "LLM",
        "에이전트",
        "게임"
      ],
      "title": "MindAgent: 신흥 게임 상호작용",
      "slug": "mindagent-emergent-gaming-interaction",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-27T03:32:58+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "MindAgent: 신흥 게임 상호작용",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277196",
      "topics": [
        "LLM",
        "구조화된 데이터"
      ],
      "title": "Struc-Bench: 대규모 언어 모델이 복잡한 구조화된 데이터 생성에 정말 능숙한가?",
      "slug": "struc-bench-are-large-language-models-really-good-at-generating-complex-structure",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:38+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "Struc-Bench: 복잡한 구조화된 데이터 생성",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277217",
      "topics": [
        "LLM",
        "프라이버시",
        "엣지"
      ],
      "title": "대규모 언어 모델을 이용한 프라이버시 보존 마스킹 복구",
      "slug": "recovering-from-privacy-preserving-masking-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:26+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 이용한 프라이버시 보존 마스킹 복구",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277239",
      "topics": [
        "LLM",
        "채팅"
      ],
      "title": "S3-DST: 대규모 언어 모델 시대의 구조화된 오픈 도메인 대화 분할 및 상태 추적",
      "slug": "s3-dst-structured-open-domain-dialogue-segmentation-and-state-tracking-in-the-era",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:38:11+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "S3-DST: 구조화된 오픈 도메인 대화 분할 및 상태 추적",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277253",
      "topics": [
        "LLM",
        "오디오"
      ],
      "title": "대규모 언어 모델을 이용한 말하기 언어 이해를 위한 텍스트 증강",
      "slug": "augmenting-text-for-spoken-language-understanding-with-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:49+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "대규모 언어 모델을 이용한 말하기 언어 이해를 위한 텍스트 증강",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277277",
      "topics": [
        "LLM",
        "압축"
      ],
      "title": "언어 모델링은 압축이다",
      "slug": "language-modeling-is-compression",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-25T03:37:32+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "언어 모델링은 압축이다",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277345",
      "topics": [
        "LLM",
        "다국어"
      ],
      "title": "백천 2: 대규모 오픈 언어 모델",
      "slug": "baichuan-2-open-large-scale-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:59:10+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "백천 2: 대규모 오픈 언어 모델",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277360",
      "topics": [
        "LLM",
        "RLHF"
      ],
      "title": "RLHF 안정화를 위한 이점 모델 및 선택적 복습",
      "slug": "stabilizing-rlhf-through-advantage-model-and-selective-rehearsal",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:22:15+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "RLHF 안정화를 위한 이점 모델 및 선택적 복습",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277446",
      "topics": [
        "LLM",
        "환각"
      ],
      "title": "검증 체인은 대규모 언어 모델에서 환각을 줄인다",
      "slug": "chain-of-verification-reduces-hallucination-in-large-language-models",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:21:05+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "검증 체인은 대규모 언어 모델에서 환각을 줄인다",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277458",
      "topics": [
        "LLM",
        "환각",
        "엔티티",
        "구조화된 데이터"
      ],
      "title": "LMDX: 언어 모델 기반 문서 정보 추출 및 위치 지정",
      "slug": "lmdx-language-model-based-document-information-extraction-and-localization",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2024-05-24T05:20:31+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      },
      "seo": {
        "title": "LMDX: 언어 모델 기반 문서 정보 추출 및 위치 지정",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198277209",
      "topics": [
        "LLM",
        "데이터"
      ],
      "title": "SlimPajama-DC: 대규모 언어 모델 훈련을 위한 데이터 조합 이해",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T23:43:32+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "SlimPajama-DC: 대규모 언어 모델 훈련을 위한 데이터 조합 이해",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198044929",
      "topics": [
        "LLM",
        "데이터",
        "에이전트"
      ],
      "title": "추론을 위한 데이터 소스",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:33:25+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "추론을 위한 데이터 소스",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198044879",
      "topics": [
        "LLM",
        "트랜스포머",
        "해석 가능성"
      ],
      "title": "Sparse Autoencoders는 언어 모델에서 해석 가능한 특징을 찾는다",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:23:08+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "Sparse Autoencoders는 언어 모델에서 해석 가능한 특징을 찾는다",
        "description": "추상적 코멘터리 및 평가"
      }
    },
    {
      "id": "198044746",
      "topics": [
        "LLM",
        "트랜스포머",
        "훈련"
      ],
      "title": "희소 연결된 기초 모델을 위한 확장 법칙",
      "slug": "accelerating-llm-inference-with-staged-speculative-decoding",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-04T07:09:44+01:00",
      "description": "추상적 코멘터리 및 평가",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692841427-researchpaper8a.png"
      },
      "seo": {
        "title": "희소 연결된 기초 모델을 위한 확장 법칙",
        "description": "추상적 코멘터리 및 평가"
      }
    }
  ],
  "blogContent": {
    "id": "198277109",
    "topics": [
      "LLM",
      "추론"
    ],
    "title": "대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킵니다",
    "slug": "pde-refiner-achieving-accurate-long-rollouts-with-neural-pde-solvers",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-04T22:18:11+01:00",
    "description": "추상적 코멘터리 및 평가",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "2023년 9월 16일 발행"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "저자:"
                    },
                    {
                      "url": "https://huggingface.co/seanobrienresearch",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "션 오브라이언"
                        }
                      ]
                    },
                    {
                      "type": "span",
                      "value": ","
                    },
                    {
                      "url": "https://huggingface.co/mikelewis0",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "마이크 루이스"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "초록"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "우리는 Li et al 2022에 의해 제안된 간단하고, 계산적으로 가벼우며, 훈련이 필요 없는 텍스트 생성 방법인 대조적 디코딩이 다양한 추론 작업에서 탐욕적 디코딩을 크게 능가하는 현장에서의 개선을 달성한다는 것을 보여줍니다. 원래 장문 텍스트 생성의 인식된 품질을 향상시키기 위해 고안된 대조적 디코딩은 강력하고 약한 모델 간의 가능성 차이를 최대화하는 문자열을 검색합니다. 우리는 대조적 디코딩이 LLaMA-65B를 LLaMA 2, GPT-3.5 및 PaLM 2-L을 HellaSwag 상식 추론 벤치마크에서, 그리고 LLaMA 2, GPT-3.5 및 PaLM-540B를 GSM8K 수학 단어 추론 벤치마크에서 능가하며, 다른 작업 모음에서도 개선을 달성한다는 것을 보여줍니다. 분석은 대조적 디코딩이 일부 추상적 추론 오류를 방지하고, 사고의 연쇄 동안 입력의 섹션을 복사하는 것과 같은 더 단순한 모드를 피함으로써 기존 방법보다 개선된다는 것을 제안합니다. 전반적으로 대조적 디코딩은 장문 생성을 위한 핵 샘플링과 추론 작업을 위한 탐욕적 디코딩을 능가하여, 언어 모델에서 텍스트를 생성하기 위한 강력한 범용 방법입니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "url": "https://arxiv.org/abs/2309.09117",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "arXiv 페이지 보기"
                        }
                      ]
                    },
                    {
                      "url": "https://arxiv.org/pdf/2309.09117",
                      "meta": [
                        {
                          "id": "rel",
                          "value": "noreferrer"
                        },
                        {
                          "id": "target",
                          "value": "_blank"
                        }
                      ],
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "PDF 보기"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "코멘터리"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "\"대조적 디코딩은 대규모 언어 모델에서 추론을 향상시킵니다\"라는 제목의 논문은 대규모 언어 모델에서 텍스트 생성 품질과 추론 능력을 향상시키는 접근 방식을 제시합니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "주요 통찰력:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "대조적 디코딩"
                            },
                            {
                              "type": "span",
                              "value": ": 이 방법은 강력하고 약한 모델 간의 가능성 차이를 활용하여 텍스트를 생성합니다. 원래 장문 텍스트 생성을 개선하기 위해 고안되었지만, 저자들은 추론 작업에 대한 그 가치를 보여줍니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "중요한 성능 향상"
                            },
                            {
                              "type": "span",
                              "value": ": 대조적 디코딩은 LLaMA-65B가 특정 추론 벤치마크, 예를 들어 HellaSwag 상식 추론 벤치마크와 GSM8K 수학 단어 추론 벤치마크에서 여러 다른 최첨단 모델을 능가하게 합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "오류 방지"
                            },
                            {
                              "type": "span",
                              "value": ": 분석은 이 방법이 일부 추상적 추론 오류를 방지하는 데 도움이 될 수 있음을 나타냅니다. 또한 텍스트 생성 동안 불필요한 입력 섹션의 복사와 같은 더 단순한 오류를 줄입니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "잠재적 실제 세계 영향:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "향상된 텍스트 생성"
                            },
                            {
                              "type": "span",
                              "value": ": 이 방법은 대규모 언어 모델에서 생성된 텍스트의 품질을 향상시키는 것을 약속하며, 출력을 더 일관되고 관련성 있으며 이성적으로 만듭니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "개선된 추론"
                            },
                            {
                              "type": "span",
                              "value": ": 추론 작업에서의 더 나은 성능은 더 지능적인 챗봇부터 다양한 분석 작업에서 전문가를 돕는 도구에 이르기까지 다양한 응용 프로그램에 사용될 수 있습니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "보다 넓은 적용 가능성"
                            },
                            {
                              "type": "span",
                              "value": ": 훈련이 필요 없는 방법으로서 대조적 디코딩은 추가적인 계산 자원을 필요로 하지 않는 이점을 제공합니다."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "다재다능성"
                            },
                            {
                              "type": "span",
                              "value": ": 이 접근 방식은 장문 생성과 특정 추론 작업 모두에서 개선을 보여주며 다재다능합니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "도전 과제:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "약한 모델에 대한 의존성"
                            },
                            {
                              "type": "span",
                              "value": ": 대조적 디코딩의 효과는 강력하고 약한 모델의 존재에 의존하며, 이는 항상 사용 가능하지 않거나 상대적 강도가 다를 수 있습니다."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "텍스트 생성과 추론을 개선하기 위한 새로운 접근 방식뿐만 아니라 입증된 효과를 감안할 때:"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 논문의 실제 세계 영향을 8.5점 만점에 8.5점으로 평가합니다."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "이 방법은 다양한 작업과 설정에 널리 적용될 수 있다면, 모델의 추론 능력이 중요한 응용 프로그램에서 상당한 실제 세계 영향을 미칠 수 있습니다."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "researchpaper9",
            "height": 816,
            "width": 1456,
            "filename": "researchpaper9.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "추상적 코멘터리 및 평가",
      "title": "대조적 디코딩은 LLM에서 추론을 향상시킵니다",
      "twitterCard": null,
      "image": {
        "width": 1456,
        "height": 816,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692843326-researchpaper9.png"
      }
    }
  },
  "topics": [
    "LLM",
    "Reasoning"
  ]
}