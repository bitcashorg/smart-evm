{
  "relatedBlogs": [
    {
      "id": "190259129",
      "topics": [
        "LLM",
        "Perangkat Keras",
        "Ringkasan",
        "Tepi"
      ],
      "title": "Podcast Ruang Laten 8/10/23 [Ringkasan]: LLM di Mana-mana: Menjalankan model 70B di browser dan iPhone menggunakan MLC — bersama Tianqi Chen dari CMU / OctoML",
      "slug": "latent-space-podcast-8-10-23-summary-llms-everywhere-running-70b-models-in-browse",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:18:37+01:00",
      "description": "Jelajahi keajaiban MLC bersama Tianqi Chen: menerapkan model 70B di browser & iPhone. Menyelami XGBoost, penciptaan TVM, & masa depan penyebaran AI universal.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691894611-screenshot-2023-08-12-at-10-42-43-pm.png"
      },
      "seo": {
        "title": "Ruang Laten 8/10/23 [Ringkasan]: LLM di Mana-mana",
        "description": "Jelajahi penerapan model 70B di browser & iPhone. Menyelami XGBoost, penciptaan TVM, & masa depan penyebaran AI universal."
      }
    },
    {
      "id": "190259087",
      "topics": [
        "Ringkasan",
        "LLM",
        "Kode",
        "Sumber Terbuka",
        "Model Kecil"
      ],
      "title": "Podcast Ruang Laten 8/4/23 [Ringkasan] Ruang Laten x AI Breakdown crossover pod!",
      "slug": "latent-space-podcast-8-4-23-summary-latent-space-x-ai-breakdown-crossover-pod",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:16:33+01:00",
      "description": "Bergabung dengan AI Breakdown & Ruang Laten untuk rangkuman teknologi AI musim panas: Menyelami GPT4.5, Llama 2, alat AI, insinyur AI yang muncul, dan lainnya!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691539617-screenshot-2023-08-08-at-8-02-52-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 8/4/23 [Ringkasan] AI Breakdown crossover",
        "description": "Menyelami GPT4.5, Llama 2, alat AI, insinyur AI yang muncul, dan lainnya!"
      }
    },
    {
      "id": "190259111",
      "topics": [
        "Ringkasan",
        "Transformers",
        "Pelatihan",
        "Sumber Terbuka"
      ],
      "title": "Podcast Ruang Laten 7/26/23 [Ringkasan] FlashAttention 2: membuat Transformers 800% lebih cepat - Tri Dao dari Together AI",
      "slug": "latent-space-podcast-7-26-23-summary-flashattention-2-making-transformers-800-fas",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:14:13+01:00",
      "description": "Temukan bagaimana FlashAttention merevolusi kecepatan AI dengan Tri Dao, saat ia mengungkap kekuatan FlashAttention 2, menyelami Hazy Lab Stanford & wawasan AI masa depan.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691543194-screenshot-2023-08-08-at-8-43-59-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 7/26/23 [Ringkasan] FlashAttention 2",
        "description": "Temukan bagaimana FlashAttention merevolusi kecepatan AI dengan Tri Dao, saat ia mengungkap kekuatan FlashAttention 2"
      }
    },
    {
      "id": "190259172",
      "topics": [
        "Ringkasan",
        "LLM",
        "Sumber Terbuka",
        "Model Kecil"
      ],
      "title": "Podcast Ruang Laten 7/19/23 [Ringkasan] - Llama 2: LLM Terbuka Baru SOTA (ft. Nathan Lambert, Matt Bornstein, Anton Troynikov, Russell Kaplan, Whole Mars Catalog et al.)",
      "slug": "latent-space-podcast-7-19-23-summary-llama-2-the-new-open-llm-sota-ft-nathan-lamb",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:12:38+01:00",
      "description": "Jelajahi Llama 2, terobosan AI terbaru dengan para ahli Nathan Lambert, Matt Bornstein & lainnya. Menyelami dataset, tolok ukur & prediksi AI. Wawasan & drama Llama menanti di podcast teratas ini!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1691968295-screenshot-2023-08-13-at-7-11-06-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 7/19/23 [Ringkasan] - Llama 2",
        "description": "Menyelami dataset, tolok ukur & prediksi AI. Wawasan & drama Llama menanti di podcast teratas ini!"
      }
    },
    {
      "id": "190259191",
      "topics": [
        "Ringkasan",
        "Kode",
        "LLM"
      ],
      "title": "Podcast Ruang Laten 7/10/23 [Ringkasan] - Penerjemah Kode == GPT 4.5 (dengan Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)",
      "slug": "latent-space-podcast-7-10-23-summary-code-interpreter-gpt-4-5-w-simon-willison-al",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:09:26+01:00",
      "description": "Jelajahi Penerjemah Kode ChatGPT: perubahan permainan dalam AI. Menyelami lonjakan kemampuan 1000x dengan Simon, Alex & ahli AI teratas. #CodeAugmentedInference #GPT4_5",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692048911-screenshot-2023-08-14-at-3-34-05-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten [Ringkasan] Penerjemah Kode = GPT 4.5",
        "description": "Jelajahi Penerjemah Kode ChatGPT: perubahan permainan dalam AI. Menyelami lonjakan kemampuan 1000x dengan Simon, Alex & ahli AI teratas. "
      }
    },
    {
      "id": "190259216",
      "topics": [
        "Ringkasan",
        "Sumber Terbuka"
      ],
      "title": "Podcast Ruang Laten 7/2/23 [Ringkasan] Tren AI: crossover pod Ruang Laten x Practical AI!",
      "slug": "latent-space-podcast-7-2-23-summary-ai-trends-a-latent-space-x-practical-ai-cross",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:08:36+01:00",
      "description": "Jelajahi fusi Practical AI & Ruang Laten saat mereka menyelami tren AI teratas 2023, merenungkan episode menonjol, dan berbagi wawasan tentang navigasi evolusi AI.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692146916-screenshot-2023-08-15-at-5-20-38-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 7/2/23 [Ringkasan] Tren AI",
        "description": "Tren AI teratas 2023, merenungkan episode menonjol, dan berbagi wawasan tentang navigasi evolusi AI."
      }
    },
    {
      "id": "190259238",
      "topics": [
        "Perangkat Keras",
        "LLM",
        "Ringkasan"
      ],
      "title": "Podcast Ruang Laten 6/20/23 [Ringkasan] - Komodifikasi Petaflop — dengan George Hotz dari tiny corp",
      "slug": "latent-space-podcast-6-20-23-summary-commoditizing-the-petaflop-with-george-ho",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:07:15+01:00",
      "description": "George Hotz dari tiny corp menantang Nvidia & Google! Menyelami dunia kolaborasi AMD, wawasan tentang ggml, Mojo, Elon & GPT-4, serta intipan ke Pacar AI.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692154615-screenshot-2023-08-15-at-10-55-40-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 6/20/23 [Ringkasan] - George Hotz",
        "description": "George Hotz dari tiny corp menantang Nvidia & Google! Kolaborasi AMD, wawasan tentang ggml, Mojo, Elon & GPT-4, serta intipan ke Pacar AI. "
      }
    },
    {
      "id": "190259294",
      "topics": [
        "LLM",
        "Fungsi",
        "Ringkasan"
      ],
      "title": "Podcast Ruang Laten 6/14/23 [Ringkasan] - Pod Darurat: API Fungsi baru OpenAI, Penurunan Harga 75%, Panjang Konteks 4x (dengan Alex Volkov, Simon Willison, Riley Goodside, Joshua Lochner, Stefania Druga, Eric Elliott, Mayo Oshin et al)",
      "slug": "latent-space-podcast-6-14-23-summary-emergency-pod-openai-s-new-functions-api-75",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:05:04+01:00",
      "description": "Jelajahi pembaruan OpenAI Juni 2023 dengan insinyur AI teratas dari Scale, Microsoft, Pinecone, & Huggingface. Menyelami paradigma Kode x LLM dan temukan Agen Fungsi Rekursif.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692221668-screenshot-2023-08-16-at-5-32-29-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 6/20/23 [Ringkasan] - Pod Darurat",
        "description": "Jelajahi pembaruan OpenAI Juni 2023 dengan insinyur AI teratas dari Scale, Microsoft, Pinecone, & Huggingface. "
      }
    },
    {
      "id": "190259333",
      "topics": [
        "LLM",
        "Ringkasan",
        "UX"
      ],
      "title": "Podcast Ruang Laten 6/8/23 [Ringkasan] - Dari RLHF ke RLHB: Kasus untuk Belajar dari Perilaku Manusia - dengan Jeffrey Wang dan Joe Reeve dari Amplitude",
      "slug": "latent-space-podcast-6-8-23-summary-from-rlhf-to-rlhb-the-case-for-learning-from",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:02:33+01:00",
      "description": "Jelajahi AI & analitik dengan Jeffrey Wang & Joe Reeve di Ruang Laten Live! Menyelami mengapa AI menghargai Analitik dan kekuatan data perilaku pihak pertama.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692386432-screenshot-2023-08-18-at-3-17-04-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 6/8/23 [Ringkasan] - Dari RLHF ke RLHB",
        "description": "Jelajahi AI & analitik dengan Jeffrey Wang & Joe Reeve di Ruang Laten Live! Menyelami mengapa AI menghargai Analitik dan kekuatan data perilaku pihak pertama. "
      }
    },
    {
      "id": "190260528",
      "topics": [
        "Ringkasan",
        "LLM",
        "UX"
      ],
      "title": "Podcast Ruang Laten 6/1/23 [Ringkasan] - Membangun AI × UX Scenius — dengan Linus Lee dari Notion AI",
      "slug": "latent-space-podcast-6-1-23-summary-building-the-ai-x-ux-scenius-with-linus-le",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T09:00:12+01:00",
      "description": "Jelajahi pendekatan transformatif Notion AI terhadap AI dan UX. Menyelami masa depan ruang kerja yang diperkaya AI, nilai di luar antarmuka obrolan, dan wawasan tentang pekerjaan pengetahuan yang efektif. Rekap pertemuan AI×UX NYC termasuk!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692390655-screenshot-2023-08-18-at-4-28-51-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 6/1/23 [Ringkasan] - AI × UX Scenius",
        "description": "Jelajahi pendekatan transformatif Notion AI terhadap AI dan UX. "
      }
    },
    {
      "id": "190260557",
      "topics": [
        "Ringkasan",
        "Kode",
        "LLM",
        "Agen"
      ],
      "title": "Podcast Ruang Laten 5/25/23 [Ringkasan] - Debugging Internet dengan agen AI – dengan Itamar Friedman dari Codium AI dan AutoGPT",
      "slug": "latent-space-podcast-5-25-23-summary-debugging-the-internet-with-ai-agents-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:58:27+01:00",
      "description": "Jelajahi masa depan AI dengan Itamar Friedman dari Codium AI dalam 'Debugging Internet'. Menyelami agen 'Extreme DRY', sinkronisasi cepat spesifikasi & tes, dan keseimbangan antara kode & pengujian. Plus, wawasan dari Toran & tampilan eksklusif pada peta jalan AutoGPT!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692397413-screenshot-2023-08-18-at-6-10-09-pm.png"
      },
      "seo": {
        "title": "Pod Ruang Laten 5/25/23 [Ringkasan] Debugging Internet",
        "description": "Menyelami agen 'Extreme DRY', sinkronisasi cepat spesifikasi & tes, dan keseimbangan antara kode & pengujian. "
      }
    },
    {
      "id": "190260577",
      "topics": [
        "LLM",
        "Model Kecil"
      ],
      "title": "Podcast Ruang Laten 5/20/23 [Ringkasan] - MPT-7B dan Awal Konteks=Infinity — dengan Jonathan Frankle dan Abhinav Venigalla dari MosaicML",
      "slug": "latent-space-podcast-5-20-23-summary-mpt-7b-and-the-beginning-of-context-infinity",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:57:33+01:00",
      "description": "Menyelami pelatihan MPT-7B \"llongboi\" MosaicML selama 9 hari, $200k, wawasan persiapan data, & munculnya model AI terbuka dengan ahli Frankle & Venigalla.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692409795-screenshot-2023-08-18-at-9-49-21-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 6/25/23 [Ringkasan] MosaicML",
        "description": "Menyelami pelatihan MPT-7B \"llongboi\" MosaicML selama 9 hari, $200k, wawasan persiapan data, & munculnya model AI terbuka "
      }
    },
    {
      "id": "190260597",
      "topics": [
        "LLM",
        "Data Terstruktur"
      ],
      "title": "Podcast Ruang Laten 5/15/23 [Ringkasan] - Kualitas dan struktur terjamin dalam output LLM - dengan Shreya Rajpal dari Guardrails AI",
      "slug": "latent-space-podcast-5-15-23-summary-guaranteed-quality-and-structure-in-llm-outp",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:56:26+01:00",
      "description": "Jelajahi Ep. 12 dengan Shreya Rajpal dari Guardrails AI: Menyelami validasi output LLM, menyempurnakan jawaban melalui loop bertanya ulang, dan menetapkan SLA untuk model. Kuasai nuansa jaminan kualitas AI.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692495732-screenshot-2023-08-19-at-9-38-27-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 5/15/23 [Ringkasan] Output LLM Berkualitas",
        "description": "Jelajahi Ep. 12 dengan Shreya Rajpal dari Guardrails AI: Menyelami validasi output LLM."
      }
    },
    {
      "id": "190260606",
      "topics": [
        "LLM",
        "Pelatihan",
        "Agen",
        "Multimodal"
      ],
      "title": "Podcast Ruang Laten 5/8/23 [Ringkasan] - Gen Pendiri AI: Awal, Membangun Cepat, dan Percaya pada Kehebatan — dengan Sharif Shameem dari Lexica",
      "slug": "latent-space-podcast-5-8-23-summary-the-ai-founder-gene-being-early-building-fast",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:52:09+01:00",
      "description": "Ep.11 dengan Sharif Shameem dari Lexica: Menyelami pola pikir pendiri AI, mengungkap rahasia inovasi perintis, membangun teknologi yang mengubah permainan, melatih model, dan potensi menarik Agen dan urutan genomik.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692501984-screenshot-2023-08-19-at-11-24-05-pm.png"
      },
      "seo": {
        "title": "Pod Ruang Laten 5/8/23 [Ringkasan] Gen Pendiri AI",
        "description": "Ep.11 dengan Sharif Shameem dari Lexica: Menyelami pola pikir pendiri AI, mengungkap rahasia inovasi perintis."
      }
    },
    {
      "id": "190260640",
      "topics": [
        "Ringkasan",
        "Sumber Terbuka",
        "LLM"
      ],
      "title": "Podcast Ruang Laten 5/5/23 [Ringkasan] - Tidak Ada Moat: AI Tertutup mendapatkan panggilan bangun Sumber Terbuka — ft. Simon Willison",
      "slug": "latent-space-podcast-5-5-23-summary-no-moat-closed-ai-gets-its-open-source-wakeup",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:49:18+01:00",
      "description": "Jelajahi 'Tidak Ada Moat: Kebangkitan Sumber Terbuka AI Tertutup' dengan Simon Willison. Menyelami wawasan memo Moat Google yang bocor, Kebocoran Otak Google, dan peningkatan kecepatan Python dengan Mojo.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692566921-screenshot-2023-08-20-at-5-25-53-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 5/5/23 [Ringkasan] - Tidak Ada Moat",
        "description": "Jelajahi 'Tidak Ada Moat: Kebangkitan Sumber Terbuka AI Tertutup' dengan Simon Willison. Menyelami wawasan memo Moat Google yang bocor."
      }
    },
    {
      "id": "190260671",
      "topics": [
        "LLM",
        "Kode",
        "Ringkasan"
      ],
      "title": "Podcast Ruang Laten 5/3/23 [Ringkasan] - Melatih LLM Kode SOTA dalam 1 minggu dan Mengkuantifikasi Vibes — dengan Reza Shabani dari Replit",
      "slug": "latent-space-podcast-5-3-23-summary-training-a-sota-code-llm-in-1-week-and-quanti",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:46:08+01:00",
      "description": "Ep. 10 dengan Reza Shabani: Menyelami pelatihan cepat LLM Kode mutakhir, menjelajahi masa depan Ghostwriter Replit, dan perjalanan dari Keuangan ke AI. Temukan transisi dari Kaplan ke Chinchilla dan lainnya!",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1692584998-screenshot-2023-08-20-at-10-17-26-pm.png"
      },
      "seo": {
        "title": "Pod Ruang Laten 5/3/23 [Ringkasan] - LLM Kode SOTA",
        "description": "Ep. 10 dengan Reza Shabani: Menyelami pelatihan cepat LLM Kode mutakhir!"
      }
    },
    {
      "id": "190629271",
      "topics": [
        "LLM",
        "Model Kecil",
        "Ringkasan"
      ],
      "title": "Podcast Ruang Laten 4/28/23 [Ringkasan] - Memetakan masa depan Model Terbuka *sejati* dan Melatih Dolly dengan $30 — dengan Mike Conover dari Databricks",
      "slug": "latent-space-podcast-4-28-23-summary-mapping-the-future-of-truly-open-models-and",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:33:12+01:00",
      "description": "Jelajahi masa depan model terbuka dengan Mike Conover dari Databricks. Menyelami penciptaan Dolly, transisinya dari 1.0 ke 2.0, & pengaruh di balik pengembangannya. Ep.9 membahas infrastruktur model, visi Databricks, & lainnya. #AI #ModelTerbuka #Dolly",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694038707-screenshot-2023-09-06-at-3-12-24-pm.png"
      },
      "seo": {
        "title": "Pod Ruang Laten 4/28/23 [Ringkasan] - Mike dari Databricks",
        "description": "Ep.9 membahas infrastruktur model, visi Databricks, & lainnya. #AI #ModelTerbuka #Dolly"
      }
    },
    {
      "id": "191164291",
      "topics": [
        "LLM",
        "Perusahaan",
        "Ringkasan"
      ],
      "title": "Podcast Ruang Laten 4/21/23 [Ringkasan] - Pencarian AI untuk Perusahaan — dengan Deedy Das dari Glean",
      "slug": "latent-space-podcast-4-21-23-summary-ai-powered-search-for-the-enterprise-with",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:31:31+01:00",
      "description": "Ep.8: Menyelami AI dalam pencarian perusahaan dengan Deedy Das dari Glean. Menganalisis tantangan dalam menciptakan raksasa pencarian AI, perbandingan Google vs ChatGPT, kompleksitas infrastruktur AI, mendeteksi teks yang dihasilkan AI, dan mengapa bisnis membutuhkan lebih dari sekadar QA Dokumen.",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694134074-screenshot-2023-09-07-at-5-43-48-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 4/21/23 [Ringkasan] - dengan Deedy Das",
        "description": "Ep.8: Menyelami AI dalam pencarian perusahaan dengan Deedy Das dari Glean. Menganalisis tantangan dalam menciptakan raksasa pencarian AI, Google vs ChatGPT ..."
      }
    },
    {
      "id": "191165673",
      "topics": [
        "Ringkasan",
        "Visi"
      ],
      "title": "Podcast Ruang Laten 4/13/23 [Ringkasan] - Model Apa Pun dan Masalah Sulit dari Visi Komputer — dengan Joseph Nelson dari Roboflow",
      "slug": "latent-space-podcast-4-13-23-summary-segment-anything-model-and-the-hard-problems",
      "authorName": "Prof. Otto Nomos",
      "authorPicture": {
        "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
      },
      "_publishedAt": "2023-10-05T08:30:03+01:00",
      "description": "Jelajahi Ep.7 dengan Joseph Nelson tentang Model Apa Pun oleh Meta. Menyelami masa depan Visi Komputer, pentingnya OCR, Segmentasi Gambar, dan lainnya. #Roboflow #AI",
      "thumbnail": {
        "url": "https://www.datocms-assets.com/101962/1694150379-screenshot-2023-09-07-at-10-15-52-pm.png"
      },
      "seo": {
        "title": "Podcast Ruang Laten 4/13/23 [Ringkasan] - Model Apa Pun",
        "description": "Menyelami masa depan Visi Komputer, pentingnya OCR, Segmentasi Gambar, dan lainnya. #Roboflow #AI"
      }
    }
  ],
  "blogContent": {
    "id": "190259319",
    "topics": [
      "Ringkasan",
      "LLM",
      "Pelatihan"
    ],
    "title": "Podcast Ruang Laten 8/16/23 [Ringkasan] - Matematika Pelatihan LLM dengan Quentin Anthony dari Eleuther AI",
    "slug": "latent-space-podcast-8-16-23-summary-the-mathematics-of-training-llms-with-que",
    "authorName": "Prof. Otto Nomos",
    "authorPicture": {
      "url": "https://www.datocms-assets.com/101962/1692842125-profottonomosheadshot.png"
    },
    "_publishedAt": "2023-10-05T09:19:45+01:00",
    "description": "Jelajahi matematika di balik pelatihan LLM dengan Quentin Anthony dari Eleuther AI. Menyelami artikel Matematika Transformers 101 & menguasai teknik pelatihan terdistribusi untuk kinerja GPU puncak.",
    "thumbnail": {
      "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
    },
    "contentBlock": [
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Tautan Asli: "
                    },
                    {
                      "url": "https://www.latent.space/p/transformers-math#details",
                      "type": "link",
                      "children": [
                        {
                          "type": "span",
                          "value": "Matematika Pelatihan LLM dengan Quentin Anthony dari Eleuther AI"
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Matematika di Balik Pelatihan Model Bahasa Besar [Ringkasan]"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dalam episode terbaru podcast Ruang Laten, pembawa acara Alessio dan Swyx bergabung dengan Quentin Anthony, tokoh penting dari Eleuther.ai. Mereka memulai dengan mengapresiasi artikel Matematika Transformers 101 Eleuther, yang dianggap oleh banyak orang sebagai sumber yang sangat berwibawa untuk memahami matematika di balik AI dan kompleksitas pelatihan model bahasa besar. Quentin menjelaskan perjalanannya, dari menjadi mahasiswa doktoral di Ohio State University hingga bergabung dengan Eleuther dan menyelami tantangan pelatihan model AI terdistribusi."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Quentin juga menjelaskan motivasi utama di balik penulisan artikel tersebut. Meskipun banyak orang di ruang Deep Learning (DL) sudah familiar dengan teori AI, sedikit yang menyelami kompleksitas praktis—seperti memahami bagaimana inferensi AI berjalan dengan benar di beberapa GPU. Dengan artikel tersebut, Eleuther bertujuan untuk menjembatani kesenjangan ini dan berbagi pengetahuan yang akan bermanfaat bagi insinyur di luar dinding institusi."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Selanjutnya, Quentin menekankan pentingnya mempertimbangkan tidak hanya dataset tetapi juga kebutuhan komputasi. Ini melibatkan memperhitungkan total waktu komputasi dan biaya yang terkait dengannya, membuat persamaan yang mereka bahas menjadi pusat untuk memahami kebutuhan komputasi. Percakapan beralih ke strategi untuk penggunaan GPU yang efisien, menunjukkan kesalahan umum dan tantangan yang dihadapi selama penyebaran skala besar."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Sepanjang waktu, tema yang mendasari adalah kebutuhan akan intuisi praktis, dengan Quentin menekankan pendekatan \"cukup baik\" daripada mengejar kesempurnaan. Pembicaraan menawarkan campuran pemahaman teoritis dan wawasan pragmatis ke dalam dunia AI dan pelatihan model besar."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "screenshot-2023-08-17-at-9-59-17-pm",
            "height": 554,
            "width": 1576,
            "filename": "screenshot-2023-08-17-at-9-59-17-pm.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Penyelaman Mendalam ke dalam Efisiensi Komputasi dan Kebutuhan Memori dalam Sistem AI"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dalam diskusi terperinci:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Pass Maju dan Mundur"
                            },
                            {
                              "type": "span",
                              "value": ": Alessio mempertanyakan mengapa komputer memiliki rasio 2:1 untuk pass maju dan mundur (2PD untuk maju dan 4PD untuk mundur). Quentin menjelaskan bahwa pass maju melibatkan propagasi input sederhana melalui lapisan, sedangkan pass mundur lebih rumit, melibatkan backpropagation."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Matematika Pembelajaran Mendalam"
                            },
                            {
                              "type": "span",
                              "value": ": Swyx menyebutkan efisiensi matematika pembelajaran mendalam, khususnya backpropagation, dibandingkan dengan metode numerik tradisional."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Kompleksitas di Balik Angka Sederhana"
                            },
                            {
                              "type": "span",
                              "value": ": Alessio menunjukkan bahwa meskipun beberapa persamaan matematika tampak sederhana dan elegan, logika di baliknya bisa kompleks. Sentimen ini terlihat dalam persepsi publik tentang rasio optimal di platform seperti Twitter."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "FLOPs Teoritis vs. Aktual"
                            },
                            {
                              "type": "span",
                              "value": ": Swyx membahas perbedaan antara FLOPs teoritis dan aktual, mencatat adanya perbedaan dalam nilai yang dilaporkan. Quentin menjelaskan bahwa FLOPs teoritis didasarkan pada harapan perangkat keras, tetapi pemanfaatan penuh tidak selalu terjadi karena tungguan sinkronisasi, pergerakan data antara CPU dan GPU, dan penundaan lainnya. Dia menyarankan untuk membandingkan FLOPs yang diharapkan dengan kemampuan GPU yang diketahui."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Pertimbangan GPU"
                            },
                            {
                              "type": "span",
                              "value": ": Diskusi menyentuh perbedaan antara GPU Nvidia dan AMD. Meskipun AMD mungkin menawarkan kinerja teoritis yang lebih baik, perangkat lunak CUDA Nvidia dan dukungan sumber terbuka yang luas menawarkan keuntungan praktis. Quentin menyoroti bahwa pilihan sering kali bergantung pada efisiensi tumpukan perangkat lunak dan momentum di domain sumber terbuka."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Kebutuhan Memori dan Presisi"
                            },
                            {
                              "type": "span",
                              "value": ": Alessio dan Swyx membahas kebutuhan memori untuk melatih model, terutama berfokus pada presisi dan kuantisasi. Quentin menjelaskan bahwa beralih dari FP32 ke presisi campuran, seperti FP16 dan FP32, atau BF16 dan FP32, seringkali menghasilkan penggunaan memori lebih banyak karena menyimpan kedua versi bobot. Dia juga menekankan evolusi jenis presisi sebagai respons terhadap kemajuan perangkat keras, mengisyaratkan potensi masa depan menggunakan representasi yang lebih kecil seperti INT4."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls9-img1",
            "height": 956,
            "width": 956,
            "filename": "abls9-img1.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692334531-abls9-img1.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Dilema Memori Pembelajaran Mendalam: Tantangan Pengoptimal Adam"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dalam diskusi tentang pembelajaran mendalam dan metode optimisasi, Quentin menyoroti makalah RWKV sebagai eksplorasi untuk mencapai kualitas Transformer tanpa beban perhatian kuadratik. Inti dari dialog berkisar pada tantangan dan kompleksitas dalam menangani kebutuhan memori komputasi dari pengoptimal Adam. Secara khusus, Quentin menunjukkan bahwa meskipun Adam efisien, ia mengonsumsi lebih banyak memori daripada SGD, khususnya tiga kali lebih banyak. Akibatnya, mendistribusikan memori, terutama saat berurusan dengan paralelisme model dan keadaan pengoptimal, menjadi penting dalam operasi pembelajaran mendalam. Alessio kemudian menekankan implikasi memori dari Adam vanila, menekankan bahwa ia menggunakan 12 byte per parameter, yang membengkak saat mempertimbangkan komponen lain seperti tingkat kuantisasi. Tema utama adalah pencarian efisiensi dan pemahaman dalam ranah optimisasi pembelajaran mendalam dan manajemen memori."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls9-img2",
            "height": 956,
            "width": 956,
            "filename": "abls9-img2.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692334519-abls9-img2.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Mengoptimalkan Memori dan Melatih Model dalam Pembelajaran Mendalam"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Quentin, Swyx, dan Alessio membahas tantangan memori dan optimisasi dalam melatih model besar."
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "marks": [
                        "strong"
                      ],
                      "value": "Poin Utama:"
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "numbered",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Memori Model vs. Pengoptimal:"
                            },
                            {
                              "type": "span",
                              "value": " Meskipun perhatian sebagian besar pada memori model, pengoptimal (misalnya, Adam) biasanya memerlukan lebih banyak memori. Ini menyimpan momentum, varians, dan parameter lainnya. Mengoptimalkan pengoptimal dapat menghasilkan efisiensi memori yang lebih baik daripada hanya berfokus pada model."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Komponen Memori dalam Pelatihan:"
                            },
                            {
                              "type": "span",
                              "value": " Saat melatih model, komponen memori utama adalah parameter model, keadaan pengoptimal, gradien, dan memori aktivasi. Memori aktivasi berubah secara dinamis, yang dapat menyebabkan masalah kehabisan memori yang tidak terduga."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Rekomputasi Aktivasi:"
                            },
                            {
                              "type": "span",
                              "value": " Untuk menangani masalah memori, beberapa strategi melibatkan rekomputasi aktivasi daripada menyimpannya. Strategi bervariasi dari rekomputasi semuanya, rekomputasi selektif berdasarkan ukuran tensor, atau menetapkan ambang ukuran statis untuk tensor yang disimpan."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Pelatihan Terdistribusi dengan Nol:"
                            },
                            {
                              "type": "span",
                              "value": " Algoritma Nol mengoptimalkan pelatihan terdistribusi. Ini menyebarkan parameter, gradien, dan keadaan pengoptimal di beberapa GPU, kemudian mengumpulkannya kembali selama setiap langkah pelatihan. Tujuannya adalah untuk membagi keadaan di seluruh GPU, tetapi ini meningkatkan beban komunikasi."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Penyetelan Halus vs. Pelatihan:"
                            },
                            {
                              "type": "span",
                              "value": " Meskipun ada metode dan pengetahuan yang mapan tentang pelatihan model, penyetelan halus menyajikan tantangannya sendiri. Aspek seperti penyesuaian tingkat pembelajaran dan transfer dataset masih merupakan area eksplorasi."
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Pertimbangan untuk Skala:"
                            },
                            {
                              "type": "span",
                              "value": " Jumlah GPU yang ideal untuk pelatihan terdistribusi bervariasi berdasarkan kecepatan interkoneksi dan total parameter. Terlalu banyak pemisahan dapat memperkenalkan inefisiensi karena beban sinkronisasi."
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Diskusi menekankan kompleksitas manajemen memori dan pentingnya mengoptimalkan tidak hanya parameter model tetapi juga komponen lain, seperti pengoptimal, untuk pembelajaran mendalam yang efisien."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls9-img3",
            "height": 956,
            "width": 956,
            "filename": "abls9-img3.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692334505-abls9-img3.png"
          }
        ]
      },
      {
        "mainContent": {
          "value": {
            "schema": "dast",
            "document": {
              "type": "root",
              "children": [
                {
                  "type": "heading",
                  "level": 2,
                  "children": [
                    {
                      "type": "span",
                      "value": "Mendekripsi Paralelisme 3D: Penyelaman Mendalam ke dalam Teknik Model AI Lanjutan"
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Dalam percakapan antara Alessio, Quentin, dan Swyx, konsep paralelisme 3D dalam model AI dieksplorasi."
                    }
                  ]
                },
                {
                  "type": "list",
                  "style": "bulleted",
                  "children": [
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Paralelisme Data"
                            },
                            {
                              "type": "span",
                              "value": ":"
                            }
                          ]
                        },
                        {
                          "type": "list",
                          "style": "numbered",
                          "children": [
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "marks": [
                                        "strong"
                                      ],
                                      "value": "Paralelisme Data"
                                    },
                                    {
                                      "type": "span",
                                      "value": ": Digambarkan sebagai memiliki salinan model di setiap GPU. Jika ada dua GPU, masing-masing memiliki salinan model yang melakukan pass maju dan mundur, setelah itu mereka menyinkronkan dan meratakan gradien."
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "marks": [
                                        "strong"
                                      ],
                                      "value": "Paralelisme Tensor"
                                    },
                                    {
                                      "type": "span",
                                      "value": ": Ini melibatkan pemisahan model. Jika ada dua GPU, model dipisahkan di tengah, dengan setiap GPU mengoperasikan tensor spesifiknya. Sinkronisasi antar GPU hanya terjadi jika diperlukan."
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "marks": [
                                        "strong"
                                      ],
                                      "value": "Paralelisme Pipa"
                                    },
                                    {
                                      "type": "span",
                                      "value": ": Secara ilustratif, jika ada empat lapisan dalam model dan empat GPU, setiap GPU memegang satu lapisan. Saat setiap GPU menyelesaikan pass majunya, ia mengirimkan outputnya ke GPU berikutnya dalam barisan. Proses ini mengingatkan pada pipa, oleh karena itu namanya."
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Masalah & Pertimbangan"
                            },
                            {
                              "type": "span",
                              "value": ":"
                            }
                          ]
                        },
                        {
                          "type": "list",
                          "style": "numbered",
                          "children": [
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "value": "Masalah potensial yang diangkat adalah kebutuhan agar semua GPU seragam dalam kemampuannya. Perbedaan VRAM antara GPU dapat menyebabkan penyumbatan. Demikian pula, memiliki GPU dengan kecepatan bervariasi akan menyebabkan masalah sinkronisasi, membuat sistem hanya secepat GPU terlambat."
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "value": "Quentin mengutip contoh nyata di mana node memiliki saklar jaringan yang bervariasi, mengakibatkan operasi bergerak dengan kecepatan saklar terlambat."
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "value": "Ketika ditanya tentang adopsi luas teknik yang dibahas, Quentin menyebutkan bahwa meskipun banyak model berbasis GPT menggunakan skema ini, sistem yang murni terpecah tampaknya lebih umum karena menawarkan kesederhanaan."
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    },
                    {
                      "type": "listItem",
                      "children": [
                        {
                          "type": "paragraph",
                          "children": [
                            {
                              "type": "span",
                              "marks": [
                                "strong"
                              ],
                              "value": "Tantangan Masa Depan"
                            },
                            {
                              "type": "span",
                              "value": ":"
                            }
                          ]
                        },
                        {
                          "type": "list",
                          "style": "numbered",
                          "children": [
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "value": "Menyesuaikan skema paralelisme 3D dengan fitur model baru, terutama dengan munculnya model multimodal yang menggabungkan berbagai jenis data seperti teks dan visi."
                                    }
                                  ]
                                }
                              ]
                            },
                            {
                              "type": "listItem",
                              "children": [
                                {
                                  "type": "paragraph",
                                  "children": [
                                    {
                                      "type": "span",
                                      "value": "Komunikasi menjadi hambatan, terutama saat mentransfer data di antara node."
                                    }
                                  ]
                                }
                              ]
                            }
                          ]
                        }
                      ]
                    }
                  ]
                },
                {
                  "type": "paragraph",
                  "children": [
                    {
                      "type": "span",
                      "value": "Pada akhirnya, Quentin menawarkan untuk menjawab pertanyaan lebih lanjut tentang topik tersebut secara offline dan menyebutkan waktu respons cepatnya di Discord. Pembicaraan berakhir dengan Alessio dan Swyx berterima kasih kepada Quentin atas wawasannya."
                    }
                  ]
                }
              ]
            }
          }
        },
        "topImages": [
          {
            "basename": "abls9-img4",
            "height": 956,
            "width": 956,
            "filename": "abls9-img4.png",
            "format": "png",
            "alt": null,
            "url": "https://www.datocms-assets.com/101962/1692334478-abls9-img4.png"
          }
        ]
      }
    ],
    "seo": {
      "description": "Menyelami artikel Matematika Transformers 101 & menguasai teknik pelatihan terdistribusi untuk kinerja GPU puncak.",
      "title": "Podcast Ruang Laten 8/16/23 [Ringkasan] Matematika Pelatihan LLM",
      "twitterCard": null,
      "image": {
        "width": 1576,
        "height": 554,
        "title": null,
        "alt": null,
        "url": "https://www.datocms-assets.com/101962/1692324088-screenshot-2023-08-17-at-9-59-17-pm.png"
      }
    }
  },
  "topics": [
    "Summary",
    "LLM",
    "Training"
  ]
}